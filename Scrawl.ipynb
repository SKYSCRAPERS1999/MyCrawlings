{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-03T13:02:17.555419Z",
     "start_time": "2018-08-03T13:02:17.550757Z"
    }
   },
   "outputs": [],
   "source": [
    "def request_view(response):\n",
    "    import webbrowser\n",
    "    request_url = response.url\n",
    "    base_url = '<head><base href=\"%s\">'%(request_url)\n",
    "    base_url = base_url.encode()\n",
    "    content = response.content.replace(b\"<head>\", base_url)\n",
    "    tem_html = open(\"tmp.html\", \"wb\")\n",
    "    tem_html.write(content)\n",
    "    tem_html.close()\n",
    "    webbrowser.open_new_tab(\"tmp.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "response = requests.get(\"http://m.qiubaichengren.net/\")\n",
    "request_view(response)\n",
    "# print (response.status_code, response.content.decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import etree\n",
    "html = etree.HTML(response.content)\n",
    "# html.xpath(\"//div[@class='page']//a[contains(text(),'下一页')]/@href\")\n",
    "html.xpath(\"//li[@class='next']/i/a/@href\")\n",
    "# from bs4 import BeautifulSoup\n",
    "# soup = BeautifulSoup(response.content, 'html.parser')\n",
    "# print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from time import sleep\n",
    "host = \"http://m.qiubaichengren.net/\"\n",
    "def test_all_links(url):\n",
    "    response = requests.get(url)\n",
    "    print(url, response.status_code)\n",
    "    from lxml import etree\n",
    "    html = etree.HTML(response.content)\n",
    "    links = html.xpath(\"//li[@class='next']/i/a/@href\")\n",
    "    if len(links) == 0:\n",
    "        pass\n",
    "    else:\n",
    "        sleep(1)\n",
    "        test_all_links(host + links[0])\n",
    "        \n",
    "test_all_links(\"http://m.qiubaichengren.net/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from lxml import etree\n",
    "\n",
    "class Login(object):\n",
    "    def __init__(self):\n",
    "        self.headers = {\n",
    "            'Referer': 'https://github.com/',\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/57.0.2987.133 Safari/537.36',\n",
    "            'Host': 'github.com'\n",
    "        }\n",
    "        self.login_url = 'https://github.com/login'\n",
    "        self.post_url = 'https://github.com/session'\n",
    "        self.logined_url = 'https://github.com/settings/profile'\n",
    "        self.session = requests.Session()\n",
    "\n",
    "    def token(self):\n",
    "        response = self.session.get(self.login_url, headers = self.headers)\n",
    "        selector = etree.HTML(response.text)\n",
    "        token = selector.xpath('//*[@id=\"login\"]/form/input[2]/@value')\n",
    "        return token\n",
    "    \n",
    "    def login(self, email, password):\n",
    "        post_data = {\n",
    "            'commit': 'Sign in',\n",
    "            'utf8': '✓',\n",
    "            'authenticity_token': self.token(),\n",
    "            'login': email,\n",
    "            'password': password\n",
    "        }\n",
    "        response = self.session.post(self.post_url, data=post_data, headers=self.headers)\n",
    "        print (response.status_code)\n",
    "        if response.status_code == 200:\n",
    "            print ('ok1')\n",
    "            self.dynamics(response.text)\n",
    "        \n",
    "        response = self.session.get(self.logined_url, headers=self.headers)\n",
    "        if response.status_code == 200:\n",
    "            print ('ok2')\n",
    "            self.profile(response.text)\n",
    "            \n",
    "    def dynamics(self, html):\n",
    "        selector = etree.HTML(html)\n",
    "        dynamics = selector.xpath('//div[contains(@class, \"news\")]//div[contains(@class, \"alert\")]')\n",
    "        for item in dynamics:\n",
    "            dynamic = ' '.join(item.xpath('.//div[@class=\"title\"]//text()')).strip()\n",
    "            print(dynamic)\n",
    "    \n",
    "    def profile(self, html):\n",
    "        selector = etree.HTML(html)\n",
    "        name = selector.xpath('//input[@id=\"user_profile_name\"]/@value')\n",
    "        email = selector.xpath('//select[@id=\"user_profile_email\"]/option[@value!=\"\"]/text()')\n",
    "        print(name, email)\n",
    "        \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    login = Login()\n",
    "    login.login(email='386333667@qq.com', password='zhzh995=')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from lxml import etree\n",
    "\n",
    "class Login(object):\n",
    "    def __init__(self):\n",
    "        self.headers = {\n",
    "            'Referer': 'https://github.com/',\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/57.0.2987.133 Safari/537.36',\n",
    "            'Host': 'github.com'\n",
    "        }\n",
    "        self.login_url = 'https://github.com/login'\n",
    "        self.post_url = 'https://github.com/session'\n",
    "        self.logined_url = 'https://github.com/settings/profile'\n",
    "        self.session = requests.Session()\n",
    "    \n",
    "    def token(self):\n",
    "        response = self.session.get(self.login_url, headers=self.headers)\n",
    "        selector = etree.HTML(response.text)\n",
    "        token = selector.xpath('//div//input[2]/@value')\n",
    "        return token\n",
    "    \n",
    "    def login(self, email, password):\n",
    "        post_data = {\n",
    "            'commit': 'Sign in',\n",
    "            'utf8': '✓',\n",
    "            'authenticity_token': self.token()[0],\n",
    "            'login': email,\n",
    "            'password': password\n",
    "        }\n",
    "        response = self.session.post(self.post_url, data=post_data, headers=self.headers)\n",
    "        if response.status_code == 200:\n",
    "            self.dynamics(response.text)\n",
    "        \n",
    "        response = self.session.get(self.logined_url, headers=self.headers)\n",
    "        if response.status_code == 200:\n",
    "            self.profile(response.text)\n",
    "    \n",
    "    def dynamics(self, html):\n",
    "        selector = etree.HTML(html)\n",
    "        dynamics = selector.xpath('//div[contains(@class, \"news\")]//div[contains(@class, \"alert\")]')\n",
    "        for item in dynamics:\n",
    "            dynamic = ' '.join(item.xpath('.//div[@class=\"title\"]//text()')).strip()\n",
    "            print(dynamic)\n",
    "    \n",
    "    def profile(self, html):\n",
    "        selector = etree.HTML(html)\n",
    "        name = selector.xpath('//input[@id=\"user_profile_name\"]/@value')[0]\n",
    "        email = selector.xpath('//select[@id=\"user_profile_email\"]/option[@value!=\"\"]/text()')\n",
    "        print(name, email)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    login = Login()\n",
    "    login.login(email='386333667@qq.com', password='zhzh995=')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "browser = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T03:09:54.134701Z",
     "start_time": "2018-07-31T03:09:54.082773Z"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "math.isnan('nan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T04:02:51.076181Z",
     "start_time": "2018-07-31T04:02:51.073092Z"
    }
   },
   "outputs": [],
   "source": [
    "print(float(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-01T05:17:07.147181Z",
     "start_time": "2018-08-01T05:17:07.135631Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('Documents/Codeforces/Muli4/output.txt') as fp:\n",
    "    for expr in fp:\n",
    "        if (expr != 'IMPOSSIBLE' and expr != None):\n",
    "            x = eval(expr)\n",
    "            print (x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-02T04:34:17.059260Z",
     "start_time": "2018-08-02T04:34:17.049010Z"
    }
   },
   "outputs": [],
   "source": [
    "ans = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-08-02T04:34:30.582Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(100000):\n",
    "    for j in range(i*i+1, (i+1)*(i+1)):\n",
    "        if (i*i*i*i % j == 0):\n",
    "            ans.append(i)\n",
    "            break\n",
    "print (ans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goverment Datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-03T17:26:59.461002Z",
     "start_time": "2018-08-03T17:26:59.449715Z"
    }
   },
   "outputs": [],
   "source": [
    "from lxml import etree\n",
    "import requests, re, time\n",
    "from bs4 import BeautifulSoup\n",
    "headers = {\n",
    "    'User-Agent':'Mozilla/5.0 (Windows; U; Windows NT 6.1; en-US; rv:1.9.1.6) Gecko/20091201 Firefox/3.5.6'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-03T03:39:31.427400Z",
     "start_time": "2018-08-03T03:39:31.421117Z"
    }
   },
   "source": [
    "## ShangWuBu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### China"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-03T12:40:54.689877Z",
     "start_time": "2018-08-03T12:40:54.668475Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_swb_china():\n",
    "    print ('In {}, begin, date is {}'.format(get_swb_china.__name__, time.strftime('%Y-%m-%d-%H:%M', time.localtime(time.time()))))\n",
    "        \n",
    "    base_url = 'http://www.mofcom.gov.cn'\n",
    "    response = requests.get(base_url + '/article/zhengcejd/', headers=headers)\n",
    "    text = str(response.content, 'utf-8')\n",
    "    html = etree.HTML(text)\n",
    "    xpath = '//*[@id=\"wrap\"]/div[2]/div/div[1]/div[2]/ul/li/a[1]/text()'\n",
    "    titles = html.xpath(xpath)\n",
    "    # print (titles)\n",
    "    xpath = '//*[@id=\"wrap\"]/div[2]/div/div[1]/div[2]/ul/li/a[1]/@href'\n",
    "    links = html.xpath(xpath)\n",
    "    # print (links)\n",
    "    xpath = '//*[@id=\"wrap\"]/div[2]/div/div[1]/div[2]/ul/li/span/text()'\n",
    "    dates = html.xpath(xpath)\n",
    "    # print (dates)\n",
    "\n",
    "    data_china = [ (t, l, d, 'china') for (t, l, d) in zip(titles, links, dates) ]\n",
    "\n",
    "    response = requests.get(base_url + '/article/b/', headers=headers)\n",
    "    text = str(response.content, 'utf-8')\n",
    "    html = etree.HTML(text)\n",
    "    xpath = '//*[@id=\"wrap\"]/div[2]/div/div[1]/div[2]/ul/li/a/text()'\n",
    "    titles = html.xpath(xpath)\n",
    "    xpath = '//*[@id=\"wrap\"]/div[2]/div/div[1]/div[2]/ul/li/a/@href'\n",
    "    links = html.xpath(xpath)\n",
    "    links = [ base_url + str(x) for x in links]\n",
    "    xpath = '//*[@id=\"wrap\"]/div[2]/div/div[1]/div[2]/ul/li/span/text()'\n",
    "    dates = html.xpath(xpath)\n",
    "\n",
    "    data_china = data_china + [ (t, l, d, 'china') for t, l, d in zip(titles, links, dates) ]\n",
    "\n",
    "    dict_china = [{'pos':x[3], 'title': x[0], 'link': x[1], 'date': x[2]} for x in data_china]\n",
    "  \n",
    "    print (len(dict_china))\n",
    "\n",
    "    print ('In {}, end, date is {}'.format(get_swb_china.__name__, time.strftime('%Y-%m-%d-%H:%M', time.localtime(time.time()))))\n",
    "\n",
    "    return dict_china"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-03T03:39:51.363515Z",
     "start_time": "2018-08-03T03:39:51.354055Z"
    }
   },
   "source": [
    "### JiangSu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-03T12:40:55.796041Z",
     "start_time": "2018-08-03T12:40:55.790433Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_swb_jiangsu():\n",
    "    \n",
    "    print ('In {}, begin, date is {}'.format(get_swb_jiangsu.__name__, time.strftime('%Y-%m-%d-%H:%M', time.localtime(time.time()))))\n",
    "\n",
    "    base_url = 'http://swt.jiangsu.gov.cn'\n",
    "    response = requests.get(base_url + '/col/col12660/index.html', headers=headers)\n",
    "    text = str(response.content, 'utf-8')\n",
    "    # print (text)\n",
    "    regex = re.compile('<a href=\"(.*)\" target=\"_blank\">(.*)</a><span style=\".*\"> \\((.*)\\)</span>')\n",
    "\n",
    "    data_jiangsu = [(x[1], base_url+x[0], x[2].replace('/', '-'), 'jiangsu') for x in re.findall(pattern=regex, string=text)]\n",
    "    \n",
    "    dict_jiangsu = [{'pos':x[3], 'title': x[0], 'link': x[1], 'date': x[2]} for x in data_jiangsu]\n",
    "    \n",
    "    print (len(dict_jiangsu))\n",
    "    \n",
    "    print ('In {}, end, date is {}'.format(get_swb_jiangsu.__name__, time.strftime('%Y-%m-%d-%H:%M', time.localtime(time.time()))))\n",
    "\n",
    "    return dict_jiangsu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ZheJiang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-03T12:40:56.780601Z",
     "start_time": "2018-08-03T12:40:56.774918Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_swb_zhejiang():\n",
    "    \n",
    "    print ('In {}, begin, date is {}'.format(get_swb_zhejiang.__name__, time.strftime('%Y-%m-%d-%H:%M', time.localtime(time.time()))))\n",
    "\n",
    "    base_url = 'http://zhejiang.mofcom.gov.cn'\n",
    "    response = requests.get(base_url + '/article/sjtongzhigg', headers=headers)\n",
    "    text = str(response.content, 'utf-8')\n",
    "    html = etree.HTML(text)\n",
    "    xpath = '//*[@id=\"main\"]/div[2]/div/ul/li/a/text()'\n",
    "    titles = html.xpath(xpath)\n",
    "    xpath = '//*[@id=\"main\"]/div[2]/div/ul/li/a/@href'\n",
    "    links = html.xpath(xpath)\n",
    "    links = [ base_url + str(x) for x in links]\n",
    "    xpath = '//*[@id=\"main\"]/div[2]/div/ul/li/span/text()'\n",
    "    dates = html.xpath(xpath)\n",
    "    dates = [x.split()[0] for x in dates]\n",
    "\n",
    "    data_zhejiang = [ (t, l, d, 'zhejiang') for t, l, d in zip(titles, links, dates) ]\n",
    "    \n",
    "    dict_zhejiang = [{'pos':x[3], 'title': x[0], 'link': x[1], 'date': x[2]} for x in data_zhejiang]\n",
    "    \n",
    "    print (len(dict_zhejiang))\n",
    "\n",
    "    print ('In {}, end, date is {}'.format(get_swb_zhejiang.__name__, time.strftime('%Y-%m-%d-%H:%M', time.localtime(time.time()))))\n",
    "\n",
    "    return dict_zhejiang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GuangDong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-03T12:40:57.808399Z",
     "start_time": "2018-08-03T12:40:57.799907Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_swb_guangdong():\n",
    "    \n",
    "    print ('In {}, begin, date is {}'.format(get_swb_guangdong.__name__, time.strftime('%Y-%m-%d-%H:%M', time.localtime(time.time()))))\n",
    "\n",
    "    base_url = 'http://www.gdcom.gov.cn/zwgk/zcwj/'\n",
    "    response = requests.get(base_url, headers=headers)\n",
    "    \n",
    "    if (response.status_code != 200):\n",
    "        return None\n",
    "\n",
    "    text = str(response.content, 'utf-8')\n",
    "    html = etree.HTML(text)\n",
    "    xpath = '/html/body/div[2]/div/div[2]/ul/li/a/text()'\n",
    "    titles = html.xpath(xpath)\n",
    "    xpath = '/html/body/div[2]/div/div[2]/ul/li/a/@href'\n",
    "    links = html.xpath(xpath)\n",
    "    tlinks = []\n",
    "    for x in links:\n",
    "        x = str(x)\n",
    "        if x != None and x[:2] == './':\n",
    "            x = base_url + x[2:]\n",
    "        tlinks.append(x)\n",
    "    links = tlinks\n",
    "    \n",
    "    xpath = '/html/body/div[2]/div/div[2]/ul/li/span/text()'\n",
    "    dates = html.xpath(xpath)\n",
    "    dates = [x.replace(' ', '') for x in dates]\n",
    "    \n",
    "    data_guangdong = [ (t, l, d, 'guangdong') for t, l, d in zip(titles, links, dates) ]\n",
    "        \n",
    "    dict_guangdong = [{'pos':x[3], 'title': x[0], 'link': x[1], 'date': x[2]} for x in data_guangdong]\n",
    "    \n",
    "    print (len(dict_guangdong))\n",
    "\n",
    "    print ('In {}, end, date is {}'.format(get_swb_guangdong.__name__, time.strftime('%Y-%m-%d-%H:%M', time.localtime(time.time()))))\n",
    "\n",
    "    return dict_guangdong"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Mysql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mysql Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-03T12:42:24.013269Z",
     "start_time": "2018-08-03T12:42:24.010302Z"
    }
   },
   "outputs": [],
   "source": [
    "import pymysql\n",
    "# db = pymysql.connect(host='119.29.190.115', user='impulse', password='njuacmicpc', port=3306)\n",
    "# cursor = db.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-03T12:41:00.053500Z",
     "start_time": "2018-08-03T12:41:00.049982Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_db(cursor, name):\n",
    "    sql = 'create database {name} default character set utf8'.format(name=name)\n",
    "    cursor.execute(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-03T17:27:26.797751Z",
     "start_time": "2018-08-03T17:27:26.378331Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Create table!!!\n",
    "# import pymysql\n",
    "# db = pymysql.connect(host='119.29.190.115', user='impulse', password='njuacmicpc', port=3306, db='gov')\n",
    "# cursor = db.cursor()\n",
    "# sql = 'create table if not exists zscqj (pos VARCHAR(32), title VARCHAR(512), link VARCHAR(512), date VARCHAR(64), PRIMARY KEY (link))'\n",
    "# cursor.execute(sql)\n",
    "# db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-03T12:42:42.249024Z",
     "start_time": "2018-08-03T12:42:42.239388Z"
    }
   },
   "outputs": [],
   "source": [
    "def sql_insert(db, cursor, table, data):\n",
    "    keys = ', '.join(data.keys())\n",
    "    values = ', '.join(['%s'] * len(data))\n",
    "    sql = 'insert into {table}({keys}) values ({values}) on duplicate key update'.format(table=table, \n",
    "            keys=keys, values=values)\n",
    "    update = ','.join([\" {key} = %s\".format(key=key) for key in data])\n",
    "    sql += update\n",
    "    #print (sql)\n",
    "    try:\n",
    "        if cursor.execute(sql, tuple(data.values())*2):\n",
    "            print('Successful')\n",
    "            db.commit()\n",
    "        else:\n",
    "            print ('Nothing to do')\n",
    "    except:\n",
    "        print ('Failed')\n",
    "        db.rollback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-03T12:42:43.290253Z",
     "start_time": "2018-08-03T12:42:43.283241Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_swb():\n",
    "    db = pymysql.connect(host='119.29.190.115', user='impulse', password='njuacmicpc', port=3306, db='gov')\n",
    "    cursor = db.cursor()\n",
    "    for dic in get_swb_china():\n",
    "        sql_insert(db=db,cursor=cursor,data=dic,table='swb')\n",
    "    for dic in get_swb_jiangsu():\n",
    "        sql_insert(db=db,cursor=cursor,data=dic,table='swb')\n",
    "    for dic in get_swb_guangdong():\n",
    "        sql_insert(db=db,cursor=cursor,data=dic,table='swb')\n",
    "    for dic in get_swb_zhejiang():\n",
    "        sql_insert(db=db,cursor=cursor,data=dic,table='swb')\n",
    "    db.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ShangWuBuWaiMaoSi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-03T14:20:39.817574Z",
     "start_time": "2018-08-03T14:20:39.807206Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_wms_china():\n",
    "    \n",
    "    print ('In {}, begin, date is {}'.format(get_wms_china.__name__, time.strftime('%Y-%m-%d-%H:%M', time.localtime(time.time()))))\n",
    "\n",
    "    base_url = 'http://wms.mofcom.gov.cn'\n",
    "    response = requests.get(base_url + '/article/zcfb/ax/', headers=headers)\n",
    "        \n",
    "    text = str(response.content, 'utf-8')\n",
    "    html = etree.HTML(text)\n",
    "    xpath = '//*[@id=\"leftList\"]/div[2]/ul/li/a[1]/text()'\n",
    "    titles = html.xpath(xpath)\n",
    "    # print (titles)\n",
    "    xpath = '//*[@id=\"leftList\"]/div[2]/ul/li/a[1]/@href'\n",
    "    links = html.xpath(xpath)\n",
    "    links = [ base_url + str(x) for x in links]\n",
    "    # print (links)\n",
    "    xpath = '//*[@id=\"leftList\"]/div[2]/ul/li/span/text()'\n",
    "    dates = html.xpath(xpath)\n",
    "    dates = [x.split()[0] for x in dates]\n",
    "    # print (dates)\n",
    "\n",
    "    data_china = [ (t, l, d, 'china') for (t, l, d) in zip(titles, links, dates) ]\n",
    "\n",
    "    response = requests.get(base_url + '/article/zcfb/g/', headers=headers)\n",
    "    \n",
    "    text = str(response.content, 'utf-8')\n",
    "    html = etree.HTML(text)\n",
    "    xpath = '//*[@id=\"leftList\"]/div[2]/ul/li/a[1]/text()'\n",
    "    titles = html.xpath(xpath)\n",
    "    xpath = '//*[@id=\"leftList\"]/div[2]/ul/li/a[1]/@href'\n",
    "    links = html.xpath(xpath)\n",
    "    links = [ base_url + str(x) for x in links]\n",
    "    xpath = '//*[@id=\"leftList\"]/div[2]/ul/li/span/text()'\n",
    "    dates = html.xpath(xpath)\n",
    "    dates = [x.split()[0] for x in dates]\n",
    "    \n",
    "    data_china = data_china + [ (t, l, d, 'china') for t, l, d in zip(titles, links, dates) ]\n",
    "\n",
    "    dict_china = [{'pos':x[3], 'title': x[0], 'link': x[1], 'date': x[2]} for x in data_china]\n",
    "  \n",
    "    print (len(dict_china))\n",
    "\n",
    "    print ('In {}, end, date is {}'.format(get_wms_china.__name__, time.strftime('%Y-%m-%d-%H:%M', time.localtime(time.time()))))\n",
    "\n",
    "    return dict_china"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-03T14:21:07.950242Z",
     "start_time": "2018-08-03T14:21:07.944104Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_wms_jiangsu():\n",
    "\n",
    "    print ('In {}, begin, date is {}'.format(get_wms_jiangsu.__name__, time.strftime('%Y-%m-%d-%H:%M', time.localtime(time.time()))))\n",
    "\n",
    "    base_url = 'http://swt.jiangsu.gov.cn'\n",
    "    \n",
    "    response = requests.get(base_url + '/col/col57691/index.html', headers=headers)\n",
    "    text = str(response.content, 'utf-8')\n",
    "    regex = re.compile('<a href=\"(.*)\" target=\"_blank\" .*title=\"(.*)\">.*</a><span.*> \\((.*)\\)</span>')\n",
    "    data_jiangsu = [(x[1], base_url+x[0], x[2].replace('/', '-'), 'jiangsu') for x in re.findall(pattern=regex, string=text)]\n",
    "    \n",
    "    response = requests.get(base_url + '/col/col57692/index.html', headers=headers)\n",
    "    text = str(response.content, 'utf-8')\n",
    "    regex = re.compile('<a href=\"(.*)\" target=\"_blank\" .*title=\"(.*)\">.*</a><span.*> \\((.*)\\)</span>')\n",
    "    data_jiangsu += [(x[1], base_url+x[0], x[2].replace('/', '-'), 'jiangsu') for x in re.findall(pattern=regex, string=text)]\n",
    "    \n",
    "    dict_jiangsu = [{'pos':x[3], 'title': x[0], 'link': x[1], 'date': x[2]} for x in data_jiangsu]\n",
    "    \n",
    "    print (len(dict_jiangsu))\n",
    "\n",
    "    print ('In {}, end, date is {}'.format(get_wms_jiangsu.__name__, time.strftime('%Y-%m-%d-%H:%M', time.localtime(time.time()))))\n",
    "\n",
    "    return dict_jiangsu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-03T14:21:42.944431Z",
     "start_time": "2018-08-03T14:21:42.935565Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_wms_zhejiang():\n",
    "\n",
    "    print ('In {}, begin, date is {}'.format(get_wms_zhejiang.__name__, time.strftime('%Y-%m-%d-%H:%M', time.localtime(time.time()))))\n",
    "\n",
    "    base_url = 'http://www.zcom.gov.cn'\n",
    "    \n",
    "    response = requests.get(base_url + '/col/col1385815/index.html', headers=headers)\n",
    "    text = str(response.content, 'utf-8')\n",
    "\n",
    "    html = etree.HTML(text)\n",
    "    xpath = '//*[@id=\"con_two_2\"]/div[position()>1]/a[1]/text()'\n",
    "    titles = html.xpath(xpath)  \n",
    "    xpath = '//*[@id=\"con_two_2\"]/div[position()>1]/a[1]/@href'\n",
    "    links = html.xpath(xpath)\n",
    "    links = [ base_url + str(x) for x in links]\n",
    "    \n",
    "    xpath = '//*[@id=\"con_two_2\"]/div[position()>1]/a[1]/span/text()'\n",
    "    dates = html.xpath(xpath)\n",
    "    data_zhejiang = [ (t, l, d, 'zhejiang') for t, l, d in zip(titles, links, dates) ]\n",
    "\n",
    "    ################\n",
    "    \n",
    "    xpath = '//*[@id=\"con_three_1\"]/div[position()>1]/a[1]/text()'\n",
    "    titles = html.xpath(xpath)  \n",
    "    xpath = '//*[@id=\"con_three_1\"]/div[position()>1]/a[1]/@href'\n",
    "    links = html.xpath(xpath)\n",
    "    links = [ base_url + str(x) for x in links]\n",
    "    \n",
    "    xpath = '//*[@id=\"con_three_1\"]/div[position()>1]/a[1]/span/text()'\n",
    "    dates = html.xpath(xpath)\n",
    "    data_zhejiang += [ (t, l, d, 'zhejiang') for t, l, d in zip(titles, links, dates) ]\n",
    "    \n",
    "    dict_zhejiang = [{'pos':x[3], 'title': x[0], 'link': x[1], 'date': x[2]} for x in data_zhejiang]\n",
    "  \n",
    "    print (len(dict_zhejiang))\n",
    "\n",
    "    print ('In {}, end, date is {}'.format(get_wms_zhejiang.__name__, time.strftime('%Y-%m-%d-%H:%M', time.localtime(time.time()))))\n",
    "\n",
    "    return dict_zhejiang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-03T14:21:40.230615Z",
     "start_time": "2018-08-03T14:21:40.224308Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_wms_guangdong():\n",
    "    \n",
    "    print ('In {}, begin, date is {}'.format(get_wms_guangdong.__name__, time.strftime('%Y-%m-%d-%H:%M', time.localtime(time.time()))))\n",
    "\n",
    "    base_url = 'http://go.gdcom.gov.cn'\n",
    "    \n",
    "    response = requests.get(base_url + '/article.php?typeid=9', headers=headers)\n",
    "    text = str(response.content, 'utf-8')\n",
    "\n",
    "    html = etree.HTML(text)\n",
    "    xpath = '/html/body/div[3]/div/div[2]/div/div[2]/div[2]/ul/li/h6/a[1]/text()'\n",
    "    titles = html.xpath(xpath)  \n",
    "    xpath = '/html/body/div[3]/div/div[2]/div/div[2]/div[2]/ul/li/h6/a[1]/@href'\n",
    "    links = html.xpath(xpath)\n",
    "    links = [ base_url + '/' + str(x) for x in links]\n",
    "    \n",
    "    xpath = '/html/body/div[3]/div/div[2]/div/div[2]/div[2]/ul/li/h6/small/text()'\n",
    "    dates = html.xpath(xpath)\n",
    "    data_guangdong = [ (t, l, d, 'guangdong') for t, l, d in zip(titles, links, dates) ]\n",
    "\n",
    "    dict_guangdong = [{'pos':x[3], 'title': x[0], 'link': x[1], 'date': x[2]} for x in data_guangdong]\n",
    "  \n",
    "    print (len(dict_guangdong))\n",
    "\n",
    "    print ('In {}, end, date is {}'.format(get_wms_guangdong.__name__, time.strftime('%Y-%m-%d-%H:%M', time.localtime(time.time()))))\n",
    "\n",
    "    return dict_guangdong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-03T14:21:46.662900Z",
     "start_time": "2018-08-03T14:21:46.656292Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_wms():\n",
    "    db = pymysql.connect(host='119.29.190.115', user='impulse', password='njuacmicpc', port=3306, db='gov')\n",
    "    cursor = db.cursor()\n",
    "    for dic in get_wms_china():\n",
    "        sql_insert(db=db,cursor=cursor,data=dic,table='wms')\n",
    "    for dic in get_wms_jiangsu():\n",
    "        sql_insert(db=db,cursor=cursor,data=dic,table='wms')\n",
    "    for dic in get_wms_guangdong():\n",
    "        sql_insert(db=db,cursor=cursor,data=dic,table='wms')\n",
    "    for dic in get_wms_zhejiang():\n",
    "        sql_insert(db=db,cursor=cursor,data=dic,table='wms')\n",
    "    db.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ZhiShiChanQuanJu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-03T15:31:17.127056Z",
     "start_time": "2018-08-03T15:31:17.104849Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_zscqj_china():\n",
    "    \n",
    "    print ('In {}, begin, date is {}'.format(get_zscqj_china.__name__, time.strftime('%Y-%m-%d-%H:%M', time.localtime(time.time()))))\n",
    "\n",
    "    base_url = 'http://www.sipo.gov.cn'\n",
    "    \n",
    "    response = requests.get(base_url + '/gwywj/index.htm', headers=headers)     \n",
    "    text = str(response.content, 'utf-8')\n",
    "    html = etree.HTML(text)\n",
    "    xpath = '/html/body/div/div/div/div[4]/div/div[2]/ul/li/a[1]/text()'\n",
    "    titles = html.xpath(xpath)\n",
    "    # print (titles)\n",
    "    xpath = '/html/body/div/div/div/div[4]/div/div[2]/ul/li/a[1]/@href'\n",
    "    links = html.xpath(xpath)\n",
    "    # print (links)\n",
    "    xpath = '/html/body/div/div/div/div[4]/div/div[2]/ul/li/span/text()'\n",
    "    dates = html.xpath(xpath)\n",
    "    # print (dates)\n",
    "    data_china = [ (t, l, d, 'china') for (t, l, d) in zip(titles, links, dates) ]\n",
    "\n",
    "    response = requests.get(base_url + '/dtxx/index.htm', headers=headers)\n",
    "    text = str(response.content, 'utf-8')\n",
    "    html = etree.HTML(text)\n",
    "    xpath = '/html/body/div/div/div/div[4]/div/div[2]/ul/li/a[1]/text()'\n",
    "    titles = html.xpath(xpath)\n",
    "    # print (titles)\n",
    "    xpath = '/html/body/div/div/div/div[4]/div/div[2]/ul/li/a[1]/@href'\n",
    "    links = html.xpath(xpath)\n",
    "    ## !!!!!\n",
    "    links = [ base_url + '/dtxx/' + str(x) for x in links] \n",
    "    # print (links)\n",
    "    xpath = '/html/body/div/div/div/div[4]/div/div[2]/ul/li/span/text()'\n",
    "    dates = html.xpath(xpath)\n",
    "    # print (dates) \n",
    "    data_china = data_china + [ (t, l, d, 'china') for t, l, d in zip(titles, links, dates) ]\n",
    "\n",
    "    response = requests.get(base_url + '/zfgg/index.htm', headers=headers)\n",
    "    text = str(response.content, 'utf-8')\n",
    "    html = etree.HTML(text)\n",
    "    xpath = '/html/body/div/div/div/div[4]/div/div[2]/ul/li/a[1]/text()'\n",
    "    titles = html.xpath(xpath)\n",
    "    # print (titles)\n",
    "    xpath = '/html/body/div/div/div/div[4]/div/div[2]/ul/li/a[1]/@href'\n",
    "    links = html.xpath(xpath)\n",
    "    ## !!!!!\n",
    "    links = [ base_url + '/zfgg/' + str(x) for x in links]\n",
    "    # print (links)\n",
    "    xpath = '/html/body/div/div/div/div[4]/div/div[2]/ul/li/span/text()'\n",
    "    dates = html.xpath(xpath)\n",
    "    # print (dates) \n",
    "    data_china = data_china + [ (t, l, d, 'china') for t, l, d in zip(titles, links, dates) ]\n",
    "    \n",
    "    response = requests.get(base_url + '/gztz/index.htm', headers=headers)\n",
    "    text = str(response.content, 'utf-8')\n",
    "    html = etree.HTML(text)\n",
    "    xpath = '/html/body/div/div/div/div[4]/div/div[2]/ul/li/a[1]/text()'\n",
    "    titles = html.xpath(xpath)\n",
    "    # print (titles)\n",
    "    xpath = '/html/body/div/div/div/div[4]/div/div[2]/ul/li/a[1]/@href'\n",
    "    links = html.xpath(xpath)\n",
    "    ## !!!!!\n",
    "    links = [ base_url + '/gztz/' + str(x) for x in links]\n",
    "    # print (links)\n",
    "    xpath = '/html/body/div/div/div/div[4]/div/div[2]/ul/li/span/text()'\n",
    "    dates = html.xpath(xpath)\n",
    "    # print (dates) \n",
    "    data_china = data_china + [ (t, l, d, 'china') for t, l, d in zip(titles, links, dates) ]\n",
    "    \n",
    "    \n",
    "    dict_china = [{'pos':x[3], 'title': x[0], 'link': x[1], 'date': x[2]} for x in data_china]\n",
    "  \n",
    "    print (len(dict_china))\n",
    "\n",
    "    print ('In {}, end, date is {}'.format(get_zscqj_china.__name__, time.strftime('%Y-%m-%d-%H:%M', time.localtime(time.time()))))\n",
    "\n",
    "    return dict_china"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-03T15:42:59.028837Z",
     "start_time": "2018-08-03T15:42:59.012490Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_zscqj_jiangsu():\n",
    "\n",
    "    print ('In {}, begin, date is {}'.format(get_zscqj_jiangsu.__name__, time.strftime('%Y-%m-%d-%H:%M', time.localtime(time.time()))))\n",
    "\n",
    "    base_url = 'http://jsip.jiangsu.gov.cn'\n",
    "    \n",
    "    response = requests.get(base_url + '/col/col3300/index.html', headers=headers)\n",
    "    text = str(response.content, 'utf-8')\n",
    "#     print (text)\n",
    "    regex = re.compile('<a href=\"(.*)\" TARGET=\"_blank\" >.*<div class=\"text\">(.*)</div>.*<div class=\"text-date\">(.*)</div>.*</a>')\n",
    "    data_jiangsu = [(x[1], base_url+x[0], x[2], 'jiangsu') for x in re.findall(pattern=regex, string=text)]\n",
    "    \n",
    "    response = requests.get(base_url + '/col/col3252/index.html', headers=headers)\n",
    "    text = str(response.content, 'utf-8')\n",
    "    regex = re.compile('<a href=\"(.*)\" TARGET=\"_blank\" >.*<div class=\"text\">(.*)</div>.*<div class=\"text-date\">(.*)</div>.*</a>')\n",
    "    data_jiangsu += [(x[1], base_url+x[0], x[2], 'jiangsu') for x in re.findall(pattern=regex, string=text)]\n",
    "    \n",
    "    dict_jiangsu = [{'pos':x[3], 'title': x[0], 'link': x[1], 'date': x[2]} for x in data_jiangsu]\n",
    "    \n",
    "    print (len(dict_jiangsu))\n",
    "\n",
    "    print ('In {}, end, date is {}'.format(get_zscqj_jiangsu.__name__, time.strftime('%Y-%m-%d-%H:%M', time.localtime(time.time()))))\n",
    "\n",
    "    return dict_jiangsu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-03T16:50:51.142397Z",
     "start_time": "2018-08-03T16:50:51.123326Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_zscqj_zhejiang():\n",
    "\n",
    "    print ('In {}, begin, date is {}'.format(get_zscqj_zhejiang.__name__, time.strftime('%Y-%m-%d-%H:%M', time.localtime(time.time()))))\n",
    "\n",
    "    base_url = 'http://www.zjpat.gov.cn'\n",
    "    \n",
    "    response = requests.get(base_url + '/interIndex.do?method=list22&dir=/zjszscqj/tzgg', headers=headers)\n",
    "    text = str(response.content, 'utf-8').replace('\\r\\n', '')\n",
    "    text = re.sub(' +', ' ', text)\n",
    "\n",
    "    regex = re.compile('<a href=\"(.*?)\" title=\"(.*?)\" target=\"_blank\" class=\"color_01\">.*?</a> </td> <td.*?> \\((.*?)\\) </td> </tr>')\n",
    "    data_zhejiang = [(x[1], base_url+'/'+x[0], x[2], 'zhejiang') for x in re.findall(pattern=regex, string=text)[1:]]\n",
    "    \n",
    "    response = requests.get(base_url + '/interIndex.do?method=list2&dir=/zjszscqj/xwdt/sxdt', headers=headers)\n",
    "    text = str(response.content, 'utf-8').replace('\\r\\n', '')\n",
    "    text = re.sub(' +', ' ', text)\n",
    "    regex = re.compile('<a href=\"(.*?)\" title=\"(.*?)\" target=\"_blank\" class=\"color_01\">.*?</a> </td> <td.*?> \\((.*?)\\) </td> </tr>')\n",
    "    data_zhejiang += [(x[1], base_url+'/'+x[0], x[2], 'zhejiang') for x in re.findall(pattern=regex, string=text)[1:]]\n",
    "    \n",
    "    dict_zhejiang = [{'pos':x[3], 'title': x[0], 'link': x[1], 'date': x[2]} for x in data_zhejiang]\n",
    "    \n",
    "    print (len(dict_zhejiang))\n",
    "    \n",
    "    print ('In {}, end, date is {}'.format(get_zscqj_zhejiang.__name__, time.strftime('%Y-%m-%d-%H:%M', time.localtime(time.time()))))\n",
    "\n",
    "    return dict_zhejiang\n",
    "\n",
    "### Very/interIndex.do?method=list2&dir=/zjszscqj/xwdt/sxdt Important to match \\r\\n...\n",
    "### re.findall(pattern='<table>([\\s\\S]*?)<\\/table>', string=text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-03T17:25:36.756752Z",
     "start_time": "2018-08-03T17:25:36.744612Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_zscqj_guangdong():\n",
    "\n",
    "    print ('In {}, begin, date is {}'.format(get_zscqj_guangdong.__name__, time.strftime('%Y-%m-%d-%H:%M', time.localtime(time.time()))))\n",
    "\n",
    "    base_url = 'http://www.gdipo.gov.cn'\n",
    "    \n",
    "    response = requests.get(base_url + '/gdipo/gdipodt/list.shtml', headers=headers)\n",
    "    text = str(response.content, 'utf-8').replace('\\r\\n', '')\n",
    "    text = re.sub(' +', ' ', text)\n",
    "    regex = re.compile('<li> <a href=\"(.*?)\" target=\"_blank\" >(.*?)</a> <div class=\"time_div\"> <span class=\"time\">(.*?)</span> </div> </li>')\n",
    "    data_guangdong = [(x[1], base_url+x[0], x[2], 'guangdong') for x in re.findall(pattern=regex, string=text)]\n",
    "\n",
    "    response = requests.get(base_url + '/gdipo/tzgg/list.shtml', headers=headers)\n",
    "    text = str(response.content, 'utf-8').replace('\\r\\n', '')\n",
    "    text = re.sub(' +', ' ', text)\n",
    "    regex = re.compile('<li> <a href=\"(.*?)\" target=\"_blank\" >(.*?)</a> <div class=\"time_div\"> <span class=\"time\">(.*?)</span> </div> </li>')\n",
    "    data_guangdong += [(x[1], base_url+x[0], x[2], 'guangdong') for x in re.findall(pattern=regex, string=text)]\n",
    "   \n",
    "    dict_guangdong = [{'pos':x[3], 'title': x[0], 'link': x[1], 'date': x[2]} for x in data_guangdong]\n",
    "    \n",
    "    print (len(dict_guangdong))\n",
    "    \n",
    "    print ('In {}, end, date is {}'.format(get_zscqj_guangdong.__name__, time.strftime('%Y-%m-%d-%H:%M', time.localtime(time.time()))))\n",
    "\n",
    "    return dict_guangdong\n",
    "\n",
    "### Very/interIndex.do?method=list2&dir=/zjszscqj/xwdt/sxdt Important to match \\r\\n...\n",
    "### re.findall(pattern='<table>([\\s\\S]*?)<\\/table>', string=text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-03T17:29:38.852041Z",
     "start_time": "2018-08-03T17:29:38.835717Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_zscqj():\n",
    "    db = pymysql.connect(host='119.29.190.115', user='impulse', password='njuacmicpc', port=3306, db='gov')\n",
    "    cursor = db.cursor()\n",
    "    for dic in get_zscqj_china():\n",
    "        sql_insert(db=db,cursor=cursor,data=dic,table='zscqj')\n",
    "    for dic in get_zscqj_jiangsu():\n",
    "        sql_insert(db=db,cursor=cursor,data=dic,table='zscqj')\n",
    "    for dic in get_zscqj_guangdong():\n",
    "        sql_insert(db=db,cursor=cursor,data=dic,table='zscqj')\n",
    "    for dic in get_zscqj_zhejiang():\n",
    "        sql_insert(db=db,cursor=cursor,data=dic,table='zscqj')\n",
    "    db.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
