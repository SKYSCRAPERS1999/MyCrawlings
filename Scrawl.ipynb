{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-03T13:02:17.555419Z",
     "start_time": "2018-08-03T13:02:17.550757Z"
    }
   },
   "outputs": [],
   "source": [
    "def request_view(response):\n",
    "    import webbrowser\n",
    "    request_url = response.url\n",
    "    base_url = '<head><base href=\"%s\">'%(request_url)\n",
    "    base_url = base_url.encode()\n",
    "    content = response.content.replace(b\"<head>\", base_url)\n",
    "    tem_html = open(\"tmp.html\", \"wb\")\n",
    "    tem_html.write(content)\n",
    "    tem_html.close()\n",
    "    webbrowser.open_new_tab(\"tmp.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "response = requests.get(\"http://m.qiubaichengren.net/\")\n",
    "request_view(response)\n",
    "# print (response.status_code, response.content.decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import etree\n",
    "html = etree.HTML(response.content)\n",
    "# html.xpath(\"//div[@class='page']//a[contains(text(),'下一页')]/@href\")\n",
    "html.xpath(\"//li[@class='next']/i/a/@href\")\n",
    "# from bs4 import BeautifulSoup\n",
    "# soup = BeautifulSoup(response.content, 'html.parser')\n",
    "# print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from time import sleep\n",
    "host = \"http://m.qiubaichengren.net/\"\n",
    "def test_all_links(url):\n",
    "    response = requests.get(url)\n",
    "    print(url, response.status_code)\n",
    "    from lxml import etree\n",
    "    html = etree.HTML(response.content)\n",
    "    links = html.xpath(\"//li[@class='next']/i/a/@href\")\n",
    "    if len(links) == 0:\n",
    "        pass\n",
    "    else:\n",
    "        sleep(1)\n",
    "        test_all_links(host + links[0])\n",
    "        \n",
    "test_all_links(\"http://m.qiubaichengren.net/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from lxml import etree\n",
    "\n",
    "class Login(object):\n",
    "    def __init__(self):\n",
    "        self.headers = {\n",
    "            'Referer': 'https://github.com/',\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/57.0.2987.133 Safari/537.36',\n",
    "            'Host': 'github.com'\n",
    "        }\n",
    "        self.login_url = 'https://github.com/login'\n",
    "        self.post_url = 'https://github.com/session'\n",
    "        self.logined_url = 'https://github.com/settings/profile'\n",
    "        self.session = requests.Session()\n",
    "\n",
    "    def token(self):\n",
    "        response = self.session.get(self.login_url, headers = self.headers)\n",
    "        selector = etree.HTML(response.text)\n",
    "        token = selector.xpath('//*[@id=\"login\"]/form/input[2]/@value')\n",
    "        return token\n",
    "    \n",
    "    def login(self, email, password):\n",
    "        post_data = {\n",
    "            'commit': 'Sign in',\n",
    "            'utf8': '✓',\n",
    "            'authenticity_token': self.token(),\n",
    "            'login': email,\n",
    "            'password': password\n",
    "        }\n",
    "        response = self.session.post(self.post_url, data=post_data, headers=self.headers)\n",
    "        print (response.status_code)\n",
    "        if response.status_code == 200:\n",
    "            print ('ok1')\n",
    "            self.dynamics(response.text)\n",
    "        \n",
    "        response = self.session.get(self.logined_url, headers=self.headers)\n",
    "        if response.status_code == 200:\n",
    "            print ('ok2')\n",
    "            self.profile(response.text)\n",
    "            \n",
    "    def dynamics(self, html):\n",
    "        selector = etree.HTML(html)\n",
    "        dynamics = selector.xpath('//div[contains(@class, \"news\")]//div[contains(@class, \"alert\")]')\n",
    "        for item in dynamics:\n",
    "            dynamic = ' '.join(item.xpath('.//div[@class=\"title\"]//text()')).strip()\n",
    "            print(dynamic)\n",
    "    \n",
    "    def profile(self, html):\n",
    "        selector = etree.HTML(html)\n",
    "        name = selector.xpath('//input[@id=\"user_profile_name\"]/@value')\n",
    "        email = selector.xpath('//select[@id=\"user_profile_email\"]/option[@value!=\"\"]/text()')\n",
    "        print(name, email)\n",
    "        \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    login = Login()\n",
    "    login.login(email='386333667@qq.com', password='zhzh995=')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from lxml import etree\n",
    "\n",
    "class Login(object):\n",
    "    def __init__(self):\n",
    "        self.headers = {\n",
    "            'Referer': 'https://github.com/',\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/57.0.2987.133 Safari/537.36',\n",
    "            'Host': 'github.com'\n",
    "        }\n",
    "        self.login_url = 'https://github.com/login'\n",
    "        self.post_url = 'https://github.com/session'\n",
    "        self.logined_url = 'https://github.com/settings/profile'\n",
    "        self.session = requests.Session()\n",
    "    \n",
    "    def token(self):\n",
    "        response = self.session.get(self.login_url, headers=self.headers)\n",
    "        selector = etree.HTML(response.text)\n",
    "        token = selector.xpath('//div//input[2]/@value')\n",
    "        return token\n",
    "    \n",
    "    def login(self, email, password):\n",
    "        post_data = {\n",
    "            'commit': 'Sign in',\n",
    "            'utf8': '✓',\n",
    "            'authenticity_token': self.token()[0],\n",
    "            'login': email,\n",
    "            'password': password\n",
    "        }\n",
    "        response = self.session.post(self.post_url, data=post_data, headers=self.headers)\n",
    "        if response.status_code == 200:\n",
    "            self.dynamics(response.text)\n",
    "        \n",
    "        response = self.session.get(self.logined_url, headers=self.headers)\n",
    "        if response.status_code == 200:\n",
    "            self.profile(response.text)\n",
    "    \n",
    "    def dynamics(self, html):\n",
    "        selector = etree.HTML(html)\n",
    "        dynamics = selector.xpath('//div[contains(@class, \"news\")]//div[contains(@class, \"alert\")]')\n",
    "        for item in dynamics:\n",
    "            dynamic = ' '.join(item.xpath('.//div[@class=\"title\"]//text()')).strip()\n",
    "            print(dynamic)\n",
    "    \n",
    "    def profile(self, html):\n",
    "        selector = etree.HTML(html)\n",
    "        name = selector.xpath('//input[@id=\"user_profile_name\"]/@value')[0]\n",
    "        email = selector.xpath('//select[@id=\"user_profile_email\"]/option[@value!=\"\"]/text()')\n",
    "        print(name, email)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    login = Login()\n",
    "    login.login(email='386333667@qq.com', password='zhzh995=')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "browser = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T03:09:54.134701Z",
     "start_time": "2018-07-31T03:09:54.082773Z"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "math.isnan('nan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T04:02:51.076181Z",
     "start_time": "2018-07-31T04:02:51.073092Z"
    }
   },
   "outputs": [],
   "source": [
    "print(float(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-01T05:17:07.147181Z",
     "start_time": "2018-08-01T05:17:07.135631Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('Documents/Codeforces/Muli4/output.txt') as fp:\n",
    "    for expr in fp:\n",
    "        if (expr != 'IMPOSSIBLE' and expr != None):\n",
    "            x = eval(expr)\n",
    "            print (x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-02T04:34:17.059260Z",
     "start_time": "2018-08-02T04:34:17.049010Z"
    }
   },
   "outputs": [],
   "source": [
    "ans = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-08-02T04:34:30.582Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(100000):\n",
    "    for j in range(i*i+1, (i+1)*(i+1)):\n",
    "        if (i*i*i*i % j == 0):\n",
    "            ans.append(i)\n",
    "            break\n",
    "print (ans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goverment Datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-03T17:26:59.461002Z",
     "start_time": "2018-08-03T17:26:59.449715Z"
    }
   },
   "outputs": [],
   "source": [
    "from lxml import etree\n",
    "import requests, re, time\n",
    "from bs4 import BeautifulSoup\n",
    "headers = {\n",
    "    'User-Agent':'Mozilla/5.0 (Windows; U; Windows NT 6.1; en-US; rv:1.9.1.6) Gecko/20091201 Firefox/3.5.6'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-03T03:39:31.427400Z",
     "start_time": "2018-08-03T03:39:31.421117Z"
    }
   },
   "source": [
    "## ShangWuBu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### China"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-03T17:32:30.977331Z",
     "start_time": "2018-08-03T17:32:30.962305Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_swb_china():\n",
    "    print ('In {}, begin, date is {}'.format(get_swb_china.__name__, time.strftime('%Y-%m-%d-%H:%M', time.localtime(time.time()))))\n",
    "        \n",
    "    base_url = 'http://www.mofcom.gov.cn'\n",
    "    response = requests.get(base_url + '/article/zhengcejd/', headers=headers)\n",
    "    if (response.status_code != 200):\n",
    "        return None\n",
    "    text = str(response.content, 'utf-8')\n",
    "    html = etree.HTML(text)\n",
    "    xpath = '//*[@id=\"wrap\"]/div[2]/div/div[1]/div[2]/ul/li/a[1]/text()'\n",
    "    titles = html.xpath(xpath)\n",
    "    # print (titles)\n",
    "    xpath = '//*[@id=\"wrap\"]/div[2]/div/div[1]/div[2]/ul/li/a[1]/@href'\n",
    "    links = html.xpath(xpath)\n",
    "    # print (links)\n",
    "    xpath = '//*[@id=\"wrap\"]/div[2]/div/div[1]/div[2]/ul/li/span/text()'\n",
    "    dates = html.xpath(xpath)\n",
    "    # print (dates)\n",
    "    data_china = [ (t, l, d, 'china') for (t, l, d) in zip(titles, links, dates) ]\n",
    "\n",
    "    response = requests.get(base_url + '/article/b/', headers=headers)\n",
    "    if (response.status_code != 200):\n",
    "        return None\n",
    "    text = str(response.content, 'utf-8')\n",
    "    html = etree.HTML(text)\n",
    "    xpath = '//*[@id=\"wrap\"]/div[2]/div/div[1]/div[2]/ul/li/a/text()'\n",
    "    titles = html.xpath(xpath)\n",
    "    xpath = '//*[@id=\"wrap\"]/div[2]/div/div[1]/div[2]/ul/li/a/@href'\n",
    "    links = html.xpath(xpath)\n",
    "    links = [ base_url + str(x) for x in links]\n",
    "    xpath = '//*[@id=\"wrap\"]/div[2]/div/div[1]/div[2]/ul/li/span/text()'\n",
    "    dates = html.xpath(xpath)\n",
    "\n",
    "    data_china = data_china + [ (t, l, d, 'china') for t, l, d in zip(titles, links, dates) ]\n",
    "\n",
    "    dict_china = [{'pos':x[3], 'title': x[0], 'link': x[1], 'date': x[2]} for x in data_china]\n",
    "  \n",
    "    print (len(dict_china))\n",
    "\n",
    "    print ('In {}, end, date is {}'.format(get_swb_china.__name__, time.strftime('%Y-%m-%d-%H:%M', time.localtime(time.time()))))\n",
    "\n",
    "    return dict_china"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-03T03:39:51.363515Z",
     "start_time": "2018-08-03T03:39:51.354055Z"
    }
   },
   "source": [
    "### JiangSu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-03T17:32:20.833790Z",
     "start_time": "2018-08-03T17:32:20.820300Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_swb_jiangsu():\n",
    "    \n",
    "    print ('In {}, begin, date is {}'.format(get_swb_jiangsu.__name__, time.strftime('%Y-%m-%d-%H:%M', time.localtime(time.time()))))\n",
    "\n",
    "    base_url = 'http://swt.jiangsu.gov.cn'\n",
    "    response = requests.get(base_url + '/col/col12660/index.html', headers=headers)\n",
    "    if (response.status_code != 200):\n",
    "        return None\n",
    "    text = str(response.content, 'utf-8')\n",
    "    # print (text)\n",
    "    regex = re.compile('<a href=\"(.*)\" target=\"_blank\">(.*)</a><span style=\".*\"> \\((.*)\\)</span>')\n",
    "\n",
    "    data_jiangsu = [(x[1], base_url+x[0], x[2].replace('/', '-'), 'jiangsu') for x in re.findall(pattern=regex, string=text)]\n",
    "    \n",
    "    dict_jiangsu = [{'pos':x[3], 'title': x[0], 'link': x[1], 'date': x[2]} for x in data_jiangsu]\n",
    "    \n",
    "    print (len(dict_jiangsu))\n",
    "    \n",
    "    print ('In {}, end, date is {}'.format(get_swb_jiangsu.__name__, time.strftime('%Y-%m-%d-%H:%M', time.localtime(time.time()))))\n",
    "\n",
    "    return dict_jiangsu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ZheJiang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-03T17:32:15.104636Z",
     "start_time": "2018-08-03T17:32:15.089498Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_swb_zhejiang():\n",
    "    \n",
    "    print ('In {}, begin, date is {}'.format(get_swb_zhejiang.__name__, time.strftime('%Y-%m-%d-%H:%M', time.localtime(time.time()))))\n",
    "\n",
    "    base_url = 'http://zhejiang.mofcom.gov.cn'\n",
    "    response = requests.get(base_url + '/article/sjtongzhigg', headers=headers)\n",
    "    if (response.status_code != 200):\n",
    "        return None\n",
    "    text = str(response.content, 'utf-8')\n",
    "    html = etree.HTML(text)\n",
    "    xpath = '//*[@id=\"main\"]/div[2]/div/ul/li/a/text()'\n",
    "    titles = html.xpath(xpath)\n",
    "    xpath = '//*[@id=\"main\"]/div[2]/div/ul/li/a/@href'\n",
    "    links = html.xpath(xpath)\n",
    "    links = [ base_url + str(x) for x in links]\n",
    "    xpath = '//*[@id=\"main\"]/div[2]/div/ul/li/span/text()'\n",
    "    dates = html.xpath(xpath)\n",
    "    dates = [x.split()[0] for x in dates]\n",
    "\n",
    "    data_zhejiang = [ (t, l, d, 'zhejiang') for t, l, d in zip(titles, links, dates) ]\n",
    "    \n",
    "    dict_zhejiang = [{'pos':x[3], 'title': x[0], 'link': x[1], 'date': x[2]} for x in data_zhejiang]\n",
    "    \n",
    "    print (len(dict_zhejiang))\n",
    "\n",
    "    print ('In {}, end, date is {}'.format(get_swb_zhejiang.__name__, time.strftime('%Y-%m-%d-%H:%M', time.localtime(time.time()))))\n",
    "\n",
    "    return dict_zhejiang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GuangDong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-03T17:32:10.282057Z",
     "start_time": "2018-08-03T17:32:10.264332Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_swb_guangdong():\n",
    "    \n",
    "    print ('In {}, begin, date is {}'.format(get_swb_guangdong.__name__, time.strftime('%Y-%m-%d-%H:%M', time.localtime(time.time()))))\n",
    "\n",
    "    base_url = 'http://www.gdcom.gov.cn/zwgk/zcwj/'\n",
    "    response = requests.get(base_url, headers=headers)\n",
    "    if (response.status_code != 200):\n",
    "        return None\n",
    "\n",
    "    text = str(response.content, 'utf-8')\n",
    "    html = etree.HTML(text)\n",
    "    xpath = '/html/body/div[2]/div/div[2]/ul/li/a/text()'\n",
    "    titles = html.xpath(xpath)\n",
    "    xpath = '/html/body/div[2]/div/div[2]/ul/li/a/@href'\n",
    "    links = html.xpath(xpath)\n",
    "    tlinks = []\n",
    "    for x in links:\n",
    "        x = str(x)\n",
    "        if x != None and x[:2] == './':\n",
    "            x = base_url + x[2:]\n",
    "        tlinks.append(x)\n",
    "    links = tlinks\n",
    "    \n",
    "    xpath = '/html/body/div[2]/div/div[2]/ul/li/span/text()'\n",
    "    dates = html.xpath(xpath)\n",
    "    dates = [x.replace(' ', '') for x in dates]\n",
    "    \n",
    "    data_guangdong = [ (t, l, d, 'guangdong') for t, l, d in zip(titles, links, dates) ]\n",
    "        \n",
    "    dict_guangdong = [{'pos':x[3], 'title': x[0], 'link': x[1], 'date': x[2]} for x in data_guangdong]\n",
    "    \n",
    "    print (len(dict_guangdong))\n",
    "\n",
    "    print ('In {}, end, date is {}'.format(get_swb_guangdong.__name__, time.strftime('%Y-%m-%d-%H:%M', time.localtime(time.time()))))\n",
    "\n",
    "    return dict_guangdong"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Mysql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mysql Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-03T12:42:24.013269Z",
     "start_time": "2018-08-03T12:42:24.010302Z"
    }
   },
   "outputs": [],
   "source": [
    "import pymysql\n",
    "# db = pymysql.connect(host='119.29.190.115', user='impulse', password='njuacmicpc', port=3306)\n",
    "# cursor = db.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-03T12:41:00.053500Z",
     "start_time": "2018-08-03T12:41:00.049982Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_db(cursor, name):\n",
    "    sql = 'create database {name} default character set utf8'.format(name=name)\n",
    "    cursor.execute(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-03T18:21:51.133212Z",
     "start_time": "2018-08-03T18:21:50.654507Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Create table!!!\n",
    "# import pymysql\n",
    "# db = pymysql.connect(host='119.29.190.115', user='impulse', password='njuacmicpc', port=3306, db='gov')\n",
    "# cursor = db.cursor()\n",
    "# sql = 'create table if not exists nyj (pos VARCHAR(32), title VARCHAR(512), link VARCHAR(512), date VARCHAR(64), PRIMARY KEY (link))'\n",
    "# cursor.execute(sql)\n",
    "# db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-03T12:42:42.249024Z",
     "start_time": "2018-08-03T12:42:42.239388Z"
    }
   },
   "outputs": [],
   "source": [
    "def sql_insert(db, cursor, table, data):\n",
    "    keys = ', '.join(data.keys())\n",
    "    values = ', '.join(['%s'] * len(data))\n",
    "    sql = 'insert into {table}({keys}) values ({values}) on duplicate key update'.format(table=table, \n",
    "            keys=keys, values=values)\n",
    "    update = ','.join([\" {key} = %s\".format(key=key) for key in data])\n",
    "    sql += update\n",
    "    #print (sql)\n",
    "    try:\n",
    "        if cursor.execute(sql, tuple(data.values())*2):\n",
    "            print('Successful')\n",
    "            db.commit()\n",
    "        else:\n",
    "            print ('Nothing to do')\n",
    "    except:\n",
    "        print ('Failed')\n",
    "        db.rollback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-03T17:34:19.154834Z",
     "start_time": "2018-08-03T17:34:19.136321Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_swb():\n",
    "    db = pymysql.connect(host='119.29.190.115', user='impulse', password='njuacmicpc', port=3306, db='gov')\n",
    "    cursor = db.cursor()\n",
    "    for dic in get_swb_china():\n",
    "        sql_insert(db=db,cursor=cursor,data=dic,table='swb')\n",
    "    for dic in get_swb_jiangsu():\n",
    "        sql_insert(db=db,cursor=cursor,data=dic,table='swb')\n",
    "    for dic in get_swb_guangdong():\n",
    "        sql_insert(db=db,cursor=cursor,data=dic,table='swb')\n",
    "    for dic in get_swb_zhejiang():\n",
    "        sql_insert(db=db,cursor=cursor,data=dic,table='swb')\n",
    "    db.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ShangWuBuWaiMaoSi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-03T17:32:50.928427Z",
     "start_time": "2018-08-03T17:32:50.907944Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_wms_china():\n",
    "    \n",
    "    print ('In {}, begin, date is {}'.format(get_wms_china.__name__, time.strftime('%Y-%m-%d-%H:%M', time.localtime(time.time()))))\n",
    "\n",
    "    base_url = 'http://wms.mofcom.gov.cn'\n",
    "    response = requests.get(base_url + '/article/zcfb/ax/', headers=headers)\n",
    "    if (response.status_code != 200):\n",
    "        return None\n",
    "    text = str(response.content, 'utf-8')\n",
    "    html = etree.HTML(text)\n",
    "    xpath = '//*[@id=\"leftList\"]/div[2]/ul/li/a[1]/text()'\n",
    "    titles = html.xpath(xpath)\n",
    "    # print (titles)\n",
    "    xpath = '//*[@id=\"leftList\"]/div[2]/ul/li/a[1]/@href'\n",
    "    links = html.xpath(xpath)\n",
    "    links = [ base_url + str(x) for x in links]\n",
    "    # print (links)\n",
    "    xpath = '//*[@id=\"leftList\"]/div[2]/ul/li/span/text()'\n",
    "    dates = html.xpath(xpath)\n",
    "    dates = [x.split()[0] for x in dates]\n",
    "    # print (dates)\n",
    "\n",
    "    data_china = [ (t, l, d, 'china') for (t, l, d) in zip(titles, links, dates) ]\n",
    "\n",
    "    response = requests.get(base_url + '/article/zcfb/g/', headers=headers)\n",
    "    if (response.status_code != 200):\n",
    "        return None\n",
    "    text = str(response.content, 'utf-8')\n",
    "    html = etree.HTML(text)\n",
    "    xpath = '//*[@id=\"leftList\"]/div[2]/ul/li/a[1]/text()'\n",
    "    titles = html.xpath(xpath)\n",
    "    xpath = '//*[@id=\"leftList\"]/div[2]/ul/li/a[1]/@href'\n",
    "    links = html.xpath(xpath)\n",
    "    links = [ base_url + str(x) for x in links]\n",
    "    xpath = '//*[@id=\"leftList\"]/div[2]/ul/li/span/text()'\n",
    "    dates = html.xpath(xpath)\n",
    "    dates = [x.split()[0] for x in dates]\n",
    "    \n",
    "    data_china = data_china + [ (t, l, d, 'china') for t, l, d in zip(titles, links, dates) ]\n",
    "\n",
    "    dict_china = [{'pos':x[3], 'title': x[0], 'link': x[1], 'date': x[2]} for x in data_china]\n",
    "  \n",
    "    print (len(dict_china))\n",
    "\n",
    "    print ('In {}, end, date is {}'.format(get_wms_china.__name__, time.strftime('%Y-%m-%d-%H:%M', time.localtime(time.time()))))\n",
    "\n",
    "    return dict_china"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-03T17:32:58.601969Z",
     "start_time": "2018-08-03T17:32:58.594574Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_wms_jiangsu():\n",
    "\n",
    "    print ('In {}, begin, date is {}'.format(get_wms_jiangsu.__name__, time.strftime('%Y-%m-%d-%H:%M', time.localtime(time.time()))))\n",
    "\n",
    "    base_url = 'http://swt.jiangsu.gov.cn'\n",
    "    \n",
    "    response = requests.get(base_url + '/col/col57691/index.html', headers=headers)\n",
    "    if (response.status_code != 200):\n",
    "        return None\n",
    "    text = str(response.content, 'utf-8')\n",
    "    regex = re.compile('<a href=\"(.*)\" target=\"_blank\" .*title=\"(.*)\">.*</a><span.*> \\((.*)\\)</span>')\n",
    "    data_jiangsu = [(x[1], base_url+x[0], x[2].replace('/', '-'), 'jiangsu') for x in re.findall(pattern=regex, string=text)]\n",
    "    \n",
    "    response = requests.get(base_url + '/col/col57692/index.html', headers=headers)\n",
    "    if (response.status_code != 200):\n",
    "        return None\n",
    "    text = str(response.content, 'utf-8')\n",
    "    regex = re.compile('<a href=\"(.*)\" target=\"_blank\" .*title=\"(.*)\">.*</a><span.*> \\((.*)\\)</span>')\n",
    "    data_jiangsu += [(x[1], base_url+x[0], x[2].replace('/', '-'), 'jiangsu') for x in re.findall(pattern=regex, string=text)]\n",
    "    \n",
    "    dict_jiangsu = [{'pos':x[3], 'title': x[0], 'link': x[1], 'date': x[2]} for x in data_jiangsu]\n",
    "    \n",
    "    print (len(dict_jiangsu))\n",
    "\n",
    "    print ('In {}, end, date is {}'.format(get_wms_jiangsu.__name__, time.strftime('%Y-%m-%d-%H:%M', time.localtime(time.time()))))\n",
    "\n",
    "    return dict_jiangsu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-03T17:33:19.343311Z",
     "start_time": "2018-08-03T17:33:19.322444Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_wms_zhejiang():\n",
    "\n",
    "    print ('In {}, begin, date is {}'.format(get_wms_zhejiang.__name__, time.strftime('%Y-%m-%d-%H:%M', time.localtime(time.time()))))\n",
    "\n",
    "    base_url = 'http://www.zcom.gov.cn'\n",
    "    \n",
    "    response = requests.get(base_url + '/col/col1385815/index.html', headers=headers)\n",
    "    if (response.status_code != 200):\n",
    "        return None\n",
    "    text = str(response.content, 'utf-8')\n",
    "\n",
    "    html = etree.HTML(text)\n",
    "    xpath = '//*[@id=\"con_two_2\"]/div[position()>1]/a[1]/text()'\n",
    "    titles = html.xpath(xpath)  \n",
    "    xpath = '//*[@id=\"con_two_2\"]/div[position()>1]/a[1]/@href'\n",
    "    links = html.xpath(xpath)\n",
    "    links = [ base_url + str(x) for x in links]\n",
    "    \n",
    "    xpath = '//*[@id=\"con_two_2\"]/div[position()>1]/a[1]/span/text()'\n",
    "    dates = html.xpath(xpath)\n",
    "    data_zhejiang = [ (t, l, d, 'zhejiang') for t, l, d in zip(titles, links, dates) ]\n",
    "\n",
    "    ################\n",
    "    \n",
    "    xpath = '//*[@id=\"con_three_1\"]/div[position()>1]/a[1]/text()'\n",
    "    titles = html.xpath(xpath)  \n",
    "    xpath = '//*[@id=\"con_three_1\"]/div[position()>1]/a[1]/@href'\n",
    "    links = html.xpath(xpath)\n",
    "    links = [ base_url + str(x) for x in links]\n",
    "    \n",
    "    xpath = '//*[@id=\"con_three_1\"]/div[position()>1]/a[1]/span/text()'\n",
    "    dates = html.xpath(xpath)\n",
    "    data_zhejiang += [ (t, l, d, 'zhejiang') for t, l, d in zip(titles, links, dates) ]\n",
    "    \n",
    "    dict_zhejiang = [{'pos':x[3], 'title': x[0], 'link': x[1], 'date': x[2]} for x in data_zhejiang]\n",
    "  \n",
    "    print (len(dict_zhejiang))\n",
    "\n",
    "    print ('In {}, end, date is {}'.format(get_wms_zhejiang.__name__, time.strftime('%Y-%m-%d-%H:%M', time.localtime(time.time()))))\n",
    "\n",
    "    return dict_zhejiang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-03T17:33:26.713367Z",
     "start_time": "2018-08-03T17:33:26.698182Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_wms_guangdong():\n",
    "    \n",
    "    print ('In {}, begin, date is {}'.format(get_wms_guangdong.__name__, time.strftime('%Y-%m-%d-%H:%M', time.localtime(time.time()))))\n",
    "\n",
    "    base_url = 'http://go.gdcom.gov.cn'\n",
    "    \n",
    "    response = requests.get(base_url + '/article.php?typeid=9', headers=headers)\n",
    "    if (response.status_code != 200):\n",
    "        return None\n",
    "    text = str(response.content, 'utf-8')\n",
    "\n",
    "    html = etree.HTML(text)\n",
    "    xpath = '/html/body/div[3]/div/div[2]/div/div[2]/div[2]/ul/li/h6/a[1]/text()'\n",
    "    titles = html.xpath(xpath)  \n",
    "    xpath = '/html/body/div[3]/div/div[2]/div/div[2]/div[2]/ul/li/h6/a[1]/@href'\n",
    "    links = html.xpath(xpath)\n",
    "    links = [ base_url + '/' + str(x) for x in links]\n",
    "    \n",
    "    xpath = '/html/body/div[3]/div/div[2]/div/div[2]/div[2]/ul/li/h6/small/text()'\n",
    "    dates = html.xpath(xpath)\n",
    "    data_guangdong = [ (t, l, d, 'guangdong') for t, l, d in zip(titles, links, dates) ]\n",
    "\n",
    "    dict_guangdong = [{'pos':x[3], 'title': x[0], 'link': x[1], 'date': x[2]} for x in data_guangdong]\n",
    "  \n",
    "    print (len(dict_guangdong))\n",
    "\n",
    "    print ('In {}, end, date is {}'.format(get_wms_guangdong.__name__, time.strftime('%Y-%m-%d-%H:%M', time.localtime(time.time()))))\n",
    "\n",
    "    return dict_guangdong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-03T17:34:45.999665Z",
     "start_time": "2018-08-03T17:34:45.996059Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_wms():\n",
    "    db = pymysql.connect(host='119.29.190.115', user='impulse', password='njuacmicpc', port=3306, db='gov')\n",
    "    cursor = db.cursor()\n",
    "    for dic in get_wms_china():\n",
    "        sql_insert(db=db,cursor=cursor,data=dic,table='wms')\n",
    "    for dic in get_wms_jiangsu():\n",
    "        sql_insert(db=db,cursor=cursor,data=dic,table='wms')\n",
    "    for dic in get_wms_guangdong():\n",
    "        sql_insert(db=db,cursor=cursor,data=dic,table='wms')\n",
    "    for dic in get_wms_zhejiang():\n",
    "        sql_insert(db=db,cursor=cursor,data=dic,table='wms')\n",
    "    db.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ZhiShiChanQuanJu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-03T17:33:43.983659Z",
     "start_time": "2018-08-03T17:33:43.958623Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_zscqj_china():\n",
    "    \n",
    "    print ('In {}, begin, date is {}'.format(get_zscqj_china.__name__, time.strftime('%Y-%m-%d-%H:%M', time.localtime(time.time()))))\n",
    "\n",
    "    base_url = 'http://www.sipo.gov.cn'\n",
    "    \n",
    "    response = requests.get(base_url + '/gwywj/index.htm', headers=headers)   \n",
    "    if (response.status_code != 200):\n",
    "        return None\n",
    "    text = str(response.content, 'utf-8')\n",
    "    html = etree.HTML(text)\n",
    "    xpath = '/html/body/div/div/div/div[4]/div/div[2]/ul/li/a[1]/text()'\n",
    "    titles = html.xpath(xpath)\n",
    "    # print (titles)\n",
    "    xpath = '/html/body/div/div/div/div[4]/div/div[2]/ul/li/a[1]/@href'\n",
    "    links = html.xpath(xpath)\n",
    "    # print (links)\n",
    "    xpath = '/html/body/div/div/div/div[4]/div/div[2]/ul/li/span/text()'\n",
    "    dates = html.xpath(xpath)\n",
    "    # print (dates)\n",
    "    data_china = [ (t, l, d, 'china') for (t, l, d) in zip(titles, links, dates) ]\n",
    "\n",
    "    response = requests.get(base_url + '/dtxx/index.htm', headers=headers)\n",
    "    if (response.status_code != 200):\n",
    "        return None\n",
    "    text = str(response.content, 'utf-8')\n",
    "    html = etree.HTML(text)\n",
    "    xpath = '/html/body/div/div/div/div[4]/div/div[2]/ul/li/a[1]/text()'\n",
    "    titles = html.xpath(xpath)\n",
    "    # print (titles)\n",
    "    xpath = '/html/body/div/div/div/div[4]/div/div[2]/ul/li/a[1]/@href'\n",
    "    links = html.xpath(xpath)\n",
    "    ## !!!!!\n",
    "    links = [ base_url + '/dtxx/' + str(x) for x in links] \n",
    "    # print (links)\n",
    "    xpath = '/html/body/div/div/div/div[4]/div/div[2]/ul/li/span/text()'\n",
    "    dates = html.xpath(xpath)\n",
    "    # print (dates) \n",
    "    data_china = data_china + [ (t, l, d, 'china') for t, l, d in zip(titles, links, dates) ]\n",
    "\n",
    "    response = requests.get(base_url + '/zfgg/index.htm', headers=headers)\n",
    "    if (response.status_code != 200):\n",
    "        return None\n",
    "    text = str(response.content, 'utf-8')\n",
    "    html = etree.HTML(text)\n",
    "    xpath = '/html/body/div/div/div/div[4]/div/div[2]/ul/li/a[1]/text()'\n",
    "    titles = html.xpath(xpath)\n",
    "    # print (titles)\n",
    "    xpath = '/html/body/div/div/div/div[4]/div/div[2]/ul/li/a[1]/@href'\n",
    "    links = html.xpath(xpath)\n",
    "    ## !!!!!\n",
    "    links = [ base_url + '/zfgg/' + str(x) for x in links]\n",
    "    # print (links)\n",
    "    xpath = '/html/body/div/div/div/div[4]/div/div[2]/ul/li/span/text()'\n",
    "    dates = html.xpath(xpath)\n",
    "    # print (dates) \n",
    "    data_china = data_china + [ (t, l, d, 'china') for t, l, d in zip(titles, links, dates) ]\n",
    "    \n",
    "    response = requests.get(base_url + '/gztz/index.htm', headers=headers)\n",
    "    if (response.status_code != 200):\n",
    "        return None\n",
    "    text = str(response.content, 'utf-8')\n",
    "    html = etree.HTML(text)\n",
    "    xpath = '/html/body/div/div/div/div[4]/div/div[2]/ul/li/a[1]/text()'\n",
    "    titles = html.xpath(xpath)\n",
    "    # print (titles)\n",
    "    xpath = '/html/body/div/div/div/div[4]/div/div[2]/ul/li/a[1]/@href'\n",
    "    links = html.xpath(xpath)\n",
    "    ## !!!!!\n",
    "    links = [ base_url + '/gztz/' + str(x) for x in links]\n",
    "    # print (links)\n",
    "    xpath = '/html/body/div/div/div/div[4]/div/div[2]/ul/li/span/text()'\n",
    "    dates = html.xpath(xpath)\n",
    "    # print (dates) \n",
    "    data_china = data_china + [ (t, l, d, 'china') for t, l, d in zip(titles, links, dates) ]\n",
    "    \n",
    "    \n",
    "    dict_china = [{'pos':x[3], 'title': x[0], 'link': x[1], 'date': x[2]} for x in data_china]\n",
    "  \n",
    "    print (len(dict_china))\n",
    "\n",
    "    print ('In {}, end, date is {}'.format(get_zscqj_china.__name__, time.strftime('%Y-%m-%d-%H:%M', time.localtime(time.time()))))\n",
    "\n",
    "    return dict_china"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-03T15:42:59.028837Z",
     "start_time": "2018-08-03T15:42:59.012490Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_zscqj_jiangsu():\n",
    "\n",
    "    print ('In {}, begin, date is {}'.format(get_zscqj_jiangsu.__name__, time.strftime('%Y-%m-%d-%H:%M', time.localtime(time.time()))))\n",
    "\n",
    "    base_url = 'http://jsip.jiangsu.gov.cn'\n",
    "    \n",
    "    response = requests.get(base_url + '/col/col3300/index.html', headers=headers)\n",
    "    if (response.status_code != 200):\n",
    "        return None\n",
    "    text = str(response.content, 'utf-8')\n",
    "    regex = re.compile('<a href=\"(.*)\" TARGET=\"_blank\" >.*<div class=\"text\">(.*)</div>.*<div class=\"text-date\">(.*)</div>.*</a>')\n",
    "    data_jiangsu = [(x[1], base_url+x[0], x[2], 'jiangsu') for x in re.findall(pattern=regex, string=text)]\n",
    "    \n",
    "    response = requests.get(base_url + '/col/col3252/index.html', headers=headers)\n",
    "    if (response.status_code != 200):\n",
    "        return None\n",
    "    text = str(response.content, 'utf-8')\n",
    "    regex = re.compile('<a href=\"(.*)\" TARGET=\"_blank\" >.*<div class=\"text\">(.*)</div>.*<div class=\"text-date\">(.*)</div>.*</a>')\n",
    "    data_jiangsu += [(x[1], base_url+x[0], x[2], 'jiangsu') for x in re.findall(pattern=regex, string=text)]\n",
    "    \n",
    "    dict_jiangsu = [{'pos':x[3], 'title': x[0], 'link': x[1], 'date': x[2]} for x in data_jiangsu]\n",
    "    \n",
    "    print (len(dict_jiangsu))\n",
    "\n",
    "    print ('In {}, end, date is {}'.format(get_zscqj_jiangsu.__name__, time.strftime('%Y-%m-%d-%H:%M', time.localtime(time.time()))))\n",
    "\n",
    "    return dict_jiangsu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-03T18:02:28.505648Z",
     "start_time": "2018-08-03T18:02:28.485323Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_zscqj_zhejiang():\n",
    "\n",
    "    print ('In {}, begin, date is {}'.format(get_zscqj_zhejiang.__name__, time.strftime('%Y-%m-%d-%H:%M', time.localtime(time.time()))))\n",
    "\n",
    "    base_url = 'http://www.zjpat.gov.cn'\n",
    "    \n",
    "    response = requests.get(base_url + '/interIndex.do?method=list22&dir=/zjszscqj/tzgg', headers=headers)\n",
    "    if (response.status_code != 200):\n",
    "        return None\n",
    "    text = str(response.content, 'utf-8').replace('\\r\\n', '')\n",
    "    text = re.sub(' +', ' ', text)\n",
    "\n",
    "    regex = re.compile('<a href=\"([^>]*?)\" title=\"([^>]*?)\" target=\"_blank\" class=\"color_01\">.*?</a> </td> <td.[^>]*?> \\((.*?)\\) </td> </tr>')\n",
    "    data_zhejiang = [(x[1], base_url+'/'+x[0], x[2], 'zhejiang') for x in re.findall(pattern=regex, string=text)]\n",
    "    \n",
    "    response = requests.get(base_url + '/interIndex.do?method=list2&dir=/zjszscqj/xwdt/sxdt', headers=headers)\n",
    "    if (response.status_code != 200):\n",
    "        return None\n",
    "    text = str(response.content, 'utf-8').replace('\\r\\n', '')\n",
    "    text = re.sub(' +', ' ', text)\n",
    "    regex = re.compile('<a href=\"([^>]*?)\" title=\"([^>]*?)\" target=\"_blank\" class=\"color_01\">.*?</a> </td> <td.[^>]*?> \\((.*?)\\) </td> </tr>')\n",
    "    data_zhejiang += [(x[1], base_url+'/'+x[0], x[2], 'zhejiang') for x in re.findall(pattern=regex, string=text)]\n",
    "    \n",
    "    dict_zhejiang = [{'pos':x[3], 'title': x[0], 'link': x[1], 'date': x[2]} for x in data_zhejiang]\n",
    "    \n",
    "    print (len(dict_zhejiang))\n",
    "    \n",
    "    print ('In {}, end, date is {}'.format(get_zscqj_zhejiang.__name__, time.strftime('%Y-%m-%d-%H:%M', time.localtime(time.time()))))\n",
    "\n",
    "    return dict_zhejiang\n",
    "\n",
    "### Very/interIndex.do?method=list2&dir=/zjszscqj/xwdt/sxdt Important to match \\r\\n...\n",
    "### re.findall(pattern='<table>([\\s\\S]*?)<\\/table>', string=text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-03T18:02:12.699810Z",
     "start_time": "2018-08-03T18:02:12.234833Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In get_zscqj_zhejiang, begin, date is 2018-08-04-02:02\n",
      "30\n",
      "In get_zscqj_zhejiang, end, date is 2018-08-04-02:02\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'pos': 'zhejiang',\n",
       "  'title': '2018年度浙江省专利奖评选候选项目公示 ',\n",
       "  'link': 'http://www.zjpat.gov.cn/interIndex.do?method=draftinfo&draftId=4aeb4c53-64daf034-0164-db25a43b-0003',\n",
       "  'date': '2018-07-27'},\n",
       " {'pos': 'zhejiang',\n",
       "  'title': '关于参加2018年中国国际专利技术与产品交易会的函 ',\n",
       "  'link': 'http://www.zjpat.gov.cn/interIndex.do?method=draftinfo&draftId=4aeb4c53-64daf034-0164-daf034d9-0001',\n",
       "  'date': '2018-07-27'},\n",
       " {'pos': 'zhejiang',\n",
       "  'title': '浙江省知识产权局关于举办全省专利行政执法能力提升培训班的通知 ',\n",
       "  'link': 'http://www.zjpat.gov.cn/interIndex.do?method=draftinfo&draftId=4aeb4c53-648890cf-0164-8890cfec-0001',\n",
       "  'date': '2018-07-11'},\n",
       " {'pos': 'zhejiang',\n",
       "  'title': '关于加快推进2018年度全国专利调查和知识产权服务业统计调查工作（浙江片区）通知 ',\n",
       "  'link': 'http://www.zjpat.gov.cn/interIndex.do?method=draftinfo&draftId=4aeb4c53-646e7089-0164-6e779312-0002',\n",
       "  'date': '2018-07-06'},\n",
       " {'pos': 'zhejiang',\n",
       "  'title': '项目评审专家公示 ',\n",
       "  'link': 'http://www.zjpat.gov.cn/interIndex.do?method=draftinfo&draftId=4aeb4c53-646e7089-0164-6e70898f-0000',\n",
       "  'date': '2018-07-06'},\n",
       " {'pos': 'zhejiang',\n",
       "  'title': '转发关于实施停征和调整部分专利收费期间提前缴费的通知 ',\n",
       "  'link': 'http://www.zjpat.gov.cn/interIndex.do?method=draftinfo&draftId=4aeb4c53-64631e76-0164-631e7684-0000',\n",
       "  'date': '2018-07-04'},\n",
       " {'pos': 'zhejiang',\n",
       "  'title': '转发国务院知识产权战略实施工作部际联席会议办公室关于表彰国家知识产权战略实施工作先进集体和先进个人的决定 ',\n",
       "  'link': 'http://www.zjpat.gov.cn/interIndex.do?method=draftinfo&draftId=4aeb4c53-644a2ffe-0164-4aae87e4-0003',\n",
       "  'date': '2018-06-29'},\n",
       " {'pos': 'zhejiang',\n",
       "  'title': '关于加快推进2018年度全国专利调查和知识产权服务业统计调查工作（浙江片区）通知 ',\n",
       "  'link': 'http://www.zjpat.gov.cn/interIndex.do?method=draftinfo&draftId=4aeb4c53-6434f75b-0164-34f75b45-0001',\n",
       "  'date': '2018-06-25'},\n",
       " {'pos': 'zhejiang',\n",
       "  'title': '关于加快推进2018年度全国专利调查和知识产权服务业统计调查工作（浙江片区）通知 ',\n",
       "  'link': 'http://www.zjpat.gov.cn/interIndex.do?method=draftinfo&draftId=4aeb4c53-640264d9-0164-0264d94d-0001',\n",
       "  'date': '2018-06-15'},\n",
       " {'pos': 'zhejiang',\n",
       "  'title': '关于加快推进2018年度全国专利调查和知识产权服务业统计调查工作（浙江片区）通知 ',\n",
       "  'link': 'http://www.zjpat.gov.cn/interIndex.do?method=draftinfo&draftId=4aeb4c53-63ec68ac-0163-ec68acfc-0001',\n",
       "  'date': '2018-06-11'},\n",
       " {'pos': 'zhejiang',\n",
       "  'title': '浙江省知识产权局关于开展2018年度浙江省专利奖评选工作的通知 ',\n",
       "  'link': 'http://www.zjpat.gov.cn/interIndex.do?method=draftinfo&draftId=4aeb4c53-63d84b3c-0163-d85b0087-0004',\n",
       "  'date': '2018-06-07'},\n",
       " {'pos': 'zhejiang',\n",
       "  'title': '关于举办知识产权保护中心业务培训班的函 ',\n",
       "  'link': 'http://www.zjpat.gov.cn/interIndex.do?method=draftinfo&draftId=4aeb4c53-638aca0f-0163-8b170b75-0007',\n",
       "  'date': '2018-05-23'},\n",
       " {'pos': 'zhejiang',\n",
       "  'title': '关于转发国家知识产权局《关于举办知识产权密集型产业研讨班的通知》 ',\n",
       "  'link': 'http://www.zjpat.gov.cn/interIndex.do?method=draftinfo&draftId=4aeb4c53-638aca0f-0163-8aca0f45-0001',\n",
       "  'date': '2018-05-23'},\n",
       " {'pos': 'zhejiang',\n",
       "  'title': '关于开展2018年度全国专利调查和知识产权服务业统计调查工作（浙江片区）通知 ',\n",
       "  'link': 'http://www.zjpat.gov.cn/interIndex.do?method=draftinfo&draftId=4aeb4c53-635dd6fb-0163-5dd6fbde-0000',\n",
       "  'date': '2018-05-14'},\n",
       " {'pos': 'zhejiang',\n",
       "  'title': '浙江省知识产权局 浙江省司法厅关于开展2018年知识产权宣传巡回演讲活动的通知 ',\n",
       "  'link': 'http://www.zjpat.gov.cn/interIndex.do?method=draftinfo&draftId=4aeb4c53-630b2ba7-0163-0b2ba760-0000',\n",
       "  'date': '2018-04-28'},\n",
       " {'pos': 'zhejiang',\n",
       "  'title': '长兴县经开区举办知识产权宣传巡回演讲专场活动 长兴县',\n",
       "  'link': 'http://www.zjpat.gov.cn/interIndex.do?method=draftinfo&draftId=4aeb4c53-64ea9631-0164-ea963161-0000',\n",
       "  'date': '2018-07-30'},\n",
       " {'pos': 'zhejiang',\n",
       "  'title': '嘉善县举办涉外企业知识产权海外布局与保护培训 嘉善县',\n",
       "  'link': 'http://www.zjpat.gov.cn/interIndex.do?method=draftinfo&draftId=4aeb4c53-64d0d37e-0164-d0d77589-0006',\n",
       "  'date': '2018-07-25'},\n",
       " {'pos': 'zhejiang',\n",
       "  'title': '衢州学院发明专利在浙江科技成果拍卖会上高价成交 衢州市',\n",
       "  'link': 'http://www.zjpat.gov.cn/interIndex.do?method=draftinfo&draftId=4aeb4c53-64d0d37e-0164-d0d5e8fd-0004',\n",
       "  'date': '2018-07-25'},\n",
       " {'pos': 'zhejiang',\n",
       "  'title': '桐乡市举办专利挖掘与撰写实战培训班 桐乡市',\n",
       "  'link': 'http://www.zjpat.gov.cn/interIndex.do?method=draftinfo&draftId=4aeb4c53-64d0d37e-0164-d0d37e85-0000',\n",
       "  'date': '2018-07-25'},\n",
       " {'pos': 'zhejiang',\n",
       "  'title': '永嘉县新增2家国家知识产权优势企业 永嘉县',\n",
       "  'link': 'http://www.zjpat.gov.cn/interIndex.do?method=draftinfo&draftId=4aeb4c53-64d0d37e-0164-d0d7eccc-0007',\n",
       "  'date': '2018-07-24'},\n",
       " {'pos': 'zhejiang',\n",
       "  'title': '青田县科技局开展”双随机一公开”专利执法检查行动 青田县',\n",
       "  'link': 'http://www.zjpat.gov.cn/interIndex.do?method=draftinfo&draftId=4aeb4c53-64d0d37e-0164-d0d700d6-0005',\n",
       "  'date': '2018-07-24'},\n",
       " {'pos': 'zhejiang',\n",
       "  'title': '云和县上半年专利申请授权量创新高 云和县',\n",
       "  'link': 'http://www.zjpat.gov.cn/interIndex.do?method=draftinfo&draftId=4aeb4c53-64d0d37e-0164-d0d426db-0001',\n",
       "  'date': '2018-07-24'},\n",
       " {'pos': 'zhejiang',\n",
       "  'title': '文成县上半年发明专利申请和授权实现优化增长 文成县',\n",
       "  'link': 'http://www.zjpat.gov.cn/interIndex.do?method=draftinfo&draftId=4aeb4c53-64d0d37e-0164-d0d56779-0003',\n",
       "  'date': '2018-07-23'},\n",
       " {'pos': 'zhejiang',\n",
       "  'title': '杭州市余杭区上半年专利工作量质并举稳步推进 余杭区',\n",
       "  'link': 'http://www.zjpat.gov.cn/interIndex.do?method=draftinfo&draftId=4aeb4c53-64d0d37e-0164-d0d4e99e-0002',\n",
       "  'date': '2018-07-23'},\n",
       " {'pos': 'zhejiang',\n",
       "  'title': '湖州市开展打击假冒专利行为专项检查行动 湖州市',\n",
       "  'link': 'http://www.zjpat.gov.cn/interIndex.do?method=draftinfo&draftId=4aeb4c53-6491890b-0164-918a4ead-0002',\n",
       "  'date': '2018-07-13'},\n",
       " {'pos': 'zhejiang',\n",
       "  'title': '温州市知识产权服务园获批成为全国首批知识产权仲裁调解能力建设机构 温州市',\n",
       "  'link': 'http://www.zjpat.gov.cn/interIndex.do?method=draftinfo&draftId=4aeb4c53-6491890b-0164-91899c93-0001',\n",
       "  'date': '2018-07-13'},\n",
       " {'pos': 'zhejiang',\n",
       "  'title': '桐乡市诞生首张专利保险单 桐乡市',\n",
       "  'link': 'http://www.zjpat.gov.cn/interIndex.do?method=draftinfo&draftId=4aeb4c53-6491890b-0164-91890bcd-0000',\n",
       "  'date': '2018-07-13'},\n",
       " {'pos': 'zhejiang',\n",
       "  'title': '嘉善县举办企业高质量专利培育和专利保险业务培训班 嘉善县',\n",
       "  'link': 'http://www.zjpat.gov.cn/interIndex.do?method=draftinfo&draftId=4aeb4c53-6482233a-0164-82246642-0002',\n",
       "  'date': '2018-07-10'},\n",
       " {'pos': 'zhejiang',\n",
       "  'title': '长兴县开展流通领域专利执法专项行动 长兴县科技局',\n",
       "  'link': 'http://www.zjpat.gov.cn/interIndex.do?method=draftinfo&draftId=4aeb4c53-6482233a-0164-82233a26-0000',\n",
       "  'date': '2018-07-10'},\n",
       " {'pos': 'zhejiang',\n",
       "  'title': '湖州市南浔区通过国家知识产权强县工程试点区现场验收 南浔区',\n",
       "  'link': 'http://www.zjpat.gov.cn/interIndex.do?method=draftinfo&draftId=4aeb4c53-6482233a-0164-8223ff99-0001',\n",
       "  'date': '2018-07-09'}]"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_zscqj_zhejiang()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-03T18:02:44.129575Z",
     "start_time": "2018-08-03T18:02:43.599283Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In get_zscqj_zhejiang, begin, date is 2018-08-04-02:02\n",
      "30\n",
      "In get_zscqj_zhejiang, end, date is 2018-08-04-02:02\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'pos': 'zhejiang',\n",
       "  'title': '2018年度浙江省专利奖评选候选项目公示 ',\n",
       "  'link': 'http://www.zjpat.gov.cn/interIndex.do?method=draftinfo&draftId=4aeb4c53-64daf034-0164-db25a43b-0003',\n",
       "  'date': '2018-07-27'},\n",
       " {'pos': 'zhejiang',\n",
       "  'title': '关于参加2018年中国国际专利技术与产品交易会的函 ',\n",
       "  'link': 'http://www.zjpat.gov.cn/interIndex.do?method=draftinfo&draftId=4aeb4c53-64daf034-0164-daf034d9-0001',\n",
       "  'date': '2018-07-27'},\n",
       " {'pos': 'zhejiang',\n",
       "  'title': '浙江省知识产权局关于举办全省专利行政执法能力提升培训班的通知 ',\n",
       "  'link': 'http://www.zjpat.gov.cn/interIndex.do?method=draftinfo&draftId=4aeb4c53-648890cf-0164-8890cfec-0001',\n",
       "  'date': '2018-07-11'},\n",
       " {'pos': 'zhejiang',\n",
       "  'title': '关于加快推进2018年度全国专利调查和知识产权服务业统计调查工作（浙江片区）通知 ',\n",
       "  'link': 'http://www.zjpat.gov.cn/interIndex.do?method=draftinfo&draftId=4aeb4c53-646e7089-0164-6e779312-0002',\n",
       "  'date': '2018-07-06'},\n",
       " {'pos': 'zhejiang',\n",
       "  'title': '项目评审专家公示 ',\n",
       "  'link': 'http://www.zjpat.gov.cn/interIndex.do?method=draftinfo&draftId=4aeb4c53-646e7089-0164-6e70898f-0000',\n",
       "  'date': '2018-07-06'},\n",
       " {'pos': 'zhejiang',\n",
       "  'title': '转发关于实施停征和调整部分专利收费期间提前缴费的通知 ',\n",
       "  'link': 'http://www.zjpat.gov.cn/interIndex.do?method=draftinfo&draftId=4aeb4c53-64631e76-0164-631e7684-0000',\n",
       "  'date': '2018-07-04'},\n",
       " {'pos': 'zhejiang',\n",
       "  'title': '转发国务院知识产权战略实施工作部际联席会议办公室关于表彰国家知识产权战略实施工作先进集体和先进个人的决定 ',\n",
       "  'link': 'http://www.zjpat.gov.cn/interIndex.do?method=draftinfo&draftId=4aeb4c53-644a2ffe-0164-4aae87e4-0003',\n",
       "  'date': '2018-06-29'},\n",
       " {'pos': 'zhejiang',\n",
       "  'title': '关于加快推进2018年度全国专利调查和知识产权服务业统计调查工作（浙江片区）通知 ',\n",
       "  'link': 'http://www.zjpat.gov.cn/interIndex.do?method=draftinfo&draftId=4aeb4c53-6434f75b-0164-34f75b45-0001',\n",
       "  'date': '2018-06-25'},\n",
       " {'pos': 'zhejiang',\n",
       "  'title': '关于加快推进2018年度全国专利调查和知识产权服务业统计调查工作（浙江片区）通知 ',\n",
       "  'link': 'http://www.zjpat.gov.cn/interIndex.do?method=draftinfo&draftId=4aeb4c53-640264d9-0164-0264d94d-0001',\n",
       "  'date': '2018-06-15'},\n",
       " {'pos': 'zhejiang',\n",
       "  'title': '关于加快推进2018年度全国专利调查和知识产权服务业统计调查工作（浙江片区）通知 ',\n",
       "  'link': 'http://www.zjpat.gov.cn/interIndex.do?method=draftinfo&draftId=4aeb4c53-63ec68ac-0163-ec68acfc-0001',\n",
       "  'date': '2018-06-11'},\n",
       " {'pos': 'zhejiang',\n",
       "  'title': '浙江省知识产权局关于开展2018年度浙江省专利奖评选工作的通知 ',\n",
       "  'link': 'http://www.zjpat.gov.cn/interIndex.do?method=draftinfo&draftId=4aeb4c53-63d84b3c-0163-d85b0087-0004',\n",
       "  'date': '2018-06-07'},\n",
       " {'pos': 'zhejiang',\n",
       "  'title': '关于举办知识产权保护中心业务培训班的函 ',\n",
       "  'link': 'http://www.zjpat.gov.cn/interIndex.do?method=draftinfo&draftId=4aeb4c53-638aca0f-0163-8b170b75-0007',\n",
       "  'date': '2018-05-23'},\n",
       " {'pos': 'zhejiang',\n",
       "  'title': '关于转发国家知识产权局《关于举办知识产权密集型产业研讨班的通知》 ',\n",
       "  'link': 'http://www.zjpat.gov.cn/interIndex.do?method=draftinfo&draftId=4aeb4c53-638aca0f-0163-8aca0f45-0001',\n",
       "  'date': '2018-05-23'},\n",
       " {'pos': 'zhejiang',\n",
       "  'title': '关于开展2018年度全国专利调查和知识产权服务业统计调查工作（浙江片区）通知 ',\n",
       "  'link': 'http://www.zjpat.gov.cn/interIndex.do?method=draftinfo&draftId=4aeb4c53-635dd6fb-0163-5dd6fbde-0000',\n",
       "  'date': '2018-05-14'},\n",
       " {'pos': 'zhejiang',\n",
       "  'title': '浙江省知识产权局 浙江省司法厅关于开展2018年知识产权宣传巡回演讲活动的通知 ',\n",
       "  'link': 'http://www.zjpat.gov.cn/interIndex.do?method=draftinfo&draftId=4aeb4c53-630b2ba7-0163-0b2ba760-0000',\n",
       "  'date': '2018-04-28'},\n",
       " {'pos': 'zhejiang',\n",
       "  'title': '长兴县经开区举办知识产权宣传巡回演讲专场活动 长兴县',\n",
       "  'link': 'http://www.zjpat.gov.cn/interIndex.do?method=draftinfo&draftId=4aeb4c53-64ea9631-0164-ea963161-0000',\n",
       "  'date': '2018-07-30'},\n",
       " {'pos': 'zhejiang',\n",
       "  'title': '嘉善县举办涉外企业知识产权海外布局与保护培训 嘉善县',\n",
       "  'link': 'http://www.zjpat.gov.cn/interIndex.do?method=draftinfo&draftId=4aeb4c53-64d0d37e-0164-d0d77589-0006',\n",
       "  'date': '2018-07-25'},\n",
       " {'pos': 'zhejiang',\n",
       "  'title': '衢州学院发明专利在浙江科技成果拍卖会上高价成交 衢州市',\n",
       "  'link': 'http://www.zjpat.gov.cn/interIndex.do?method=draftinfo&draftId=4aeb4c53-64d0d37e-0164-d0d5e8fd-0004',\n",
       "  'date': '2018-07-25'},\n",
       " {'pos': 'zhejiang',\n",
       "  'title': '桐乡市举办专利挖掘与撰写实战培训班 桐乡市',\n",
       "  'link': 'http://www.zjpat.gov.cn/interIndex.do?method=draftinfo&draftId=4aeb4c53-64d0d37e-0164-d0d37e85-0000',\n",
       "  'date': '2018-07-25'},\n",
       " {'pos': 'zhejiang',\n",
       "  'title': '永嘉县新增2家国家知识产权优势企业 永嘉县',\n",
       "  'link': 'http://www.zjpat.gov.cn/interIndex.do?method=draftinfo&draftId=4aeb4c53-64d0d37e-0164-d0d7eccc-0007',\n",
       "  'date': '2018-07-24'},\n",
       " {'pos': 'zhejiang',\n",
       "  'title': '青田县科技局开展”双随机一公开”专利执法检查行动 青田县',\n",
       "  'link': 'http://www.zjpat.gov.cn/interIndex.do?method=draftinfo&draftId=4aeb4c53-64d0d37e-0164-d0d700d6-0005',\n",
       "  'date': '2018-07-24'},\n",
       " {'pos': 'zhejiang',\n",
       "  'title': '云和县上半年专利申请授权量创新高 云和县',\n",
       "  'link': 'http://www.zjpat.gov.cn/interIndex.do?method=draftinfo&draftId=4aeb4c53-64d0d37e-0164-d0d426db-0001',\n",
       "  'date': '2018-07-24'},\n",
       " {'pos': 'zhejiang',\n",
       "  'title': '文成县上半年发明专利申请和授权实现优化增长 文成县',\n",
       "  'link': 'http://www.zjpat.gov.cn/interIndex.do?method=draftinfo&draftId=4aeb4c53-64d0d37e-0164-d0d56779-0003',\n",
       "  'date': '2018-07-23'},\n",
       " {'pos': 'zhejiang',\n",
       "  'title': '杭州市余杭区上半年专利工作量质并举稳步推进 余杭区',\n",
       "  'link': 'http://www.zjpat.gov.cn/interIndex.do?method=draftinfo&draftId=4aeb4c53-64d0d37e-0164-d0d4e99e-0002',\n",
       "  'date': '2018-07-23'},\n",
       " {'pos': 'zhejiang',\n",
       "  'title': '湖州市开展打击假冒专利行为专项检查行动 湖州市',\n",
       "  'link': 'http://www.zjpat.gov.cn/interIndex.do?method=draftinfo&draftId=4aeb4c53-6491890b-0164-918a4ead-0002',\n",
       "  'date': '2018-07-13'},\n",
       " {'pos': 'zhejiang',\n",
       "  'title': '温州市知识产权服务园获批成为全国首批知识产权仲裁调解能力建设机构 温州市',\n",
       "  'link': 'http://www.zjpat.gov.cn/interIndex.do?method=draftinfo&draftId=4aeb4c53-6491890b-0164-91899c93-0001',\n",
       "  'date': '2018-07-13'},\n",
       " {'pos': 'zhejiang',\n",
       "  'title': '桐乡市诞生首张专利保险单 桐乡市',\n",
       "  'link': 'http://www.zjpat.gov.cn/interIndex.do?method=draftinfo&draftId=4aeb4c53-6491890b-0164-91890bcd-0000',\n",
       "  'date': '2018-07-13'},\n",
       " {'pos': 'zhejiang',\n",
       "  'title': '嘉善县举办企业高质量专利培育和专利保险业务培训班 嘉善县',\n",
       "  'link': 'http://www.zjpat.gov.cn/interIndex.do?method=draftinfo&draftId=4aeb4c53-6482233a-0164-82246642-0002',\n",
       "  'date': '2018-07-10'},\n",
       " {'pos': 'zhejiang',\n",
       "  'title': '长兴县开展流通领域专利执法专项行动 长兴县科技局',\n",
       "  'link': 'http://www.zjpat.gov.cn/interIndex.do?method=draftinfo&draftId=4aeb4c53-6482233a-0164-82233a26-0000',\n",
       "  'date': '2018-07-10'},\n",
       " {'pos': 'zhejiang',\n",
       "  'title': '湖州市南浔区通过国家知识产权强县工程试点区现场验收 南浔区',\n",
       "  'link': 'http://www.zjpat.gov.cn/interIndex.do?method=draftinfo&draftId=4aeb4c53-6482233a-0164-8223ff99-0001',\n",
       "  'date': '2018-07-09'}]"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_zscqj_zhejiang()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-03T17:34:06.305042Z",
     "start_time": "2018-08-03T17:34:06.286718Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_zscqj_guangdong():\n",
    "\n",
    "    print ('In {}, begin, date is {}'.format(get_zscqj_guangdong.__name__, time.strftime('%Y-%m-%d-%H:%M', time.localtime(time.time()))))\n",
    "\n",
    "    base_url = 'http://www.gdipo.gov.cn'\n",
    "    \n",
    "    response = requests.get(base_url + '/gdipo/gdipodt/list.shtml', headers=headers)\n",
    "    if (response.status_code != 200):\n",
    "        return None\n",
    "    text = str(response.content, 'utf-8').replace('\\r\\n', '')\n",
    "    text = re.sub(' +', ' ', text)\n",
    "    regex = re.compile('<li> <a href=\"(.*?)\" target=\"_blank\" >(.*?)</a> <div class=\"time_div\"> <span class=\"time\">(.*?)</span> </div> </li>')\n",
    "    data_guangdong = [(x[1], base_url+x[0], x[2], 'guangdong') for x in re.findall(pattern=regex, string=text)]\n",
    "\n",
    "    response = requests.get(base_url + '/gdipo/tzgg/list.shtml', headers=headers)\n",
    "    if (response.status_code != 200):\n",
    "        return None\n",
    "    text = str(response.content, 'utf-8').replace('\\r\\n', '')\n",
    "    text = re.sub(' +', ' ', text)\n",
    "    regex = re.compile('<li> <a href=\"(.*?)\" target=\"_blank\" >(.*?)</a> <div class=\"time_div\"> <span class=\"time\">(.*?)</span> </div> </li>')\n",
    "    data_guangdong += [(x[1], base_url+x[0], x[2], 'guangdong') for x in re.findall(pattern=regex, string=text)]\n",
    "   \n",
    "    dict_guangdong = [{'pos':x[3], 'title': x[0], 'link': x[1], 'date': x[2]} for x in data_guangdong]\n",
    "    \n",
    "    print (len(dict_guangdong))\n",
    "    \n",
    "    print ('In {}, end, date is {}'.format(get_zscqj_guangdong.__name__, time.strftime('%Y-%m-%d-%H:%M', time.localtime(time.time()))))\n",
    "\n",
    "    return dict_guangdong\n",
    "\n",
    "### Very/interIndex.do?method=list2&dir=/zjszscqj/xwdt/sxdt Important to match \\r\\n...\n",
    "### re.findall(pattern='<table>([\\s\\S]*?)<\\/table>', string=text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-03T17:29:38.852041Z",
     "start_time": "2018-08-03T17:29:38.835717Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_zscqj():\n",
    "    db = pymysql.connect(host='119.29.190.115', user='impulse', password='njuacmicpc', port=3306, db='gov')\n",
    "    cursor = db.cursor()\n",
    "    for dic in get_zscqj_china():\n",
    "        sql_insert(db=db,cursor=cursor,data=dic,table='zscqj')\n",
    "    for dic in get_zscqj_jiangsu():\n",
    "        sql_insert(db=db,cursor=cursor,data=dic,table='zscqj')\n",
    "    for dic in get_zscqj_guangdong():\n",
    "        sql_insert(db=db,cursor=cursor,data=dic,table='zscqj')\n",
    "    for dic in get_zscqj_zhejiang():\n",
    "        sql_insert(db=db,cursor=cursor,data=dic,table='zscqj')\n",
    "    db.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-03T17:38:53.331658Z",
     "start_time": "2018-08-03T17:38:53.327137Z"
    }
   },
   "source": [
    "## NengYuanJu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-03T17:44:02.935262Z",
     "start_time": "2018-08-03T17:44:02.919218Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_nyj_china():\n",
    "    print ('In {}, begin, date is {}'.format(get_zscqj_china.__name__, time.strftime('%Y-%m-%d-%H:%M', time.localtime(time.time()))))\n",
    "\n",
    "    base_url = 'http://www.nea.gov.cn'\n",
    "    \n",
    "    response = requests.get(base_url + '/xwzx/nyyw.htm', headers=headers)   \n",
    "    if (response.status_code != 200):\n",
    "        return None\n",
    "    text = str(response.content, 'utf-8')\n",
    "    html = etree.HTML(text)\n",
    "    xpath = '//div[@class=\"content\"]/div/ul/li/a/text()'\n",
    "    titles = html.xpath(xpath)\n",
    "    # print (titles)\n",
    "    xpath = '//div[@class=\"content\"]/div/ul/li/a/@href'\n",
    "    links = html.xpath(xpath)\n",
    "    # print (links)\n",
    "    xpath = '//div[@class=\"content\"]/div/ul/li/span/text()'\n",
    "    dates = html.xpath(xpath)\n",
    "    # print (dates)\n",
    "    data_china = [ (t, l, d, 'china') for (t, l, d) in zip(titles, links, dates) ]\n",
    "    \n",
    "    dict_china = [{'pos':x[3], 'title': x[0], 'link': x[1], 'date': x[2]} for x in data_china]\n",
    "  \n",
    "    print (len(dict_china))\n",
    "    \n",
    "    print ('In {}, end, date is {}'.format(get_zscqj_china.__name__, time.strftime('%Y-%m-%d-%H:%M', time.localtime(time.time()))))\n",
    "\n",
    "    return dict_china"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-03T18:03:26.531252Z",
     "start_time": "2018-08-03T18:03:26.519479Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_nyj_jiangsu():\n",
    "    print ('In {}, begin, date is {}'.format(get_zscqj_jiangsu.__name__, time.strftime('%Y-%m-%d-%H:%M', time.localtime(time.time()))))\n",
    "\n",
    "    base_url = 'http://jsb.nea.gov.cn'\n",
    "    \n",
    "    response = requests.get(base_url + '/info/community/101.html', headers=headers)   \n",
    "    if (response.status_code != 200):\n",
    "        return None\n",
    "    text = str(response.content, 'gbk').replace('\\r\\n', '')\n",
    "    text = re.sub(' +', ' ', text)\n",
    "    html = etree.HTML(text)\n",
    "\n",
    "    regex = re.compile('<a href=\"([^>]*?)\" target=_blank>(.*?)</a></td><td.*?> <p.*?>\\[(.*?)\\] </td>')\n",
    "    data_jiangsu = [(x[1], base_url+x[0], x[2], 'jiangsu') for x in re.findall(pattern=regex, string=text)]\n",
    "    \n",
    "    dict_jiangsu = [{'pos':x[3], 'title': x[0], 'link': x[1], 'date': x[2].replace('/', '-')} for x in data_jiangsu]\n",
    "    \n",
    "    print (len(dict_jiangsu))\n",
    "    \n",
    "    print ('In {}, end, date is {}'.format(get_zscqj_jiangsu.__name__, time.strftime('%Y-%m-%d-%H:%M', time.localtime(time.time()))))\n",
    "\n",
    "    return dict_jiangsu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-03T18:20:05.295184Z",
     "start_time": "2018-08-03T18:20:05.273540Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_nyj_zhejiang():\n",
    "    print ('In {}, begin, date is {}'.format(get_zscqj_zhejiang.__name__, time.strftime('%Y-%m-%d-%H:%M', time.localtime(time.time()))))\n",
    "\n",
    "    base_url = 'http://zjb.nea.gov.cn'\n",
    "\n",
    "    response = requests.get(base_url + '/article/zygg/d1/', headers=headers)   \n",
    "    if (response.status_code != 200):\n",
    "        return None\n",
    "    text = str(response.content, 'gbk')\n",
    "    html = etree.HTML(text)\n",
    "    xpath = '//div[@class=\"d5\"]/a/text()'\n",
    "    titles = html.xpath(xpath)\n",
    "    # print (titles)\n",
    "    xpath = '//div[@class=\"d5\"]/a/@href'\n",
    "    links = html.xpath(xpath)\n",
    "    links = [base_url + x for x in links]\n",
    "    # print (links)\n",
    "    xpath = '//div[@class=\"d5\"]/span/text()'\n",
    "    dates = html.xpath(xpath)\n",
    "    # print (dates)\n",
    "    data_zhejiang = [ (t, l, d, 'zhejiang') for (t, l, d) in zip(titles, links, dates) ]\n",
    "    \n",
    "    response = requests.get(base_url + '/article/ywdd/', headers=headers)   \n",
    "    if (response.status_code != 200):\n",
    "        return None\n",
    "    text = str(response.content, 'gbk')\n",
    "    html = etree.HTML(text)\n",
    "    xpath = '//div[@class=\"d5\"]/a/text()'\n",
    "    titles = html.xpath(xpath)\n",
    "    # print (titles)\n",
    "    xpath = '//div[@class=\"d5\"]/a/@href'\n",
    "    links = html.xpath(xpath)\n",
    "    links = [base_url + x for x in links]\n",
    "    # print (links)\n",
    "    xpath = '//div[@class=\"d5\"]/span/text()'\n",
    "    dates = html.xpath(xpath)\n",
    "    # print (dates)\n",
    "    data_zhejiang += [ (t, l, d, 'zhejiang') for (t, l, d) in zip(titles, links, dates) ]\n",
    "    \n",
    "    dict_zhejiang = [{'pos':x[3], 'title': x[0], 'link': x[1], 'date': x[2]} for x in data_zhejiang]\n",
    "  \n",
    "    print (len(dict_zhejiang))\n",
    "    \n",
    "    print ('In {}, end, date is {}'.format(get_zscqj_zhejiang.__name__, time.strftime('%Y-%m-%d-%H:%M', time.localtime(time.time()))))\n",
    "\n",
    "    return dict_zhejiang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-03T18:22:55.969381Z",
     "start_time": "2018-08-03T18:22:55.953606Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_nyj_guangdong():\n",
    "    ## Infact, it is nyj of southern china\n",
    "    print ('In {}, begin, date is {}'.format(get_nyj_guangdong.__name__, time.strftime('%Y-%m-%d-%H:%M', time.localtime(time.time()))))\n",
    "\n",
    "    base_url = 'http://nfj.nea.gov.cn'\n",
    "    \n",
    "    response = requests.get(base_url + '/frontIndex/showNews.do?type=3', headers=headers)   \n",
    "    if (response.status_code != 200):\n",
    "        return None\n",
    "    text = str(response.content, 'utf-8')\n",
    "    html = etree.HTML(text)\n",
    "    xpath = '//div[@class=\"new_list2\"]/ul/li/a/text()'\n",
    "    titles = html.xpath(xpath)\n",
    "    # print (titles)\n",
    "    xpath = '//div[@class=\"new_list2\"]/ul/li/a/@href'\n",
    "    links = html.xpath(xpath)\n",
    "    # print (links)\n",
    "    xpath = '//div[@class=\"new_list2\"]/ul/li/span/text()'\n",
    "    dates = html.xpath(xpath)\n",
    "    # print (dates)\n",
    "    data_guangdong = [ (t, l, d, 'guangdong') for (t, l, d) in zip(titles, links, dates) ]\n",
    "    \n",
    "    dict_guangdong = [{'pos':x[3], 'title': x[0], 'link': x[1], 'date': x[2]} for x in data_guangdong]\n",
    "    \n",
    "    print (len(dict_guangdong))\n",
    "\n",
    "    print ('In {}, end, date is {}'.format(get_nyj_guangdong.__name__, time.strftime('%Y-%m-%d-%H:%M', time.localtime(time.time()))))\n",
    "\n",
    "    return dict_guangdong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-03T18:22:58.563333Z",
     "start_time": "2018-08-03T18:22:58.558813Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_nyj():\n",
    "    db = pymysql.connect(host='119.29.190.115', user='impulse', password='njuacmicpc', port=3306, db='gov')\n",
    "    cursor = db.cursor()\n",
    "    for dic in get_nyj_china():\n",
    "        sql_insert(db=db,cursor=cursor,data=dic,table='nyj')\n",
    "    for dic in get_nyj_jiangsu():\n",
    "        sql_insert(db=db,cursor=cursor,data=dic,table='nyj')\n",
    "    for dic in get_nyj_guangdong():\n",
    "        sql_insert(db=db,cursor=cursor,data=dic,table='nyj')\n",
    "    for dic in get_nyj_zhejiang():\n",
    "        sql_insert(db=db,cursor=cursor,data=dic,table='nyj')\n",
    "    db.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
