{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-07T06:39:55.147902Z",
     "start_time": "2018-08-07T06:39:55.143608Z"
    }
   },
   "outputs": [],
   "source": [
    "def request_view(response):\n",
    "    import webbrowser\n",
    "    request_url = response.url\n",
    "    base_url = '<head><base href=\"%s\">'%(request_url)\n",
    "    base_url = base_url.encode()\n",
    "    content = response.content.replace(b\"<head>\", base_url)\n",
    "    tem_html = open(\"tmp.html\", \"wb\")\n",
    "    tem_html.write(content)\n",
    "    tem_html.close()\n",
    "    webbrowser.open_new_tab(\"tmp.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-07T07:21:08.720003Z",
     "start_time": "2018-08-07T07:21:08.713574Z"
    }
   },
   "outputs": [],
   "source": [
    "## Mysql Template\n",
    "\n",
    "## Test Mysql\n",
    "\n",
    "import pymysql\n",
    "# db = pymysql.connect(host='119.29.190.115', user='impulse', password='njuacmicpc', port=3306)\n",
    "# cursor = db.cursor()\n",
    "\n",
    "def create_db(cursor, name):\n",
    "    sql = 'create database {name} default character set utf8'.format(name=name)\n",
    "    cursor.execute(sql)\n",
    "\n",
    "def create_table(cursor, name):\n",
    "    sql = 'create table if not exists {} (pos VARCHAR(32), title VARCHAR(512), link VARCHAR(512), date VARCHAR(64), PRIMARY KEY (link))'.format(name)\n",
    "    cursor.execute(sql)\n",
    "\n",
    "def sql_insert(db, cursor, table, data):\n",
    "    keys = ', '.join(data.keys())\n",
    "    values = ', '.join(['%s'] * len(data))\n",
    "    sql = 'insert into {table}({keys}) values ({values}) on duplicate key update'.format(table=table, \n",
    "            keys=keys, values=values)\n",
    "    update = ','.join([\" {key} = %s\".format(key=key) for key in data])\n",
    "    sql += update\n",
    "    #print (sql)\n",
    "    try:\n",
    "        if cursor.execute(sql, tuple(data.values())*2):\n",
    "            print('Successful')\n",
    "            db.commit()\n",
    "        else:\n",
    "            print ('Nothing to do')\n",
    "    except:\n",
    "        print ('Failed')\n",
    "        db.rollback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-07T07:21:09.503214Z",
     "start_time": "2018-08-07T07:21:09.491809Z"
    }
   },
   "outputs": [],
   "source": [
    "# Goverment Datas\n",
    "\n",
    "from lxml import etree\n",
    "import requests, re, time\n",
    "from bs4 import BeautifulSoup\n",
    "headers = {\n",
    "    'User-Agent':'Mozilla/5.0 (Windows; U; Windows NT 6.1; en-US; rv:1.9.1.6) Gecko/20091201 Firefox/3.5.6'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-07T07:21:10.473279Z",
     "start_time": "2018-08-07T07:21:10.401634Z"
    }
   },
   "outputs": [],
   "source": [
    "## ShangWuBu\n",
    "\n",
    "### China\n",
    "\n",
    "def get_swb_china():\n",
    "    print ('In {}, begin, date is {}'.format(get_swb_china.__name__, time.strftime('%Y-%m-%d-%H:%M', time.localtime(time.time()))))\n",
    "        \n",
    "    base_url = 'http://www.mofcom.gov.cn'\n",
    "    response = requests.get(base_url + '/article/zhengcejd/', headers=headers, timeout = 10)\n",
    "    if (response.status_code != 200):\n",
    "        return None\n",
    "    text = str(response.content, 'utf-8')\n",
    "    html = etree.HTML(text)\n",
    "    xpath = '//*[@id=\"wrap\"]/div[2]/div/div[1]/div[2]/ul/li/a[1]/text()'\n",
    "    titles = html.xpath(xpath)\n",
    "    # print (titles)\n",
    "    xpath = '//*[@id=\"wrap\"]/div[2]/div/div[1]/div[2]/ul/li/a[1]/@href'\n",
    "    links = html.xpath(xpath)\n",
    "    # print (links)\n",
    "    xpath = '//*[@id=\"wrap\"]/div[2]/div/div[1]/div[2]/ul/li/span/text()'\n",
    "    dates = html.xpath(xpath)\n",
    "    # print (dates)\n",
    "    data_china = [ (t, l, d, 'china') for (t, l, d) in zip(titles, links, dates) ]\n",
    "\n",
    "    response = requests.get(base_url + '/article/b/', headers=headers, timeout = 10)\n",
    "    if (response.status_code != 200):\n",
    "        return None\n",
    "    text = str(response.content, 'utf-8')\n",
    "    html = etree.HTML(text)\n",
    "    xpath = '//*[@id=\"wrap\"]/div[2]/div/div[1]/div[2]/ul/li/a/text()'\n",
    "    titles = html.xpath(xpath)\n",
    "    xpath = '//*[@id=\"wrap\"]/div[2]/div/div[1]/div[2]/ul/li/a/@href'\n",
    "    links = html.xpath(xpath)\n",
    "    links = [ base_url + str(x) for x in links]\n",
    "    xpath = '//*[@id=\"wrap\"]/div[2]/div/div[1]/div[2]/ul/li/span/text()'\n",
    "    dates = html.xpath(xpath)\n",
    "\n",
    "    data_china = data_china + [ (t, l, d, 'china') for t, l, d in zip(titles, links, dates) ]\n",
    "\n",
    "    dict_china = [{'pos':x[3], 'title': x[0], 'link': x[1], 'date': x[2]} for x in data_china]\n",
    "  \n",
    "    print (len(dict_china))\n",
    "\n",
    "    print ('In {}, end, date is {}'.format(get_swb_china.__name__, time.strftime('%Y-%m-%d-%H:%M', time.localtime(time.time()))))\n",
    "\n",
    "    return dict_china\n",
    "\n",
    "### JiangSu\n",
    "\n",
    "def get_swb_jiangsu():\n",
    "    \n",
    "    print ('In {}, begin, date is {}'.format(get_swb_jiangsu.__name__, time.strftime('%Y-%m-%d-%H:%M', time.localtime(time.time()))))\n",
    "\n",
    "    base_url = 'http://swt.jiangsu.gov.cn'\n",
    "    response = requests.get(base_url + '/col/col12660/index.html', headers=headers, timeout = 10)\n",
    "    if (response.status_code != 200):\n",
    "        return None\n",
    "    text = str(response.content, 'utf-8')\n",
    "    # print (text)\n",
    "    regex = re.compile('<a href=\"(.*)\" target=\"_blank\">(.*)</a><span style=\".*\"> \\((.*)\\)</span>')\n",
    "\n",
    "    data_jiangsu = [(x[1], base_url+x[0], x[2].replace('/', '-'), 'jiangsu') for x in re.findall(pattern=regex, string=text)]\n",
    "    \n",
    "    dict_jiangsu = [{'pos':x[3], 'title': x[0], 'link': x[1], 'date': x[2]} for x in data_jiangsu]\n",
    "    \n",
    "    print (len(dict_jiangsu))\n",
    "    \n",
    "    print ('In {}, end, date is {}'.format(get_swb_jiangsu.__name__, time.strftime('%Y-%m-%d-%H:%M', time.localtime(time.time()))))\n",
    "\n",
    "    return dict_jiangsu\n",
    "\n",
    "## ZheJiang\n",
    "\n",
    "def get_swb_zhejiang():\n",
    "    \n",
    "    print ('In {}, begin, date is {}'.format(get_swb_zhejiang.__name__, time.strftime('%Y-%m-%d-%H:%M', time.localtime(time.time()))))\n",
    "\n",
    "    base_url = 'http://zhejiang.mofcom.gov.cn'\n",
    "    response = requests.get(base_url + '/article/sjtongzhigg', headers=headers, timeout = 10)\n",
    "    if (response.status_code != 200):\n",
    "        return None\n",
    "    text = str(response.content, 'utf-8')\n",
    "    html = etree.HTML(text)\n",
    "    xpath = '//*[@id=\"main\"]/div[2]/div/ul/li/a/text()'\n",
    "    titles = html.xpath(xpath)\n",
    "    xpath = '//*[@id=\"main\"]/div[2]/div/ul/li/a/@href'\n",
    "    links = html.xpath(xpath)\n",
    "    links = [ base_url + str(x) for x in links]\n",
    "    xpath = '//*[@id=\"main\"]/div[2]/div/ul/li/span/text()'\n",
    "    dates = html.xpath(xpath)\n",
    "    dates = [x.split()[0] for x in dates]\n",
    "\n",
    "    data_zhejiang = [ (t, l, d, 'zhejiang') for t, l, d in zip(titles, links, dates) ]\n",
    "    \n",
    "    dict_zhejiang = [{'pos':x[3], 'title': x[0], 'link': x[1], 'date': x[2]} for x in data_zhejiang]\n",
    "    \n",
    "    print (len(dict_zhejiang))\n",
    "\n",
    "    print ('In {}, end, date is {}'.format(get_swb_zhejiang.__name__, time.strftime('%Y-%m-%d-%H:%M', time.localtime(time.time()))))\n",
    "\n",
    "    return dict_zhejiang\n",
    "\n",
    "## GuangDong\n",
    "\n",
    "def get_swb_guangdong():\n",
    "    \n",
    "    print ('In {}, begin, date is {}'.format(get_swb_guangdong.__name__, time.strftime('%Y-%m-%d-%H:%M', time.localtime(time.time()))))\n",
    "\n",
    "    base_url = 'http://www.gdcom.gov.cn/zwgk/zcwj/'\n",
    "    response = requests.get(base_url, headers=headers, timeout = 10)\n",
    "    if (response.status_code != 200):\n",
    "        return None\n",
    "\n",
    "    text = str(response.content, 'utf-8')\n",
    "    html = etree.HTML(text)\n",
    "    xpath = '/html/body/div[2]/div/div[2]/ul/li/a/text()'\n",
    "    titles = html.xpath(xpath)\n",
    "    xpath = '/html/body/div[2]/div/div[2]/ul/li/a/@href'\n",
    "    links = html.xpath(xpath)\n",
    "    tlinks = []\n",
    "    for x in links:\n",
    "        x = str(x)\n",
    "        if x != None and x[:2] == './':\n",
    "            x = base_url + x[2:]\n",
    "        tlinks.append(x)\n",
    "    links = tlinks\n",
    "    \n",
    "    xpath = '/html/body/div[2]/div/div[2]/ul/li/span/text()'\n",
    "    dates = html.xpath(xpath)\n",
    "    dates = [x.replace(' ', '') for x in dates]\n",
    "    \n",
    "    data_guangdong = [ (t, l, d, 'guangdong') for t, l, d in zip(titles, links, dates) ]\n",
    "        \n",
    "    dict_guangdong = [{'pos':x[3], 'title': x[0], 'link': x[1], 'date': x[2]} for x in data_guangdong]\n",
    "    \n",
    "    print (len(dict_guangdong))\n",
    "\n",
    "    print ('In {}, end, date is {}'.format(get_swb_guangdong.__name__, time.strftime('%Y-%m-%d-%H:%M', time.localtime(time.time()))))\n",
    "\n",
    "    return dict_guangdong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-07T07:41:57.398137Z",
     "start_time": "2018-08-07T07:41:57.364678Z"
    }
   },
   "outputs": [],
   "source": [
    "## ShangWuBuWaiMaoSi\n",
    "\n",
    "def get_wms_china():\n",
    "    \n",
    "    print ('In {}, begin, date is {}'.format(get_wms_china.__name__, time.strftime('%Y-%m-%d-%H:%M', time.localtime(time.time()))))\n",
    "\n",
    "    base_url = 'http://wms.mofcom.gov.cn'\n",
    "    response = requests.get(base_url + '/article/zcfb/ax/', headers=headers, timeout = 10)\n",
    "    if (response.status_code != 200):\n",
    "        return None\n",
    "    text = str(response.content, 'utf-8')\n",
    "    html = etree.HTML(text)\n",
    "    xpath = '//*[@id=\"leftList\"]/div[2]/ul/li/a[1]/text()'\n",
    "    titles = html.xpath(xpath)\n",
    "    # print (titles)\n",
    "    xpath = '//*[@id=\"leftList\"]/div[2]/ul/li/a[1]/@href'\n",
    "    links = html.xpath(xpath)\n",
    "    links = [ base_url + str(x) for x in links]\n",
    "    # print (links)\n",
    "    xpath = '//*[@id=\"leftList\"]/div[2]/ul/li/span/text()'\n",
    "    dates = html.xpath(xpath)\n",
    "    dates = [x.split()[0] for x in dates]\n",
    "    # print (dates)\n",
    "\n",
    "    data_china = [ (t, l, d, 'china') for (t, l, d) in zip(titles, links, dates) ]\n",
    "\n",
    "    response = requests.get(base_url + '/article/zcfb/g/', headers=headers, timeout = 10)\n",
    "    if (response.status_code != 200):\n",
    "        return None\n",
    "    text = str(response.content, 'utf-8')\n",
    "    html = etree.HTML(text)\n",
    "    xpath = '//*[@id=\"leftList\"]/div[2]/ul/li/a[1]/text()'\n",
    "    titles = html.xpath(xpath)\n",
    "    xpath = '//*[@id=\"leftList\"]/div[2]/ul/li/a[1]/@href'\n",
    "    links = html.xpath(xpath)\n",
    "    links = [ base_url + str(x) for x in links]\n",
    "    xpath = '//*[@id=\"leftList\"]/div[2]/ul/li/span/text()'\n",
    "    dates = html.xpath(xpath)\n",
    "    dates = [x.split()[0] for x in dates]\n",
    "    \n",
    "    data_china = data_china + [ (t, l, d, 'china') for t, l, d in zip(titles, links, dates) ]\n",
    "\n",
    "    dict_china = [{'pos':x[3], 'title': x[0], 'link': x[1], 'date': x[2]} for x in data_china]\n",
    "  \n",
    "    print (len(dict_china))\n",
    "\n",
    "    print ('In {}, end, date is {}'.format(get_wms_china.__name__, time.strftime('%Y-%m-%d-%H:%M', time.localtime(time.time()))))\n",
    "\n",
    "    return dict_china\n",
    "\n",
    "def get_wms_jiangsu():\n",
    "\n",
    "    print ('In {}, begin, date is {}'.format(get_wms_jiangsu.__name__, time.strftime('%Y-%m-%d-%H:%M', time.localtime(time.time()))))\n",
    "\n",
    "    base_url = 'http://swt.jiangsu.gov.cn'\n",
    "    \n",
    "    response = requests.get(base_url + '/col/col57691/index.html', headers=headers, timeout = 10)\n",
    "    if (response.status_code != 200):\n",
    "        return None\n",
    "    text = str(response.content, 'utf-8')\n",
    "    regex = re.compile('<a href=\"(.*)\" target=\"_blank\" .*title=\"(.*)\">.*</a><span.*> \\((.*)\\)</span>')\n",
    "    data_jiangsu = [(x[1], base_url+x[0], x[2].replace('/', '-'), 'jiangsu') for x in re.findall(pattern=regex, string=text)]\n",
    "    \n",
    "    response = requests.get(base_url + '/col/col57692/index.html', headers=headers, timeout = 10)\n",
    "    if (response.status_code != 200):\n",
    "        return None\n",
    "    text = str(response.content, 'utf-8')\n",
    "    regex = re.compile('<a href=\"(.*)\" target=\"_blank\" .*title=\"(.*)\">.*</a><span.*> \\((.*)\\)</span>')\n",
    "    data_jiangsu += [(x[1], base_url+x[0], x[2].replace('/', '-'), 'jiangsu') for x in re.findall(pattern=regex, string=text)]\n",
    "    \n",
    "    dict_jiangsu = [{'pos':x[3], 'title': x[0], 'link': x[1], 'date': x[2]} for x in data_jiangsu]\n",
    "    \n",
    "    print (len(dict_jiangsu))\n",
    "\n",
    "    print ('In {}, end, date is {}'.format(get_wms_jiangsu.__name__, time.strftime('%Y-%m-%d-%H:%M', time.localtime(time.time()))))\n",
    "\n",
    "    return dict_jiangsu\n",
    "\n",
    "def get_wms_zhejiang():\n",
    "\n",
    "    print ('In {}, begin, date is {}'.format(get_wms_zhejiang.__name__, time.strftime('%Y-%m-%d-%H:%M', time.localtime(time.time()))))\n",
    "\n",
    "    base_url = 'http://www.zcom.gov.cn'\n",
    "    \n",
    "    response = requests.get(base_url + '/col/col1385815/index.html', headers=headers, timeout = 10)\n",
    "    if (response.status_code != 200):\n",
    "        return None\n",
    "    text = str(response.content, 'utf-8')\n",
    "\n",
    "    html = etree.HTML(text)\n",
    "    xpath = '//*[@id=\"con_two_2\"]/div[position()>1]/a[1]/text()'\n",
    "    titles = html.xpath(xpath)  \n",
    "    xpath = '//*[@id=\"con_two_2\"]/div[position()>1]/a[1]/@href'\n",
    "    links = html.xpath(xpath)\n",
    "    links = [ base_url + str(x) for x in links]\n",
    "    \n",
    "    xpath = '//*[@id=\"con_two_2\"]/div[position()>1]/a[1]/span/text()'\n",
    "    dates = html.xpath(xpath)\n",
    "    data_zhejiang = [ (t, l, d, 'zhejiang') for t, l, d in zip(titles, links, dates) ]\n",
    "\n",
    "    ################\n",
    "    \n",
    "    xpath = '//*[@id=\"con_three_1\"]/div[position()>1]/a[1]/text()'\n",
    "    titles = html.xpath(xpath)  \n",
    "    xpath = '//*[@id=\"con_three_1\"]/div[position()>1]/a[1]/@href'\n",
    "    links = html.xpath(xpath)\n",
    "    links = [ base_url + str(x) for x in links]\n",
    "    \n",
    "    xpath = '//*[@id=\"con_three_1\"]/div[position()>1]/a[1]/span/text()'\n",
    "    dates = html.xpath(xpath)\n",
    "    data_zhejiang += [ (t, l, d, 'zhejiang') for t, l, d in zip(titles, links, dates) ]\n",
    "    \n",
    "    dict_zhejiang = [{'pos':x[3], 'title': x[0], 'link': x[1], 'date': x[2]} for x in data_zhejiang]\n",
    "  \n",
    "    print (len(dict_zhejiang))\n",
    "\n",
    "    print ('In {}, end, date is {}'.format(get_wms_zhejiang.__name__, time.strftime('%Y-%m-%d-%H:%M', time.localtime(time.time()))))\n",
    "\n",
    "    return dict_zhejiang\n",
    "\n",
    "def get_wms_guangdong():\n",
    "    \n",
    "    print ('In {}, begin, date is {}'.format(get_wms_guangdong.__name__, time.strftime('%Y-%m-%d-%H:%M', time.localtime(time.time()))))\n",
    "\n",
    "    base_url = 'http://go.gdcom.gov.cn'\n",
    "    \n",
    "    response = requests.get(base_url + '/article.php?typeid=9', headers=headers, timeout = 10)\n",
    "    if (response.status_code != 200):\n",
    "        return None\n",
    "    text = str(response.content, 'utf-8')\n",
    "\n",
    "    html = etree.HTML(text)\n",
    "    xpath = '/html/body/div[3]/div/div[2]/div/div[2]/div[2]/ul/li/h6/a[1]/text()'\n",
    "    titles = html.xpath(xpath)  \n",
    "    xpath = '/html/body/div[3]/div/div[2]/div/div[2]/div[2]/ul/li/h6/a[1]/@href'\n",
    "    links = html.xpath(xpath)\n",
    "    links = [ base_url + '/' + str(x) for x in links]\n",
    "    \n",
    "    xpath = '/html/body/div[3]/div/div[2]/div/div[2]/div[2]/ul/li/h6/small/text()'\n",
    "    dates = html.xpath(xpath)\n",
    "    data_guangdong = [ (t, l, d, 'guangdong') for t, l, d in zip(titles, links, dates) ]\n",
    "\n",
    "    dict_guangdong = [{'pos':x[3], 'title': x[0], 'link': x[1], 'date': x[2]} for x in data_guangdong]\n",
    "  \n",
    "    print (len(dict_guangdong))\n",
    "\n",
    "    print ('In {}, end, date is {}'.format(get_wms_guangdong.__name__, time.strftime('%Y-%m-%d-%H:%M', time.localtime(time.time()))))\n",
    "\n",
    "    return dict_guangdong\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-07T07:21:13.577307Z",
     "start_time": "2018-08-07T07:21:13.541473Z"
    }
   },
   "outputs": [],
   "source": [
    "## ZhiShiChanQuanJu\n",
    "\n",
    "def get_zscqj_china():\n",
    "    \n",
    "    print ('In {}, begin, date is {}'.format(get_zscqj_china.__name__, time.strftime('%Y-%m-%d-%H:%M', time.localtime(time.time()))))\n",
    "\n",
    "    base_url = 'http://www.sipo.gov.cn'\n",
    "    \n",
    "    response = requests.get(base_url + '/gwywj/index.htm', headers=headers, timeout=10)   \n",
    "    if (response.status_code != 200):\n",
    "        return None\n",
    "    text = str(response.content, 'utf-8')\n",
    "    html = etree.HTML(text)\n",
    "    xpath = '/html/body/div/div/div/div[4]/div/div[2]/ul/li/a[1]/text()'\n",
    "    titles = html.xpath(xpath)\n",
    "    # print (titles)\n",
    "    xpath = '/html/body/div/div/div/div[4]/div/div[2]/ul/li/a[1]/@href'\n",
    "    links = html.xpath(xpath)\n",
    "    # print (links)\n",
    "    xpath = '/html/body/div/div/div/div[4]/div/div[2]/ul/li/span/text()'\n",
    "    dates = html.xpath(xpath)\n",
    "    # print (dates)\n",
    "    data_china = [ (t, l, d, 'china') for (t, l, d) in zip(titles, links, dates) ]\n",
    "\n",
    "    response = requests.get(base_url + '/dtxx/index.htm', headers=headers, timeout=10)\n",
    "    if (response.status_code != 200):\n",
    "        return None\n",
    "    text = str(response.content, 'utf-8')\n",
    "    html = etree.HTML(text)\n",
    "    xpath = '/html/body/div/div/div/div[4]/div/div[2]/ul/li/a[1]/text()'\n",
    "    titles = html.xpath(xpath)\n",
    "    # print (titles)\n",
    "    xpath = '/html/body/div/div/div/div[4]/div/div[2]/ul/li/a[1]/@href'\n",
    "    links = html.xpath(xpath)\n",
    "    ## !!!!!\n",
    "    links = [ base_url + '/dtxx/' + str(x) for x in links] \n",
    "    # print (links)\n",
    "    xpath = '/html/body/div/div/div/div[4]/div/div[2]/ul/li/span/text()'\n",
    "    dates = html.xpath(xpath)\n",
    "    # print (dates) \n",
    "    data_china = data_china + [ (t, l, d, 'china') for t, l, d in zip(titles, links, dates) ]\n",
    "\n",
    "    response = requests.get(base_url + '/zfgg/index.htm', headers=headers, timeout=10)\n",
    "    if (response.status_code != 200):\n",
    "        return None\n",
    "    text = str(response.content, 'utf-8')\n",
    "    html = etree.HTML(text)\n",
    "    xpath = '/html/body/div/div/div/div[4]/div/div[2]/ul/li/a[1]/text()'\n",
    "    titles = html.xpath(xpath)\n",
    "    # print (titles)\n",
    "    xpath = '/html/body/div/div/div/div[4]/div/div[2]/ul/li/a[1]/@href'\n",
    "    links = html.xpath(xpath)\n",
    "    ## !!!!!\n",
    "    links = [ base_url + '/zfgg/' + str(x) for x in links]\n",
    "    # print (links)\n",
    "    xpath = '/html/body/div/div/div/div[4]/div/div[2]/ul/li/span/text()'\n",
    "    dates = html.xpath(xpath)\n",
    "    # print (dates) \n",
    "    data_china = data_china + [ (t, l, d, 'china') for t, l, d in zip(titles, links, dates) ]\n",
    "    \n",
    "    response = requests.get(base_url + '/gztz/index.htm', headers=headers, timeout=10)\n",
    "    if (response.status_code != 200):\n",
    "        return None\n",
    "    text = str(response.content, 'utf-8')\n",
    "    html = etree.HTML(text)\n",
    "    xpath = '/html/body/div/div/div/div[4]/div/div[2]/ul/li/a[1]/text()'\n",
    "    titles = html.xpath(xpath)\n",
    "    # print (titles)\n",
    "    xpath = '/html/body/div/div/div/div[4]/div/div[2]/ul/li/a[1]/@href'\n",
    "    links = html.xpath(xpath)\n",
    "    ## !!!!!\n",
    "    links = [ base_url + '/gztz/' + str(x) for x in links]\n",
    "    # print (links)\n",
    "    xpath = '/html/body/div/div/div/div[4]/div/div[2]/ul/li/span/text()'\n",
    "    dates = html.xpath(xpath)\n",
    "    # print (dates) \n",
    "    data_china = data_china + [ (t, l, d, 'china') for t, l, d in zip(titles, links, dates) ]\n",
    "    \n",
    "    \n",
    "    dict_china = [{'pos':x[3], 'title': x[0], 'link': x[1], 'date': x[2]} for x in data_china]\n",
    "  \n",
    "    print (len(dict_china))\n",
    "\n",
    "    print ('In {}, end, date is {}'.format(get_zscqj_china.__name__, time.strftime('%Y-%m-%d-%H:%M', time.localtime(time.time()))))\n",
    "\n",
    "    return dict_china\n",
    "\n",
    "def get_zscqj_jiangsu():\n",
    "\n",
    "    print ('In {}, begin, date is {}'.format(get_zscqj_jiangsu.__name__, time.strftime('%Y-%m-%d-%H:%M', time.localtime(time.time()))))\n",
    "\n",
    "    base_url = 'http://jsip.jiangsu.gov.cn'\n",
    "    \n",
    "    response = requests.get(base_url + '/col/col3300/index.html', headers=headers, timeout=10)\n",
    "    if (response.status_code != 200):\n",
    "        return None\n",
    "    text = str(response.content, 'utf-8')\n",
    "    regex = re.compile('<a href=\"(.*)\" TARGET=\"_blank\" >.*<div class=\"text\">(.*)</div>.*<div class=\"text-date\">(.*)</div>.*</a>')\n",
    "    data_jiangsu = [(x[1], base_url+x[0], x[2], 'jiangsu') for x in re.findall(pattern=regex, string=text)]\n",
    "    \n",
    "    response = requests.get(base_url + '/col/col3252/index.html', headers=headers, timeout=10)\n",
    "    if (response.status_code != 200):\n",
    "        return None\n",
    "    text = str(response.content, 'utf-8')\n",
    "    regex = re.compile('<a href=\"(.*)\" TARGET=\"_blank\" >.*<div class=\"text\">(.*)</div>.*<div class=\"text-date\">(.*)</div>.*</a>')\n",
    "    data_jiangsu += [(x[1], base_url+x[0], x[2], 'jiangsu') for x in re.findall(pattern=regex, string=text)]\n",
    "    \n",
    "    dict_jiangsu = [{'pos':x[3], 'title': x[0], 'link': x[1], 'date': x[2]} for x in data_jiangsu]\n",
    "    \n",
    "    print (len(dict_jiangsu))\n",
    "\n",
    "    print ('In {}, end, date is {}'.format(get_zscqj_jiangsu.__name__, time.strftime('%Y-%m-%d-%H:%M', time.localtime(time.time()))))\n",
    "\n",
    "    return dict_jiangsu\n",
    "\n",
    "def get_zscqj_zhejiang():\n",
    "\n",
    "    print ('In {}, begin, date is {}'.format(get_zscqj_zhejiang.__name__, time.strftime('%Y-%m-%d-%H:%M', time.localtime(time.time()))))\n",
    "\n",
    "    base_url = 'http://www.zjpat.gov.cn'\n",
    "    \n",
    "    response = requests.get(base_url + '/interIndex.do?method=list22&dir=/zjszscqj/tzgg', headers=headers, timeout=10)\n",
    "    if (response.status_code != 200):\n",
    "        return None\n",
    "    text = str(response.content, 'utf-8').replace('\\r\\n', '')\n",
    "    text = re.sub(' +', ' ', text)\n",
    "\n",
    "    regex = re.compile('<a href=\"([^>]*?)\" title=\"([^>]*?)\" target=\"_blank\" class=\"color_01\">.*?</a> </td> <td.[^>]*?> \\((.*?)\\) </td> </tr>')\n",
    "    data_zhejiang = [(x[1], base_url+'/'+x[0], x[2], 'zhejiang') for x in re.findall(pattern=regex, string=text)]\n",
    "    \n",
    "    response = requests.get(base_url + '/interIndex.do?method=list2&dir=/zjszscqj/xwdt/sxdt', headers=headers, timeout=10)\n",
    "    if (response.status_code != 200):\n",
    "        return None\n",
    "    text = str(response.content, 'utf-8').replace('\\r\\n', '')\n",
    "    text = re.sub(' +', ' ', text)\n",
    "    regex = re.compile('<a href=\"([^>]*?)\" title=\"([^>]*?)\" target=\"_blank\" class=\"color_01\">.*?</a> </td> <td.[^>]*?> \\((.*?)\\) </td> </tr>')\n",
    "    data_zhejiang += [(x[1], base_url+'/'+x[0], x[2], 'zhejiang') for x in re.findall(pattern=regex, string=text)]\n",
    "    \n",
    "    dict_zhejiang = [{'pos':x[3], 'title': x[0], 'link': x[1], 'date': x[2]} for x in data_zhejiang]\n",
    "    \n",
    "    print (len(dict_zhejiang))\n",
    "    \n",
    "    print ('In {}, end, date is {}'.format(get_zscqj_zhejiang.__name__, time.strftime('%Y-%m-%d-%H:%M', time.localtime(time.time()))))\n",
    "\n",
    "    return dict_zhejiang\n",
    "\n",
    "\n",
    "def get_zscqj_guangdong():\n",
    "\n",
    "    print ('In {}, begin, date is {}'.format(get_zscqj_guangdong.__name__, time.strftime('%Y-%m-%d-%H:%M', time.localtime(time.time()))))\n",
    "\n",
    "    base_url = 'http://www.gdipo.gov.cn'\n",
    "    \n",
    "    response = requests.get(base_url + '/gdipo/gdipodt/list.shtml', headers=headers, timeout=10)\n",
    "    if (response.status_code != 200):\n",
    "        return None\n",
    "    text = str(response.content, 'utf-8').replace('\\r\\n', '')\n",
    "    text = re.sub(' +', ' ', text)\n",
    "    regex = re.compile('<li> <a href=\"(.*?)\" target=\"_blank\" >(.*?)</a> <div class=\"time_div\"> <span class=\"time\">(.*?)</span> </div> </li>')\n",
    "    data_guangdong = [(x[1], base_url+x[0], x[2], 'guangdong') for x in re.findall(pattern=regex, string=text)]\n",
    "\n",
    "    response = requests.get(base_url + '/gdipo/tzgg/list.shtml', headers=headers, timeout=10)\n",
    "    if (response.status_code != 200):\n",
    "        return None\n",
    "    text = str(response.content, 'utf-8').replace('\\r\\n', '')\n",
    "    text = re.sub(' +', ' ', text)\n",
    "    regex = re.compile('<li> <a href=\"(.*?)\" target=\"_blank\" >(.*?)</a> <div class=\"time_div\"> <span class=\"time\">(.*?)</span> </div> </li>')\n",
    "    data_guangdong += [(x[1], base_url+x[0], x[2], 'guangdong') for x in re.findall(pattern=regex, string=text)]\n",
    "   \n",
    "    dict_guangdong = [{'pos':x[3], 'title': x[0], 'link': x[1], 'date': x[2]} for x in data_guangdong]\n",
    "    \n",
    "    print (len(dict_guangdong))\n",
    "    \n",
    "    print ('In {}, end, date is {}'.format(get_zscqj_guangdong.__name__, time.strftime('%Y-%m-%d-%H:%M', time.localtime(time.time()))))\n",
    "\n",
    "    return dict_guangdong\n",
    "\n",
    "### Very/interIndex.do?method=list2&dir=/zjszscqj/xwdt/sxdt Important to match \\r\\n...\n",
    "### re.findall(pattern='<table>([\\s\\S]*?)<\\/table>', string=text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-07T07:21:43.469681Z",
     "start_time": "2018-08-07T07:21:43.443144Z"
    }
   },
   "outputs": [],
   "source": [
    "## NengYuanJu\n",
    "\n",
    "def get_nyj_china():\n",
    "    print ('In {}, begin, date is {}'.format(get_nyj_china.__name__, time.strftime('%Y-%m-%d-%H:%M', time.localtime(time.time()))))\n",
    "\n",
    "    base_url = 'http://www.nea.gov.cn'\n",
    "    \n",
    "    response = requests.get(base_url + '/xwzx/nyyw.htm', headers=headers, timeout = 10)   \n",
    "    if (response.status_code != 200):\n",
    "        return None\n",
    "    text = str(response.content, 'utf-8')\n",
    "    html = etree.HTML(text)\n",
    "    xpath = '//div[@class=\"content\"]/div/ul/li/a/text()'\n",
    "    titles = html.xpath(xpath)\n",
    "    # print (titles)\n",
    "    xpath = '//div[@class=\"content\"]/div/ul/li/a/@href'\n",
    "    links = html.xpath(xpath)\n",
    "    # print (links)\n",
    "    xpath = '//div[@class=\"content\"]/div/ul/li/span/text()'\n",
    "    dates = html.xpath(xpath)\n",
    "    # print (dates)\n",
    "    data_china = [ (t, l, d, 'china') for (t, l, d) in zip(titles, links, dates) ]\n",
    "    \n",
    "    dict_china = [{'pos':x[3], 'title': x[0], 'link': x[1], 'date': x[2]} for x in data_china]\n",
    "  \n",
    "    print (len(dict_china))\n",
    "    \n",
    "    print ('In {}, end, date is {}'.format(get_nyj_china.__name__, time.strftime('%Y-%m-%d-%H:%M', time.localtime(time.time()))))\n",
    "\n",
    "    return dict_china\n",
    "\n",
    "def get_nyj_jiangsu():\n",
    "    print ('In {}, begin, date is {}'.format(get_nyj_jiangsu.__name__, time.strftime('%Y-%m-%d-%H:%M', time.localtime(time.time()))))\n",
    "\n",
    "    base_url = 'http://jsb.nea.gov.cn'\n",
    "    \n",
    "    response = requests.get(base_url + '/info/community/101.html', headers=headers, timeout = 10)   \n",
    "    if (response.status_code != 200):\n",
    "        return None\n",
    "    text = str(response.content, 'gbk').replace('\\r\\n', '')\n",
    "    text = re.sub(' +', ' ', text)\n",
    "    html = etree.HTML(text)\n",
    "\n",
    "    regex = re.compile('<a href=\"([^>]*?)\" target=_blank>(.*?)</a></td><td.*?> <p.*?>\\[(.*?)\\] </td>')\n",
    "    data_jiangsu = [(x[1], base_url+x[0], x[2], 'jiangsu') for x in re.findall(pattern=regex, string=text)]\n",
    "    \n",
    "    dict_jiangsu = [{'pos':x[3], 'title': x[0], 'link': x[1], 'date': x[2].replace('/', '-')} for x in data_jiangsu]\n",
    "    \n",
    "    print (len(dict_jiangsu))\n",
    "    \n",
    "    print ('In {}, end, date is {}'.format(get_nyj_jiangsu.__name__, time.strftime('%Y-%m-%d-%H:%M', time.localtime(time.time()))))\n",
    "\n",
    "    return dict_jiangsu\n",
    "\n",
    "def get_nyj_zhejiang():\n",
    "    print ('In {}, begin, date is {}'.format(get_nyj_zhejiang.__name__, time.strftime('%Y-%m-%d-%H:%M', time.localtime(time.time()))))\n",
    "\n",
    "    base_url = 'http://zjb.nea.gov.cn'\n",
    "\n",
    "    response = requests.get(base_url + '/article/zygg/d1/', headers=headers, timeout = 10)   \n",
    "    if (response.status_code != 200):\n",
    "        return None\n",
    "    text = str(response.content, 'gbk')\n",
    "    html = etree.HTML(text)\n",
    "    xpath = '//div[@class=\"d5\"]/a/text()'\n",
    "    titles = html.xpath(xpath)\n",
    "    # print (titles)\n",
    "    xpath = '//div[@class=\"d5\"]/a/@href'\n",
    "    links = html.xpath(xpath)\n",
    "    links = [base_url + x for x in links]\n",
    "    # print (links)\n",
    "    xpath = '//div[@class=\"d5\"]/span/text()'\n",
    "    dates = html.xpath(xpath)\n",
    "    # print (dates)\n",
    "    data_zhejiang = [ (t, l, d, 'zhejiang') for (t, l, d) in zip(titles, links, dates) ]\n",
    "    \n",
    "    response = requests.get(base_url + '/article/ywdd/', headers=headers, timeout = 10)   \n",
    "    if (response.status_code != 200):\n",
    "        return None\n",
    "    text = str(response.content, 'gbk')\n",
    "    html = etree.HTML(text)\n",
    "    xpath = '//div[@class=\"d5\"]/a/text()'\n",
    "    titles = html.xpath(xpath)\n",
    "    # print (titles)\n",
    "    xpath = '//div[@class=\"d5\"]/a/@href'\n",
    "    links = html.xpath(xpath)\n",
    "    links = [base_url + x for x in links]\n",
    "    # print (links)\n",
    "    xpath = '//div[@class=\"d5\"]/span/text()'\n",
    "    dates = html.xpath(xpath)\n",
    "    # print (dates)\n",
    "    data_zhejiang += [ (t, l, d, 'zhejiang') for (t, l, d) in zip(titles, links, dates) ]\n",
    "    \n",
    "    dict_zhejiang = [{'pos':x[3], 'title': x[0], 'link': x[1], 'date': x[2]} for x in data_zhejiang]\n",
    "  \n",
    "    print (len(dict_zhejiang))\n",
    "    \n",
    "    print ('In {}, end, date is {}'.format(get_nyj_zhejiang.__name__, time.strftime('%Y-%m-%d-%H:%M', time.localtime(time.time()))))\n",
    "\n",
    "    return dict_zhejiang\n",
    "\n",
    "def get_nyj_guangdong():\n",
    "    ## Infact, it is nyj of southern china\n",
    "    print ('In {}, begin, date is {}'.format(get_nyj_guangdong.__name__, time.strftime('%Y-%m-%d-%H:%M', time.localtime(time.time()))))\n",
    "\n",
    "    base_url = 'http://nfj.nea.gov.cn'\n",
    "    \n",
    "    response = requests.get(base_url + '/frontIndex/showNews.do?type=3', headers=headers, timeout = 10)   \n",
    "    if (response.status_code != 200):\n",
    "        return None\n",
    "    text = str(response.content, 'utf-8')\n",
    "    html = etree.HTML(text)\n",
    "    xpath = '//div[@class=\"new_list2\"]/ul/li/a/text()'\n",
    "    titles = html.xpath(xpath)\n",
    "    # print (titles)\n",
    "    xpath = '//div[@class=\"new_list2\"]/ul/li/a/@href'\n",
    "    links = html.xpath(xpath)\n",
    "    # print (links)\n",
    "    xpath = '//div[@class=\"new_list2\"]/ul/li/span/text()'\n",
    "    dates = html.xpath(xpath)\n",
    "    # print (dates)\n",
    "    data_guangdong = [ (t, l, d, 'guangdong') for (t, l, d) in zip(titles, links, dates) ]\n",
    "    \n",
    "    dict_guangdong = [{'pos':x[3], 'title': x[0], 'link': x[1], 'date': x[2]} for x in data_guangdong]\n",
    "    \n",
    "    print (len(dict_guangdong))\n",
    "\n",
    "    print ('In {}, end, date is {}'.format(get_nyj_guangdong.__name__, time.strftime('%Y-%m-%d-%H:%M', time.localtime(time.time()))))\n",
    "\n",
    "    return dict_guangdong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-07T07:21:42.372236Z",
     "start_time": "2018-08-07T07:21:42.366686Z"
    }
   },
   "outputs": [],
   "source": [
    "## JinBiaoWei\n",
    "\n",
    "def get_jbw_china():\n",
    "    print ('In {}, begin, date is {}'.format(get_jbw_china.__name__, time.strftime('%Y-%m-%d-%H:%M', time.localtime(time.time()))))\n",
    "\n",
    "    base_url = 'http://www.cfstc.org' \n",
    "    \n",
    "    response = requests.get(base_url + '/jinbiaowei/2929484/index.html', headers=headers, timeout = 10)\n",
    "    if (response.status_code != 200):\n",
    "        return None\n",
    "    text = str(response.content, 'utf-8')\n",
    "    html = etree.HTML(text)\n",
    "    xpath = '//table[@opentype=\"page\"]/tbody/tr/td/ul/li/a[1]/text()'\n",
    "    titles = html.xpath(xpath)\n",
    "    # print (titles)\n",
    "    xpath = '//table[@opentype=\"page\"]/tbody/tr/td/ul/li/a[1]/@href'\n",
    "    links = html.xpath(xpath)\n",
    "    ## !!!!!\n",
    "    links = [ base_url + '/gztz/' + str(x) for x in links]\n",
    "    # print (links)\n",
    "    xpath = '//table[@opentype=\"page\"]/tbody/tr/td/ul/li/span/text()'\n",
    "    dates = html.xpath(xpath)\n",
    "    # print (dates) \n",
    "    data_china = [ (t, l, d, 'china') for t, l, d in zip(titles, links, dates) ]\n",
    "    \n",
    "    dict_china = [{'pos':x[3], 'title': x[0], 'link': x[1], 'date': x[2]} for x in data_china]\n",
    "  \n",
    "    print (len(dict_china))\n",
    "\n",
    "    print ('In {}, end, date is {}'.format(get_jbw_china.__name__, time.strftime('%Y-%m-%d-%H:%M', time.localtime(time.time()))))\n",
    "\n",
    "    return dict_china"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-07T07:21:52.212133Z",
     "start_time": "2018-08-07T07:21:52.118742Z"
    }
   },
   "outputs": [],
   "source": [
    "## ZhengJianHui\n",
    "\n",
    "def get_zjh_china():\n",
    "    print ('In {}, begin, date is {}'.format(get_zjh_china.__name__, time.strftime('%Y-%m-%d-%H:%M', time.localtime(time.time()))))\n",
    "\n",
    "    from selenium import webdriver\n",
    "    from selenium.webdriver.common.by import By\n",
    "    from selenium.webdriver.support.ui import WebDriverWait\n",
    "    from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "    chrome_options = webdriver.ChromeOptions()\n",
    "    chrome_options.add_argument('--headless')\n",
    "    driver = webdriver.Chrome(chrome_options=chrome_options)\n",
    "\n",
    "    base_url = 'http://www.csrc.gov.cn/pub/zjhpublic' \n",
    "    \n",
    "    driver.get(base_url + '/index.htm?channel=3300/3311/')\n",
    "    driver.switch_to.frame(\"DataList\")\n",
    "    driver.execute_script(\"window.scrollTo(0,document.body.scrollHeight)\")\n",
    "    time.sleep(1)\n",
    "#     html = driver.page_source\n",
    "    elements = driver.find_elements_by_xpath('//div[@class=\"row\"]/li[@class=\"mc\"]/div/a')\n",
    "    urls = [ele.get_attribute(\"href\") for ele in elements if len(ele.text) > 0]\n",
    "    titles = [ele.text for ele in elements if len(ele.text) > 0]\n",
    "    elements = driver.find_elements_by_xpath('//div[@class=\"row\"]/li[@class=\"fbrq\"]')\n",
    "    dates = [ele.text for ele in elements if len(ele.text) > 0]\n",
    "    dates = [ date.replace('年','-').replace('月','-').replace('日','') for date in dates]\n",
    "\n",
    "    data_china = [(x[0], x[1], x[2]) for x in zip(titles,urls,dates)]    \n",
    "    \n",
    "    driver.get(base_url + '/index.htm?channel=3300/3302/')\n",
    "    driver.switch_to.frame(\"DataList\")\n",
    "    driver.execute_script(\"window.scrollTo(0,document.body.scrollHeight)\")\n",
    "    time.sleep(1)\n",
    "#     html = driver.page_source\n",
    "    elements = driver.find_elements_by_xpath('//div[@class=\"row\"]/li[@class=\"mc\"]/div/a')\n",
    "    urls = [ele.get_attribute(\"href\") for ele in elements if len(ele.text) > 0]\n",
    "    titles = [ele.text for ele in elements if len(ele.text) > 0]\n",
    "    elements = driver.find_elements_by_xpath('//div[@class=\"row\"]/li[@class=\"fbrq\"]')\n",
    "    dates = [ele.text for ele in elements if len(ele.text) > 0]\n",
    "    dates = [ date.replace('年','-').replace('月','-').replace('日','') for date in dates]\n",
    "\n",
    "    data_china += [(x[0], x[1], x[2]) for x in zip(titles,urls,dates)]\n",
    "\n",
    "    \n",
    "    driver.quit()    \n",
    "    \n",
    "    dict_china = [{'pos': 'china', 'title': x[0], 'link': x[1], 'date': x[2]} for x in data_china]\n",
    "    \n",
    "    print (len(dict_china))\n",
    "    \n",
    "    print ('In {}, end, date is {}'.format(get_zjh_china.__name__, time.strftime('%Y-%m-%d-%H:%M', time.localtime(time.time()))))\n",
    "\n",
    "    return dict_china\n",
    "\n",
    "def get_zjh_jiangsu():\n",
    "    print ('In {}, begin, date is {}'.format(get_zjh_jiangsu.__name__, time.strftime('%Y-%m-%d-%H:%M', time.localtime(time.time()))))\n",
    "\n",
    "    from selenium import webdriver\n",
    "    from selenium.webdriver.common.by import By\n",
    "    from selenium.webdriver.support.ui import WebDriverWait\n",
    "    from selenium.webdriver.support import expected_conditions as EC\n",
    "    \n",
    "    chrome_options = webdriver.ChromeOptions()\n",
    "    chrome_options.add_argument('--headless')\n",
    "    driver = webdriver.Chrome(chrome_options=chrome_options)\n",
    "\n",
    "    base_url = 'http://www.csrc.gov.cn/pub/zjhpublicofjs' \n",
    "    \n",
    "    driver.get(base_url + '/index.htm?channel=3284/3565/')\n",
    "    driver.switch_to.frame(\"DataList\")\n",
    "    \n",
    "    driver.execute_script(\"window.scrollTo(0,document.body.scrollHeight)\")\n",
    "    time.sleep(1)\n",
    "#     html = driver.page_source\n",
    "    elements = driver.find_elements_by_xpath('//div[@class=\"row\"]/li[@class=\"mc\"]/div/a')\n",
    "    urls = [ele.get_attribute(\"href\") for ele in elements if len(ele.text) > 0 ]\n",
    "    titles = [ele.text for ele in elements if len(ele.text) > 0 ]\n",
    "    elements = driver.find_elements_by_xpath('//div[@class=\"row\"]/li[@class=\"fbrq\"]')\n",
    "    dates = [ele.text for ele in elements if len(ele.text) > 0 ]\n",
    "    dates = [ date.replace('年','-').replace('月','-').replace('日','') for date in dates]\n",
    "\n",
    "    data_jiangsu = [(x[0], x[1], x[2]) for x in zip(titles,urls,dates)]    \n",
    "    \n",
    "    driver.quit()    \n",
    "    \n",
    "    dict_jiangsu = [{'pos': 'jiangsu', 'title': x[0], 'link': x[1], 'date': x[2]} for x in data_jiangsu]\n",
    "    \n",
    "    print (len(dict_jiangsu))\n",
    "    \n",
    "    print ('In {}, end, date is {}'.format(get_zjh_jiangsu.__name__, time.strftime('%Y-%m-%d-%H:%M', time.localtime(time.time()))))\n",
    "\n",
    "    return dict_jiangsu\n",
    "\n",
    "def get_zjh_zhejiang():\n",
    "    print ('In {}, begin, date is {}'.format(get_zjh_zhejiang.__name__, time.strftime('%Y-%m-%d-%H:%M', time.localtime(time.time()))))\n",
    "\n",
    "    from selenium import webdriver\n",
    "    from selenium.webdriver.common.by import By\n",
    "    from selenium.webdriver.support.ui import WebDriverWait\n",
    "    from selenium.webdriver.support import expected_conditions as EC\n",
    "    \n",
    "    chrome_options = webdriver.ChromeOptions()\n",
    "    chrome_options.add_argument('--headless')\n",
    "    driver = webdriver.Chrome(chrome_options=chrome_options)\n",
    "\n",
    "    base_url = 'http://www.csrc.gov.cn/pub/zjhpublicofzj' \n",
    "    \n",
    "    driver.get(base_url + '/index.htm?channel=3284/3565/')\n",
    "    driver.switch_to.frame(\"DataList\")\n",
    "    \n",
    "    driver.execute_script(\"window.scrollTo(0,document.body.scrollHeight)\")\n",
    "    time.sleep(1)\n",
    "#     html = driver.page_source\n",
    "    elements = driver.find_elements_by_xpath('//div[@class=\"row\"]/li[@class=\"mc\"]/div/a')\n",
    "    urls = [ele.get_attribute(\"href\") for ele in elements if len(ele.text) > 0 ]\n",
    "    titles = [ele.text for ele in elements if len(ele.text) > 0 ]\n",
    "    elements = driver.find_elements_by_xpath('//div[@class=\"row\"]/li[@class=\"fbrq\"]')\n",
    "    dates = [ele.text for ele in elements if len(ele.text) > 0 ]\n",
    "    dates = [ date.replace('年','-').replace('月','-').replace('日','') for date in dates]\n",
    "\n",
    "    data_zhejiang = [(x[0], x[1], x[2]) for x in zip(titles,urls,dates)]    \n",
    "    \n",
    "    driver.quit()    \n",
    "    \n",
    "    dict_zhejiang = [{'pos': 'zhejiang', 'title': x[0], 'link': x[1], 'date': x[2]} for x in data_zhejiang]\n",
    "    \n",
    "    print (len(dict_zhejiang))\n",
    "    \n",
    "    print ('In {}, end, date is {}'.format(get_zjh_zhejiang.__name__, time.strftime('%Y-%m-%d-%H:%M', time.localtime(time.time()))))\n",
    "\n",
    "    return dict_zhejiang\n",
    "\n",
    "def get_zjh_guangdong():\n",
    "    print ('In {}, begin, date is {}'.format(get_zjh_guangdong.__name__, time.strftime('%Y-%m-%d-%H:%M', time.localtime(time.time()))))\n",
    "\n",
    "    from selenium import webdriver\n",
    "    from selenium.webdriver.common.by import By\n",
    "    from selenium.webdriver.support.ui import WebDriverWait\n",
    "    from selenium.webdriver.support import expected_conditions as EC\n",
    "    \n",
    "    chrome_options = webdriver.ChromeOptions()\n",
    "    chrome_options.add_argument('--headless')\n",
    "    driver = webdriver.Chrome(chrome_options=chrome_options)\n",
    "\n",
    "    base_url = 'http://www.csrc.gov.cn/pub/zjhpublicofgd' \n",
    "    \n",
    "    driver.get(base_url + '/index.htm?channel=3284/3565/')\n",
    "    driver.switch_to.frame(\"DataList\")\n",
    "    \n",
    "    driver.execute_script(\"window.scrollTo(0,document.body.scrollHeight)\")\n",
    "    time.sleep(1)\n",
    "#     html = driver.page_source\n",
    "    elements = driver.find_elements_by_xpath('//div[@class=\"row\"]/li[@class=\"mc\"]/div/a')\n",
    "    urls = [ele.get_attribute(\"href\") for ele in elements if len(ele.text) > 0 ]\n",
    "    titles = [ele.text for ele in elements if len(ele.text) > 0 ]\n",
    "    elements = driver.find_elements_by_xpath('//div[@class=\"row\"]/li[@class=\"fbrq\"]')\n",
    "    dates = [ele.text for ele in elements if len(ele.text) > 0 ]\n",
    "    dates = [ date.replace('年','-').replace('月','-').replace('日','') for date in dates]\n",
    "\n",
    "    data_guangdong = [(x[0], x[1], x[2]) for x in zip(titles,urls,dates)]    \n",
    "    \n",
    "    driver.quit()    \n",
    "    \n",
    "    dict_guangdong = [{'pos': 'guangdong', 'title': x[0], 'link': x[1], 'date': x[2]} for x in data_guangdong]\n",
    "    \n",
    "    print (len(dict_guangdong))\n",
    "    \n",
    "    print ('In {}, end, date is {}'.format(get_zjh_guangdong.__name__, time.strftime('%Y-%m-%d-%H:%M', time.localtime(time.time()))))\n",
    "\n",
    "    return dict_guangdong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-07T07:22:05.330208Z",
     "start_time": "2018-08-07T07:22:05.298528Z"
    }
   },
   "outputs": [],
   "source": [
    "## YinJianHui\n",
    "\n",
    "def get_yjh_china():\n",
    "    \n",
    "    print ('In {}, begin, date is {}'.format(get_yjh_china.__name__, time.strftime('%Y-%m-%d-%H:%M', time.localtime(time.time()))))\n",
    "\n",
    "    base_url = 'http://www.cbrc.gov.cn'\n",
    "    \n",
    "    response = requests.get(base_url + '/chinese/home/docViewPage/114.html', headers=headers, timeout = 10)   \n",
    "    if (response.status_code != 200):\n",
    "        return None\n",
    "    text = str(response.content, 'utf-8')\n",
    "    html = etree.HTML(text)\n",
    "    xpath = '//div[@class=\"right\"]//tr/td[1]/a/text()'\n",
    "    titles = html.xpath(xpath)\n",
    "#     print (titles)\n",
    "    xpath = '//div[@class=\"right\"]//tr/td[1]/a/@href'\n",
    "    links = html.xpath(xpath)\n",
    "    links = [base_url + link for link in links]\n",
    "    # print (links)\n",
    "    xpath = '//div[@class=\"right\"]//tr/td[2]/text()'\n",
    "    dates = html.xpath(xpath)\n",
    "    dates = [date.replace('\\r\\n\\t', '').replace('\\t','') for date in dates]\n",
    "    # print (dates)\n",
    "    data_china = [ (t, l, d, 'china') for (t, l, d) in zip(titles, links, dates) ]\n",
    "    \n",
    "    \n",
    "    dict_china = [{'pos':x[3], 'title': x[0], 'link': x[1], 'date': x[2]} for x in data_china]\n",
    "  \n",
    "    print (len(dict_china))\n",
    "\n",
    "    print ('In {}, end, date is {}'.format(get_yjh_china.__name__, time.strftime('%Y-%m-%d-%H:%M', time.localtime(time.time()))))\n",
    "\n",
    "    return dict_china\n",
    "\n",
    "def get_yjh_zhejiang():\n",
    "    \n",
    "    print ('In {}, begin, date is {}'.format(get_yjh_zhejiang.__name__, time.strftime('%Y-%m-%d-%H:%M', time.localtime(time.time()))))\n",
    "\n",
    "    base_url = 'http://www.cbrc.gov.cn'\n",
    "    \n",
    "    response = requests.get(base_url + '/zhejiang/pcjgDocMore/600610/left.html', headers=headers, timeout = 10)   \n",
    "    if (response.status_code != 200):\n",
    "        return None\n",
    "    text = str(response.content, 'utf-8')\n",
    "    html = etree.HTML(text)\n",
    "    xpath = '//div[@class=\"bookw3\"]/a/@title'\n",
    "    titles = html.xpath(xpath)\n",
    "#     print (titles)\n",
    "    xpath = '//div[@class=\"bookw3\"]/a/@href'\n",
    "    links = html.xpath(xpath)\n",
    "    links = [base_url + link for link in links]\n",
    "    # print (links)\n",
    "    xpath = '//div[contains(@class,\"work_list_date\")]/text()'\n",
    "    dates = html.xpath(xpath)\n",
    "    dates = [date.replace('\\r\\n\\t', '') for date in dates]\n",
    "    # print (dates)\n",
    "    data_zhejiang = [ (t, l, d, 'zhejiang') for (t, l, d) in zip(titles, links, dates) ]\n",
    "    \n",
    "    dict_zhejiang = [{'pos':x[3], 'title': x[0], 'link': x[1], 'date': x[2]} for x in data_zhejiang]\n",
    "  \n",
    "    print (len(dict_zhejiang))\n",
    "\n",
    "    print ('In {}, end, date is {}'.format(get_yjh_zhejiang.__name__, time.strftime('%Y-%m-%d-%H:%M', time.localtime(time.time()))))\n",
    "\n",
    "    return dict_zhejiang\n",
    "\n",
    "def get_yjh_guangdong():\n",
    "    \n",
    "    print ('In {}, begin, date is {}'.format(get_yjh_guangdong.__name__, time.strftime('%Y-%m-%d-%H:%M', time.localtime(time.time()))))\n",
    "\n",
    "    base_url = 'http://www.cbrc.gov.cn'\n",
    "    \n",
    "    response = requests.get(base_url + '/guangdong/pcjgDocMore/601710/left.html', headers=headers, timeout = 10)   \n",
    "    if (response.status_code != 200):\n",
    "        return None\n",
    "    text = str(response.content, 'utf-8')\n",
    "    html = etree.HTML(text)\n",
    "    xpath = '//div[@class=\"bookw3\"]/a/@title'\n",
    "    titles = html.xpath(xpath)\n",
    "#     print (titles)\n",
    "    xpath = '//div[@class=\"bookw3\"]/a/@href'\n",
    "    links = html.xpath(xpath)\n",
    "    links = [base_url + link for link in links]\n",
    "    # print (links)\n",
    "    xpath = '//div[contains(@class,\"work_list_date\")]/text()'\n",
    "    dates = html.xpath(xpath)\n",
    "    dates = [date.replace('\\r\\n\\t', '') for date in dates]\n",
    "    # print (dates)\n",
    "    data_guangdong = [ (t, l, d, 'guangdong') for (t, l, d) in zip(titles, links, dates) ]\n",
    "    \n",
    "    dict_guangdong = [{'pos':x[3], 'title': x[0], 'link': x[1], 'date': x[2]} for x in data_guangdong]\n",
    "  \n",
    "    print (len(dict_guangdong))\n",
    "\n",
    "    print ('In {}, end, date is {}'.format(get_yjh_guangdong.__name__, time.strftime('%Y-%m-%d-%H:%M', time.localtime(time.time()))))\n",
    "\n",
    "    return dict_guangdong\n",
    "\n",
    "def get_yjh_jiangsu():\n",
    "    \n",
    "    print ('In {}, begin, date is {}'.format(get_yjh_jiangsu.__name__, time.strftime('%Y-%m-%d-%H:%M', time.localtime(time.time()))))\n",
    "\n",
    "    base_url = 'http://www.cbrc.gov.cn'\n",
    "    \n",
    "    response = requests.get(base_url + '/jiangsu/pcjgDocMore/600810/left.html', headers=headers, timeout = 10)   \n",
    "    if (response.status_code != 200):\n",
    "        return None\n",
    "    text = str(response.content, 'utf-8')\n",
    "    html = etree.HTML(text)\n",
    "    xpath = '//div[@class=\"bookw3\"]/a/@title'\n",
    "    titles = html.xpath(xpath)\n",
    "#     print (titles)\n",
    "    xpath = '//div[@class=\"bookw3\"]/a/@href'\n",
    "    links = html.xpath(xpath)\n",
    "    links = [base_url + link for link in links]\n",
    "    # print (links)\n",
    "    xpath = '//div[contains(@class,\"work_list_date\")]/text()'\n",
    "    dates = html.xpath(xpath)\n",
    "    dates = [date.replace('\\r\\n\\t', '') for date in dates]\n",
    "    # print (dates)\n",
    "    data_jiangsu = [ (t, l, d, 'jiangsu') for (t, l, d) in zip(titles, links, dates) ]\n",
    "    \n",
    "    dict_jiangsu = [{'pos':x[3], 'title': x[0], 'link': x[1], 'date': x[2]} for x in data_jiangsu]\n",
    "  \n",
    "    print (len(dict_jiangsu))\n",
    "\n",
    "    print ('In {}, end, date is {}'.format(get_yjh_jiangsu.__name__, time.strftime('%Y-%m-%d-%H:%M', time.localtime(time.time()))))\n",
    "\n",
    "    return dict_jiangsu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-07T07:22:14.353549Z",
     "start_time": "2018-08-07T07:22:14.272228Z"
    }
   },
   "outputs": [],
   "source": [
    "## RenMinYinHang\n",
    "\n",
    "def get_rmyh_china():\n",
    "    print ('In {}, begin, date is {}'.format(get_rmyh_china.__name__, time.strftime('%Y-%m-%d-%H:%M', time.localtime(time.time()))))\n",
    "    \n",
    "    from selenium import webdriver\n",
    "    from selenium.webdriver.common.by import By\n",
    "    from selenium.webdriver.support.ui import WebDriverWait\n",
    "    from selenium.webdriver.support import expected_conditions as EC\n",
    "    \n",
    "    chrome_options = webdriver.ChromeOptions()\n",
    "    chrome_options.add_argument('--headless')\n",
    "    driver = webdriver.Chrome(chrome_options=chrome_options)\n",
    "\n",
    "    base_url = 'http://www.pbc.gov.cn'\n",
    "    \n",
    "    driver.get(base_url + '/diaochatongjisi/116219/index.html')\n",
    "    driver.execute_script(\"window.scrollTo(0,document.body.scrollHeight)\")\n",
    "    time.sleep(1)\n",
    "    \n",
    "    xpath = '//td[@height=23 or contains(@class, \"font14\")]/a[@href and @target=\"_blank\"]'\n",
    "    elements = driver.find_elements_by_xpath(xpath)\n",
    "    links = [ele.get_attribute(\"href\") for ele in elements if len(ele.text) > 0 ]\n",
    "    titles = [ele.text for ele in elements if len(ele.text) > 0 ]\n",
    "    dates = ['' for ele in elements if len(ele.text) > 0 ]    \n",
    "    \n",
    "    data_china = [ (t, l, d, 'china') for (t, l, d) in zip(titles, links, dates) ]\n",
    "    \n",
    "    \n",
    "    driver.get(base_url + '/tiaofasi/144941/index.html')\n",
    "    driver.execute_script(\"window.scrollTo(0,document.body.scrollHeight)\")\n",
    "    time.sleep(1)\n",
    "    \n",
    "    xpath = '//td[@height=23 or contains(@class, \"font14\")]/a[@href and @target=\"_blank\"]'\n",
    "    elements = driver.find_elements_by_xpath(xpath)\n",
    "    links = [ele.get_attribute(\"href\") for ele in elements if len(ele.text) > 0 ]\n",
    "    titles = [ele.text for ele in elements if len(ele.text) > 0 ]\n",
    "    dates = ['' for ele in elements if len(ele.text) > 0 ]    \n",
    "    \n",
    "    data_china += [ (t, l, d, 'china') for (t, l, d) in zip(titles, links, dates) ]\n",
    "\n",
    "    driver.quit()\n",
    "    \n",
    "    dict_china = [{'pos':x[3], 'title': x[0], 'link': x[1], 'date': x[2]} for x in data_china]\n",
    "  \n",
    "    print (len(dict_china))\n",
    "\n",
    "    print ('In {}, end, date is {}'.format(get_rmyh_china.__name__, time.strftime('%Y-%m-%d-%H:%M', time.localtime(time.time()))))\n",
    "\n",
    "    return dict_china\n",
    "\n",
    "def get_rmyh_jiangsu():\n",
    "#     //td[@height=23 or @class=\"font14\"]/a[@href and @target=\"_blank\"]\n",
    "    print ('In {}, begin, date is {}'.format(get_rmyh_jiangsu.__name__, time.strftime('%Y-%m-%d-%H:%M', time.localtime(time.time()))))\n",
    "    \n",
    "    from selenium import webdriver\n",
    "    from selenium.webdriver.common.by import By\n",
    "    from selenium.webdriver.support.ui import WebDriverWait\n",
    "    from selenium.webdriver.support import expected_conditions as EC\n",
    "    \n",
    "    chrome_options = webdriver.ChromeOptions()\n",
    "    chrome_options.add_argument('--headless')\n",
    "    driver = webdriver.Chrome(chrome_options=chrome_options)\n",
    "\n",
    "    base_url = 'http://nanjing.pbc.gov.cn'\n",
    "    \n",
    "    driver.get(base_url + '/nanjing/117512/index.html')\n",
    "    driver.execute_script(\"window.scrollTo(0,document.body.scrollHeight)\")\n",
    "    time.sleep(1)\n",
    "    \n",
    "#     print (driver.page_source)\n",
    "    xpath = '//td[@class=\"art_titdt\"]'\n",
    "    elements = driver.find_elements_by_xpath(xpath)\n",
    "    dates = ['' for ele in elements]    \n",
    "    xpath = '//td[@class=\"art_titdt\"]/a'\n",
    "    elements = driver.find_elements_by_xpath(xpath)\n",
    "    links = [ele.get_attribute(\"href\") for ele in elements]\n",
    "    titles = [ele.get_attribute(\"title\") for ele in elements]\n",
    "    \n",
    "    data_jiangsu = [ (t, l, d, 'jiangsu') for (t, l, d) in zip(titles, links, dates) ]\n",
    "    \n",
    "    \n",
    "    driver.get(base_url + '/nanjing/117532/index.html')\n",
    "    driver.execute_script(\"window.scrollTo(0,document.body.scrollHeight)\")\n",
    "    time.sleep(1)\n",
    "    \n",
    "#     print (driver.page_source)\n",
    "    xpath = '//td[@class=\"art_titjr\"]'\n",
    "    elements = driver.find_elements_by_xpath(xpath)\n",
    "    dates = [ele.text.replace(' ', '') for ele in elements]    \n",
    "    xpath = '//td[@class=\"art_titjr\"]/a'\n",
    "    elements = driver.find_elements_by_xpath(xpath)\n",
    "    links = [ele.get_attribute(\"href\") for ele in elements]\n",
    "    titles = [ele.get_attribute(\"title\") for ele in elements]\n",
    "    \n",
    "    data_jiangsu += [ (t, l, d, 'jiangsu') for (t, l, d) in zip(titles, links, dates) ]\n",
    "    \n",
    "    dict_jiangsu = [{'pos':x[3], 'title': x[0], 'link': x[1], 'date': x[2]} for x in data_jiangsu]\n",
    "  \n",
    "    print (len(dict_jiangsu))\n",
    "\n",
    "    print ('In {}, end, date is {}'.format(get_rmyh_jiangsu.__name__, time.strftime('%Y-%m-%d-%H:%M', time.localtime(time.time()))))\n",
    "\n",
    "    return dict_jiangsu\n",
    "\n",
    "def get_rmyh_zhejiang():\n",
    "#     //td[@height=23 or @class=\"font14\"]/a[@href and @target=\"_blank\"]\n",
    "    print ('In {}, begin, date is {}'.format(get_rmyh_zhejiang.__name__, time.strftime('%Y-%m-%d-%H:%M', time.localtime(time.time()))))\n",
    "    \n",
    "    from selenium import webdriver\n",
    "    from selenium.webdriver.common.by import By\n",
    "    from selenium.webdriver.support.ui import WebDriverWait\n",
    "    from selenium.webdriver.support import expected_conditions as EC\n",
    "    \n",
    "    chrome_options = webdriver.ChromeOptions()\n",
    "    chrome_options.add_argument('--headless')\n",
    "    driver = webdriver.Chrome(chrome_options=chrome_options)\n",
    "\n",
    "    base_url = 'http://hangzhou.pbc.gov.cn'\n",
    "    \n",
    "    driver.get(base_url + '/hangzhou/125264/index.html')\n",
    "    driver.execute_script(\"window.scrollTo(0,document.body.scrollHeight)\")\n",
    "    time.sleep(1)\n",
    "    \n",
    "#     print (driver.page_source)\n",
    "    xpath = '//td[@height=22]/span[2]'\n",
    "    elements = driver.find_elements_by_xpath(xpath)\n",
    "    dates = [ele.text for ele in elements]    \n",
    "    xpath = '//td[@height=22]/span[1]/a'\n",
    "    elements = driver.find_elements_by_xpath(xpath)\n",
    "    links = [ele.get_attribute(\"href\") for ele in elements]\n",
    "    titles = [ele.get_attribute(\"title\") for ele in elements]\n",
    "    \n",
    "    data_zhejiang = [ (t, l, d, 'zhejiang') for (t, l, d) in zip(titles, links, dates) ]\n",
    "    \n",
    "    \n",
    "    driver.get(base_url + '/hangzhou/125249/index.html')\n",
    "    driver.execute_script(\"window.scrollTo(0,document.body.scrollHeight)\")\n",
    "    time.sleep(1)\n",
    "    \n",
    "#     print (driver.page_source)\n",
    "    xpath = '//td[@height=22]/span[2]'\n",
    "    elements = driver.find_elements_by_xpath(xpath)\n",
    "    dates = [ele.text for ele in elements]    \n",
    "    xpath = '//td[@height=22]/span[1]/a'\n",
    "    elements = driver.find_elements_by_xpath(xpath)\n",
    "    links = [ele.get_attribute(\"href\") for ele in elements]\n",
    "    titles = [ele.get_attribute(\"title\") for ele in elements]\n",
    "    \n",
    "    data_zhejiang += [ (t, l, d, 'zhejiang') for (t, l, d) in zip(titles, links, dates) ]\n",
    "    \n",
    "    dict_zhejiang = [{'pos':x[3], 'title': x[0], 'link': x[1], 'date': x[2]} for x in data_zhejiang]\n",
    "  \n",
    "    print (len(dict_zhejiang))\n",
    "\n",
    "    print ('In {}, end, date is {}'.format(get_rmyh_zhejiang.__name__, time.strftime('%Y-%m-%d-%H:%M', time.localtime(time.time()))))\n",
    "\n",
    "    return dict_zhejiang\n",
    "\n",
    "def get_rmyh_guangdong():\n",
    "#     //td[@height=23 or @class=\"font14\"]/a[@href and @target=\"_blank\"]\n",
    "    print ('In {}, begin, date is {}'.format(get_rmyh_guangdong.__name__, time.strftime('%Y-%m-%d-%H:%M', time.localtime(time.time()))))\n",
    "    \n",
    "    from selenium import webdriver\n",
    "    from selenium.webdriver.common.by import By\n",
    "    from selenium.webdriver.support.ui import WebDriverWait\n",
    "    from selenium.webdriver.support import expected_conditions as EC\n",
    "    \n",
    "    chrome_options = webdriver.ChromeOptions()\n",
    "    chrome_options.add_argument('--headless')\n",
    "    driver = webdriver.Chrome(chrome_options=chrome_options)\n",
    "\n",
    "    base_url = 'http://guangzhou.pbc.gov.cn'\n",
    "    \n",
    "    driver.get(base_url + '/guangzhou/129136/index.html')\n",
    "    driver.execute_script(\"window.scrollTo(0,document.body.scrollHeight)\")\n",
    "    time.sleep(1)\n",
    "    \n",
    "    xpath = '//td[contains(@class, \"font14\")]'\n",
    "    elements = driver.find_elements_by_xpath(xpath)\n",
    "    dates = [ele.text[-10:] for ele in elements]   \n",
    "    xpath = '//td[contains(@class, \"font14\")]/a'\n",
    "    elements = driver.find_elements_by_xpath(xpath)\n",
    "    links = [ele.get_attribute(\"href\") for ele in elements]\n",
    "    titles = [ele.text for ele in elements]\n",
    "    \n",
    "    data_guangdong = [ (t, l, d, 'guangdong') for (t, l, d) in zip(titles, links, dates) ]\n",
    "    \n",
    "    \n",
    "    driver.get(base_url + '/guangzhou/129138/index.html')\n",
    "    driver.execute_script(\"window.scrollTo(0,document.body.scrollHeight)\")\n",
    "    time.sleep(1)\n",
    "    \n",
    "    xpath = '//td[contains(@class, \"font14\")]'\n",
    "    elements = driver.find_elements_by_xpath(xpath)\n",
    "    dates = [ele.text[-10:] for ele in elements]   \n",
    "    xpath = '//td[contains(@class, \"font14\")]/a'\n",
    "    elements = driver.find_elements_by_xpath(xpath)\n",
    "    links = [ele.get_attribute(\"href\") for ele in elements]\n",
    "    titles = [ele.text for ele in elements]\n",
    "    \n",
    "    data_guangdong += [ (t, l, d, 'guangdong') for (t, l, d) in zip(titles, links, dates) ]\n",
    "    \n",
    "    dict_guangdong = [{'pos':x[3], 'title': x[0], 'link': x[1], 'date': x[2]} for x in data_guangdong]\n",
    "  \n",
    "    print (len(dict_guangdong))\n",
    "    \n",
    "    print ('In {}, end, date is {}'.format(get_rmyh_guangdong.__name__, time.strftime('%Y-%m-%d-%H:%M', time.localtime(time.time()))))\n",
    "\n",
    "    return dict_guangdong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-07T08:07:51.718517Z",
     "start_time": "2018-08-07T08:07:51.700919Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_table(name):\n",
    "    import random\n",
    "    poses = ['china', 'guangdong', 'zhejiang', 'jiangsu']\n",
    "    random.shuffle(poses)\n",
    "    for pos in poses:\n",
    "        try:\n",
    "            db = pymysql.connect(host='119.29.190.115', user='impulse', password='njuacmicpc',\n",
    "                         port=3306, db='gov', write_timeout = 6, read_timeout = 6)\n",
    "            cursor = db.cursor()\n",
    "            for dic in globals()['get_{}_{}'.format(name, pos)]():\n",
    "                sql_insert(db=db,cursor=cursor,data=dic,table=name)\n",
    "        except Exception as err:\n",
    "            pass\n",
    "        finally:    \n",
    "            db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-07T08:07:52.444055Z",
     "start_time": "2018-08-07T08:07:52.428162Z"
    }
   },
   "outputs": [],
   "source": [
    "def run():\n",
    "    import random\n",
    "    tables = [ 'wms', 'swb','nyj', 'zscqj', 'jbw', 'zjh', 'yjh', 'rmyh']\n",
    "    random.shuffle(tables)\n",
    "    for tab in tables:\n",
    "        try:\n",
    "            get_table(tab)\n",
    "        except Exception as err:\n",
    "            print(\"Error {}\".format(err))\n",
    "            time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-07T08:08:19.089344Z",
     "start_time": "2018-08-07T08:08:09.169267Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In get_zjh_china, begin, date is 2018-08-07-16:08\n",
      "19\n",
      "In get_zjh_china, end, date is 2018-08-07-16:08\n",
      "Nothing to do\n",
      "Nothing to do\n",
      "Nothing to do\n",
      "Nothing to do\n",
      "Nothing to do\n",
      "Nothing to do\n",
      "Nothing to do\n",
      "Nothing to do\n",
      "Nothing to do\n",
      "Nothing to do\n",
      "Nothing to do\n",
      "Nothing to do\n",
      "Nothing to do\n",
      "Nothing to do\n",
      "Nothing to do\n",
      "Nothing to do\n",
      "Nothing to do\n",
      "Nothing to do\n",
      "Nothing to do\n",
      "In get_zjh_guangdong, begin, date is 2018-08-07-16:08\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-272-41f627089c73>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-271-89b39e761dee>\u001b[0m in \u001b[0;36mrun\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtab\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m             \u001b[0mget_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-270-6ef577380fcc>\u001b[0m in \u001b[0;36mget_table\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m      8\u001b[0m                          port=3306, db='gov', write_timeout = 6, read_timeout = 6)\n\u001b[1;32m      9\u001b[0m             \u001b[0mcursor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcursor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mdic\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mglobals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'get_{}_{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m                 \u001b[0msql_insert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcursor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcursor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdic\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-209-313035f8f40e>\u001b[0m in \u001b[0;36mget_zjh_guangdong\u001b[0;34m()\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0mchrome_options\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwebdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mChromeOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0mchrome_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_argument\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'--headless'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m     \u001b[0mdriver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwebdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mChrome\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchrome_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchrome_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0mbase_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'http://www.csrc.gov.cn/pub/zjhpublicofgd'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/selenium/webdriver/chrome/webdriver.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, executable_path, port, options, service_args, desired_capabilities, service_log_path, chrome_options)\u001b[0m\n\u001b[1;32m     73\u001b[0m                 command_executor=ChromeRemoteConnection(\n\u001b[1;32m     74\u001b[0m                     remote_server_addr=self.service.service_url),\n\u001b[0;32m---> 75\u001b[0;31m                 desired_capabilities=desired_capabilities)\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, command_executor, desired_capabilities, browser_profile, proxy, keep_alive, file_detector, options)\u001b[0m\n\u001b[1;32m    154\u001b[0m             warnings.warn(\"Please use FirefoxOptions to set browser profile\",\n\u001b[1;32m    155\u001b[0m                           DeprecationWarning)\n\u001b[0;32m--> 156\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcapabilities\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbrowser_profile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_switch_to\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSwitchTo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mobile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMobile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36mstart_session\u001b[0;34m(self, capabilities, browser_profile)\u001b[0m\n\u001b[1;32m    249\u001b[0m         parameters = {\"capabilities\": w3c_caps,\n\u001b[1;32m    250\u001b[0m                       \"desiredCapabilities\": capabilities}\n\u001b[0;32m--> 251\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCommand\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNEW_SESSION\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'sessionId'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'value'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrap_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, command, params)\u001b[0m\n\u001b[1;32m    470\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m         \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'%s%s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 472\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/remote_connection.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, method, url, body)\u001b[0m\n\u001b[1;32m    494\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparsed_url\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m                 \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhttplib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHTTPException\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1329\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1331\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1332\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
