{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-18T03:48:56.859541Z",
     "start_time": "2018-09-18T03:48:56.788387Z"
    }
   },
   "outputs": [],
   "source": [
    "import pymongo\n",
    "mongo_uri = 'mongodb://impulse:njuacmicpc@120.79.139.239/weibo'\n",
    "client = pymongo.MongoClient(host=mongo_uri, port=27017)\n",
    "db = client['weibo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-18T03:55:25.797421Z",
     "start_time": "2018-09-18T03:55:25.792019Z"
    }
   },
   "outputs": [],
   "source": [
    "# for name in ['good_words', 'bad_words']:\n",
    "#     collection = db[name]\n",
    "#     result = collection.find({'created_date':'2018-09-18'}, {'word':1,'senti':1,'good':1,'mid':1,'bad':1})\n",
    "#     for x in result:\n",
    "#         x.pop('_id')\n",
    "#         x['created_date'] = '2018-09-17'\n",
    "#         if collection.find(x).count() == 0:\n",
    "#             print (x)\n",
    "#             collection.insert_one(x)\n",
    "        \n",
    "# collection = db['word_tf']\n",
    "# result = collection.find({'created_date':'2018-09-18'}, {'word':1,'tf':1})\n",
    "# for x in result:\n",
    "#     x.pop('_id')\n",
    "#     x['created_date'] = '2018-09-17'\n",
    "#     if collection.find(x).count() == 0:\n",
    "#         print (x)\n",
    "#         collection.insert_one(x)\n",
    "\n",
    "# collection = db['word_tfidf']\n",
    "# result = collection.find({'created_date':'2018-09-18'}, {'word':1,'tfidf':1})\n",
    "# for x in result:\n",
    "#     x.pop('_id')\n",
    "#     x['created_date'] = '2018-09-17'\n",
    "#     if collection.find(x).count() == 0:\n",
    "#         print (x)\n",
    "#         collection.insert_one(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-25T14:23:22.472612Z",
     "start_time": "2018-08-25T14:23:22.295748Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.08197674, 0.01918605, 0.00767442, 0.00290698, 0.00127907,\n",
       "        0.00011628, 0.0005814 , 0.00069767, 0.00034884, 0.00011628,\n",
       "        0.00046512, 0.00023256, 0.        , 0.        , 0.00011628,\n",
       "        0.00023256, 0.        , 0.00011628, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.00011628, 0.        , 0.00011628]),\n",
       " array([  8. ,  16.6,  25.2,  33.8,  42.4,  51. ,  59.6,  68.2,  76.8,\n",
       "         85.4,  94. , 102.6, 111.2, 119.8, 128.4, 137. , 145.6, 154.2,\n",
       "        162.8, 171.4, 180. , 188.6, 197.2, 205.8, 214.4, 223. , 231.6,\n",
       "        240.2, 248.8, 257.4, 266. ]),\n",
       " <a list of 30 Patch objects>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt  # 绘图库\n",
    "plt.hist(ls, bins=30, color='steelblue', density=True )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# User Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import re, sys, bson\n",
    "collection = db['users']\n",
    "regex = re.compile('(?:谈股|财经|说股|期货|外汇|讲股|论股|看股|港股|美股|理财师|A股|经济政策|短线|炒股|荐股|盈亏|炒股|股利|股海|股民|股票|个股|做空|诱多|诱空|踏空|长空|短空|长多|短多|死多|翻多|翻空|多杀多|扎空|空仓|建仓|满仓|斩仓|减仓|加仓|重仓|清仓|套牢|补仓|仓位|庄家|震仓|追涨|杀跌|止盈|抄底|逃顶|盘整|回档|坐庄|吸筹|对敲|洗盘|散户|中户|坐轿|抬轿|筹码|抢帽子|多头陷阱|空头陷阱|护盘|跳空|开盘价|收盘价|最高价|最低价|成交量|放量|缩量|热门股|冷门股|白马股|黑马股|龙头股|阴跌|换手率|现手|平开|低开|高开|内盘|外盘|均价|浮筹|市盈率|含权|回购|基本面分析|量比|每股|收益|市净率|探底|填权|停牌|退市)')    \n",
    "nregex = re.compile('(?:公司|企业|CEO|基金会|大学|学院|政府)')\n",
    "\n",
    "weibo_list = collection.find({}, {'id': 1, 'description': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print (weibo_list.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "id_del = []\n",
    "for x in weibo_list:\n",
    "    desp = x['description']\n",
    "    if re.search(nregex, desp) != None or re.search(regex, desp) == None:\n",
    "        id_del.append(x['id'])\n",
    "\n",
    "for id in id_del:\n",
    "    collection.delete_one({'id': id})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "results = collection.find({}, {'id': 1})\n",
    "id_list = []\n",
    "for result in results:\n",
    "    id_list.append(str(result['id']))\n",
    "print (len(id_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "collection = db['weibos']\n",
    "results = collection.find({}, {'created_at': 1})\n",
    "time_list = []\n",
    "import re\n",
    "for result in results:\n",
    "    if re.search('2018-07-20', result['created_at']) != None:\n",
    "        time_list.append(str(result['created_at']))\n",
    "time_list = sorted(time_list, reverse=True)\n",
    "print (len(time_list))\n",
    "print (time_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "date = time.strftime('%Y-%m-%d', time.localtime())\n",
    "ldate = time.strftime('%Y-%m-%d', time.localtime(time.time() - 24 * 60 * 60))\n",
    "lldate = time.strftime('%Y-%m-%d', time.localtime(time.time() - 2 * 24 * 60 * 60))\n",
    "print (date)\n",
    "print (ldate)\n",
    "print (lldate)\n",
    "h = \"{}|{}|{}\".format(date, ldate, lldate)\n",
    "results1 = collection.find({'created_date': {'$regex': date}})\n",
    "results2 = collection.find({'created_date': {'$regex': ldate}})\n",
    "print (results1.count())\n",
    "print (results2.count())\n",
    "\n",
    "# weibo_id_list = []\n",
    "# for delete in deletes: \n",
    "#     weibo_id_list.append(delete['id'])\n",
    "# print (len(weibo_id_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print (weibo_id_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-26T01:21:20.066626Z",
     "start_time": "2018-07-26T01:21:20.063410Z"
    }
   },
   "source": [
    "## Load weibo_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-29T13:25:34.645881Z",
     "start_time": "2018-07-29T13:25:34.641098Z"
    }
   },
   "outputs": [],
   "source": [
    "import pymongo\n",
    "import pandas as pd\n",
    "def get_data():\n",
    "    client = pymongo.MongoClient(host='mongodb://impulse:njuacmicpc@120.79.139.239/weibo', port=27017)\n",
    "    db = client['weibo']\n",
    "    collection = db['weibos']\n",
    "    results = collection.find({}, {'id':1, 'user':1,'attitudes_count':1,'comments_count':1,'reposts_count':1,'text':1,'full_text':1})\n",
    "    \n",
    "    data = pd.DataFrame(list(results)[:500]) # modified\n",
    "    if 'attitudes_count' in data.columns: ## if it is normal\n",
    "        data = data.get(['user','attitudes_count','comments_count','reposts_count','text', 'full_text'])\n",
    "        data.columns = ['user', 'at_cnt', 'cmt_cnt', 'rep_cnt', 'text', 'f_text']\n",
    "        for i in range(len(data)):\n",
    "            if len(str(data.loc[i, 'f_text'])) > 135:\n",
    "                data.loc[i, 'text'] = data.loc[i, 'f_text']\n",
    "        data = data.drop('f_text', axis=1)\n",
    "    else:\n",
    "        print ('some errors occur')\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-15T14:26:50.269105Z",
     "start_time": "2018-08-15T14:26:50.249802Z"
    }
   },
   "outputs": [],
   "source": [
    "import pymongo, time\n",
    "import pandas as pd\n",
    "mongo_uri = 'mongodb://impulse:njuacmicpc@120.79.139.239/weibo'\n",
    "\n",
    "def get_data():\n",
    "    \n",
    "    print ('In {}, begin, date is {}'.format(get_data.__name__, time.strftime('%Y-%m-%d-%H:%M', time.localtime(time.time()))))\n",
    "\n",
    "    client = pymongo.MongoClient(host=mongo_uri, port=27017)\n",
    "    db = client['weibo']\n",
    "    collection = db['weibos']\n",
    "    results = collection.find({}, {'id':1,'user':1,'attitudes_count':1,'comments_count':1,'reposts_count':1,'text':1,'full_text':1})\n",
    "    print ('In {}: len of db: {}'.format(get_data.__name__, results.count()))\n",
    "    data = pd.DataFrame(list(results)) # for test\n",
    "    if 'attitudes_count' in data.columns: ## if it is normal\n",
    "        data = data.get(['id', 'user','attitudes_count','comments_count','reposts_count','text', 'full_text'])\n",
    "        data.columns = ['id', 'user', 'at_cnt', 'cmt_cnt', 'rep_cnt', 'text', 'f_text']\n",
    "        for i in range(len(data)):\n",
    "            if len(str(data.loc[i, 'f_text'])) > 135:\n",
    "                data.loc[i, 'text'] = data.loc[i, 'f_text']\n",
    "        data = data.drop('f_text', axis=1)        \n",
    "        print ('In {}: data loaded, len {}'.format(get_data.__name__, len(data)))\n",
    "    else:\n",
    "        print ('In {}: some errors occur'.format(get_data.__name__))        \n",
    "    \n",
    "    client.close()\n",
    "    print ('In {}, end, date is {}'.format(get_data.__name__, time.strftime('%Y-%m-%d-%H:%M', time.localtime(time.time()))))\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-15T14:37:26.341401Z",
     "start_time": "2018-08-15T14:26:51.127785Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In get_data, begin, date is 2018-08-15-22:26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/impulse/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:13: DeprecationWarning: count is deprecated. Use Collection.count_documents instead.\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In get_data: len of db: 50032\n",
      "In get_data: data loaded, len 50032\n",
      "In get_data, end, date is 2018-08-15-22:37\n"
     ]
    }
   ],
   "source": [
    "data = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-29T08:39:37.443168Z",
     "start_time": "2018-07-29T08:34:13.278222Z"
    }
   },
   "outputs": [],
   "source": [
    "client = pymongo.MongoClient(host='120.79.139.239', port=27017)\n",
    "db = client['weibo']\n",
    "collection = db['weibos']\n",
    "results = collection.find({}, {'user':1,'attitudes_count':1,'comments_count':1,'reposts_count':1,'text':1,'full_text':1})\n",
    "# data0 = pd.DataFrame(list(results))\n",
    "data0 = pd.DataFrame(columns={'user', 'at_cnt', 'cmt_cnt', 'rep_cnt', 'text', 'f_text'})\n",
    "dic = {'user':'user','at_cnt':'attitudes_count','cmt_cnt':'comments_count','rep_cnt':'reposts_count','text':'text','f_text':'full_text'}\n",
    "for cnt, raw in enumerate(results):    \n",
    "#     res = pd.DataFrame(columns={'user', 'at_cnt', 'cmt_cnt', 'rep_cnt', 'text', 'f_text'}, index=[cnt])\n",
    "    res = {}\n",
    "    for k, v in dic.items():\n",
    "        if v in raw:\n",
    "            res[k] = raw[v]\n",
    "        else:\n",
    "            res[k] = \"\"\n",
    "    \n",
    "    if len(res.get('f_text')) > 130:\n",
    "        res['text'] = res['f_text']\n",
    "        res['f_text'] = \"\"\n",
    "        \n",
    "    data0.loc[cnt] = res\n",
    "\n",
    "print (len(data0))\n",
    "print (data0.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-29T13:25:53.331766Z",
     "start_time": "2018-07-29T13:25:53.328226Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def read_stop_words(): \n",
    "    stop_words = []\n",
    "    stop_letters = []\n",
    "    with open('stop_words.txt') as sp:\n",
    "        for x in sp:\n",
    "            stop_words.append(x[:-1])\n",
    "    with open('stop_letters.txt') as sp:\n",
    "        for x in sp:\n",
    "            stop_letters.append(x[:-1])\n",
    "    stop_words = set(stop_words)\n",
    "    re_stop_letter = re.compile('|'.join(stop_letters))\n",
    "    return (stop_words, re_stop_letter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-29T13:25:55.149341Z",
     "start_time": "2018-07-29T13:25:54.005429Z"
    }
   },
   "outputs": [],
   "source": [
    "import re, jieba\n",
    "jieba.load_userdict('jieba_dict_companys')\n",
    "\n",
    "def get_clean_text(data, output=True):\n",
    "    texts = []\n",
    "    for cnt, raw in enumerate(data.text):\n",
    "        del_name = re.findall('@([^ |<|:|\\(|\\)|\\\\|\\/|<|>|\\[|\\]]+)', raw)\n",
    "        for name in del_name:\n",
    "            raw = re.sub(name, '', raw)\n",
    "        raw = re.sub('<br />', '，', raw)\n",
    "        raw = re.sub('[^\\u4e00-\\u9fa5|，|!|。]+|\\?{1}|:{1}', '', raw)\n",
    "        texts.append(raw)\n",
    "        \n",
    "        if cnt % 1000 == 0 and output == True:\n",
    "            print ('cnt = {}'.format(cnt))\n",
    "    if len(texts) == len(data):\n",
    "        return pd.Series(texts)\n",
    "    else:\n",
    "        print('not the same length')\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-29T13:26:04.275646Z",
     "start_time": "2018-07-29T13:26:03.743454Z"
    }
   },
   "outputs": [],
   "source": [
    "import re, jieba\n",
    "import jieba.posseg as postag\n",
    "                           \n",
    "def get_words(data, re_stop_letter, stop_words, output=True):\n",
    "    words = []\n",
    "    for cnt, raw in enumerate(data.c_text):\n",
    "        result = postag.cut(raw)\n",
    "        raw = [x.word for x in result if (len(x.word) > 1 and 'n' in x.flag and re.search(re_stop_letter, x.word) == None and x.word not in stop_words)]\n",
    "        words.append(raw)\n",
    "        \n",
    "        if cnt % 1000 == 0 and output == True:\n",
    "            print ('cnt = {}'.format(cnt))\n",
    "            \n",
    "    return pd.Series(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-29T13:26:05.525375Z",
     "start_time": "2018-07-29T13:26:05.522092Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_word_count(lst):\n",
    "    count = {}\n",
    "    for x in lst:\n",
    "        if x in count:\n",
    "            count[x] += 1\n",
    "        else:\n",
    "            count[x] = 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-29T13:37:30.072007Z",
     "start_time": "2018-07-29T13:37:30.065236Z"
    }
   },
   "outputs": [],
   "source": [
    "import requests, re, time, json\n",
    "\n",
    "# # sentiments\n",
    "def get_sentiment(data, output=True):\n",
    "    headers = {\n",
    "        'Content-Type': 'application/json'\n",
    "    }\n",
    "    params = {\n",
    "        'access_token': '24.cb5b8cccad6a49c21d4cccd1a047f9ae.2592000.1534940191.282335-11569351'\n",
    "    }\n",
    "    positive_prob = []\n",
    "    for cnt, (text, senti) in enumerate(zip(data.c_text, data.senti)):\n",
    "        \n",
    "        if isinstance(senti, int) or isinstance(senti, float):\n",
    "            positive_prob.append(senti)\n",
    "            print ('omit: {}'.format(cnt))\n",
    "            continue\n",
    "            \n",
    "        else:\n",
    "            start_time = time.clock()\n",
    "            post_json = {\n",
    "                \"text\": text\n",
    "            }\n",
    "    \n",
    "            response = requests.post('https://aip.baidubce.com/rpc/2.0/nlp/v1/sentiment_classify',\n",
    "                                    params=params, headers=headers, json=post_json)\n",
    "            if response.status_code != 200:\n",
    "                time.sleep(2.0)\n",
    "                response = requests.post('https://aip.baidubce.com/rpc/2.0/nlp/v1/sentiment_classify',\n",
    "                                    params=params, headers=headers, json=post_json)\n",
    "    \n",
    "            if response.text != None:\n",
    "                res_json = json.loads(response.text)\n",
    "                if res_json.get('items') != None and res_json.get('items')[0].get('positive_prob') != None: \n",
    "                    prob = res_json.get('items')[0].get('positive_prob')\n",
    "                    #print (prob)\n",
    "                    positive_prob.append(prob)\n",
    "                else:\n",
    "                    print('-1')\n",
    "                    positive_prob.append('-1')\n",
    "            else:\n",
    "                print('-1')\n",
    "                positive_prob.append('-1')\n",
    "            elapsed = (time.clock() - start_time)\n",
    "            time.sleep(0.21 - elapsed)\n",
    "\n",
    "        if cnt % 1000 == 0 and output:\n",
    "            print ('In {}: cnt = {}'.format(get_sentiment.__name__, cnt))\n",
    "    if len(data) != len(positive_prob):\n",
    "        print ('In {}: length not equal'.format(get_sentiment.__name__))\n",
    "        \n",
    "    return pd.Series(positive_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-29T13:31:34.985433Z",
     "start_time": "2018-07-29T13:26:20.946445Z"
    }
   },
   "outputs": [],
   "source": [
    "data = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-29T13:32:14.796076Z",
     "start_time": "2018-07-29T13:32:14.776285Z"
    }
   },
   "outputs": [],
   "source": [
    "stop_words, re_stop_letter = read_stop_words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-29T13:32:16.236874Z",
     "start_time": "2018-07-29T13:32:16.201403Z"
    }
   },
   "outputs": [],
   "source": [
    "data['c_text'] = get_clean_text(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-29T13:32:23.859381Z",
     "start_time": "2018-07-29T13:32:20.129227Z"
    }
   },
   "outputs": [],
   "source": [
    "data['words'] = get_words(data=data, re_stop_letter=re_stop_letter, stop_words=stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-29T13:34:35.602972Z",
     "start_time": "2018-07-29T13:34:35.597117Z"
    }
   },
   "outputs": [],
   "source": [
    "data['hash'] = [ int((hash(x)+len(str(y))*47)%(1e9+7)) for x, y in zip(data.text, data.user)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-29T13:34:35.602972Z",
     "start_time": "2018-07-29T13:34:35.597117Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-29T13:36:37.099730Z",
     "start_time": "2018-07-29T13:36:36.460013Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('../ScrapyDatas/weibo_test_data.csv')\n",
    "data['senti'] = pd.Series([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-29T13:38:10.806859Z",
     "start_time": "2018-07-29T13:38:07.951977Z"
    }
   },
   "outputs": [],
   "source": [
    "# notice ! in use !\n",
    "data['senti'] = get_sentiment(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-29T13:36:51.504620Z",
     "start_time": "2018-07-29T13:36:50.770046Z"
    }
   },
   "outputs": [],
   "source": [
    "data_prev = pd.read_csv('../ScrapyDatas/weibo_test_data.csv')\n",
    "senti_dict = dict([ (hs, sen) for hs, sen in zip(data_prev.hash, data_prev.senti)])\n",
    "\n",
    "# print (senti_dict)\n",
    "if 'senti' not in data:\n",
    "    data['senti'] = pd.Series([])\n",
    "\n",
    "new_senti = []\n",
    "for hs, sen in zip(data.hash, data.senti):\n",
    "    if isinstance(sen, int) and sen > 0 and sen < 1:\n",
    "        new_senti.append(sen)\n",
    "    elif hs in senti_dict:\n",
    "        new_senti.append(senti_dict[hs])\n",
    "    else:\n",
    "        new_senti.append('')\n",
    "    \n",
    "if len(new_senti) != len(data):\n",
    "    print('senti length error')\n",
    "    \n",
    "print (new_senti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-27T00:03:18.853175Z",
     "start_time": "2018-07-27T00:03:18.811812Z"
    }
   },
   "outputs": [],
   "source": [
    "word_counts = [ get_word_count(lst) for lst in data.words]\n",
    "data['dict'] = pd.Series(word_counts)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-27T00:03:18.867398Z",
     "start_time": "2018-07-27T00:03:18.855889Z"
    }
   },
   "outputs": [],
   "source": [
    "data['level'] = (1 + data.at_cnt) * (1 + data.rep_cnt) * (1 + data.cmt_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-27T00:03:19.025832Z",
     "start_time": "2018-07-27T00:03:18.873194Z"
    }
   },
   "outputs": [],
   "source": [
    "data2 = pd.read_csv('../ScrapyDatas/weibo_test_data.csv')\n",
    "data['senti'] = data2.senti"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-26T01:21:35.655384Z",
     "start_time": "2018-07-26T01:21:35.646720Z"
    }
   },
   "source": [
    "## load idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-27T00:03:30.437045Z",
     "start_time": "2018-07-27T00:03:30.425729Z"
    }
   },
   "outputs": [],
   "source": [
    "import math, numpy as np\n",
    "def tf(word, count):\n",
    "    return count[word] / sum(count.values())\n",
    "\n",
    "def n_containing(word, count_list):\n",
    "    return sum(1 for count in count_list if word in count)\n",
    "    \n",
    "def idf(word, count_list):\n",
    "    return math.log(len(count_list) / (1 + n_containing(word, count_list)))\n",
    "\n",
    "def tfidf(word, count, count_list):\n",
    "    return tf(word, count) * idf(word, count_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-27T00:03:33.855740Z",
     "start_time": "2018-07-27T00:03:32.650298Z"
    }
   },
   "outputs": [],
   "source": [
    "data_idf_dict = pd.read_csv('../ScrapyDatas/weibo_idf_dict.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-27T00:03:44.989324Z",
     "start_time": "2018-07-27T00:03:33.897449Z"
    }
   },
   "outputs": [],
   "source": [
    "data_idf_dict = [ eval(dic) for dic in np.array(data_idf_dict[1]).tolist() ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-27T00:03:45.040218Z",
     "start_time": "2018-07-27T00:03:44.994521Z"
    }
   },
   "outputs": [],
   "source": [
    "data_dict_all = {}\n",
    "for dic in data.dict:\n",
    "    for k, v in dic.items():\n",
    "        if k in data_dict_all:\n",
    "            data_dict_all[k] += v\n",
    "        else:\n",
    "            data_dict_all[k] = v\n",
    "            \n",
    "        if len(k) == 4:\n",
    "            head, tail = k[2:], k[:-2]\n",
    "            if head in data_dict_all:\n",
    "                data_dict_all[head] += v\n",
    "            else:\n",
    "                data_dict_all[head] = v\n",
    "                \n",
    "            if tail in data_dict_all:\n",
    "                data_dict_all[tail] += v\n",
    "            else:\n",
    "                data_dict_all[tail] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-27T00:03:51.812349Z",
     "start_time": "2018-07-27T00:03:45.041942Z"
    }
   },
   "outputs": [],
   "source": [
    "# remove not nouns\n",
    "\n",
    "from snownlp import SnowNLP\n",
    "def tpok(word):\n",
    "    string = str(word)\n",
    "    s = SnowNLP(string)\n",
    "    ls = list(s.tags)\n",
    "    if len(ls) >= 3:\n",
    "        return False\n",
    "    if len(ls) == 1 and 'n' not in ls[0][1]:\n",
    "        return False\n",
    "    if len(word) == 2:\n",
    "        tail = str(word[-1])\n",
    "        st = SnowNLP(tail)\n",
    "        ls = list(st.tags)\n",
    "        if len(ls) == 1 and ls[0][1] == 'v':\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "data_dict_all = dict([ (k, v) for k, v in data_dict_all.items() if tpok(k)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-27T00:03:51.825381Z",
     "start_time": "2018-07-27T00:03:51.813827Z"
    }
   },
   "outputs": [],
   "source": [
    "data_dict_all = dict(sorted(data_dict_all.items(), key=lambda x: math.sqrt(len(x[0]))*x[1], reverse=True))\n",
    "data_dict_all = dict([(x,y) for x,y in data_dict_all.items() if y > 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-27T00:03:51.864885Z",
     "start_time": "2018-07-27T00:03:51.827543Z"
    }
   },
   "outputs": [],
   "source": [
    "data_words_list_clean = []\n",
    "for dic in data.dict:\n",
    "    data_words_clean = {}\n",
    "    for k, v in dic.items():\n",
    "        if k in data_dict_all:\n",
    "            data_words_clean[k] = v\n",
    "    data_words_list_clean.append(data_words_clean)\n",
    "\n",
    "data.dict = data_words_list_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### have dict for each, get dict for all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-27T01:00:49.111516Z",
     "start_time": "2018-07-27T01:00:46.770160Z"
    }
   },
   "outputs": [],
   "source": [
    "data_idf_dict_all = {}\n",
    "for dic in data_idf_dict:\n",
    "    for k, v in dic.items():\n",
    "        if k in data_idf_dict_all:\n",
    "            data_idf_dict_all[k] += v\n",
    "        else:\n",
    "            data_idf_dict_all[k] = v\n",
    "            \n",
    "        if len(k) == 4:\n",
    "            head, tail = k[2:], k[:-2]\n",
    "            if head in data_idf_dict_all:\n",
    "                data_idf_dict_all[head] += v\n",
    "            else:\n",
    "                data_idf_dict_all[head] = v\n",
    "                \n",
    "            if tail in data_idf_dict_all:\n",
    "                data_idf_dict_all[tail] += v\n",
    "            else:\n",
    "                data_idf_dict_all[tail] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-27T01:00:50.499359Z",
     "start_time": "2018-07-27T01:00:50.167482Z"
    }
   },
   "outputs": [],
   "source": [
    "data_idf_dict_all = dict(sorted(data_idf_dict_all.items(), key=lambda x: math.sqrt(len(x[0]))*x[1], reverse=True))\n",
    "data_idf_dict_all = dict([(x,y) for x,y in data_idf_dict_all.items() if y > 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-26T01:37:19.267989Z",
     "start_time": "2018-07-26T01:37:19.265623Z"
    }
   },
   "source": [
    "### work idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 关键词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-27T01:00:53.170110Z",
     "start_time": "2018-07-27T01:00:53.089505Z"
    }
   },
   "outputs": [],
   "source": [
    "# only tf for all\n",
    "print(\"Top words in all documents\")\n",
    "all_scores = { word: tf(word, data_dict_all) for word in data_dict_all}\n",
    "all_sorted_words = sorted(all_scores.items(), key=lambda x: math.sqrt(len(x[0]))*x[1], reverse=True)\n",
    "for word, score in all_sorted_words[:100]:\n",
    "    print(\"\\tWord: {}, TF: {}\".format(word, round(score, 5))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-27T01:01:08.603657Z",
     "start_time": "2018-07-27T01:00:55.666883Z"
    }
   },
   "outputs": [],
   "source": [
    "# tf-idf for all\n",
    "print(\"Top words in all documents\")\n",
    "\n",
    "all_scores = { word : tfidf(word, data_dict_all, data_idf_dict_all)\n",
    "                     for word in data_dict_all }\n",
    "all_sorted_words = sorted(all_scores.items(), key=lambda x: math.sqrt(len(x[0]))*x[1], reverse=True)\n",
    "for word, score in all_sorted_words[:100]:\n",
    "    print(\"\\tWord: {}, TF-IDF: {}\".format(word, round(score, 5))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-27T00:04:43.634573Z",
     "start_time": "2018-07-27T00:04:43.626529Z"
    }
   },
   "outputs": [],
   "source": [
    "### 输出关键词\n",
    "## TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-27T01:01:15.897909Z",
     "start_time": "2018-07-27T01:01:15.885565Z"
    }
   },
   "outputs": [],
   "source": [
    "# tf-idf for each\n",
    "\n",
    "def get_critical_words(data):\n",
    "    countlist = data.dict\n",
    "    critical_words = []\n",
    "    for i, count in enumerate(data.dict):\n",
    "        #print(\"Top words in document {}\".format(i))\n",
    "        scores = {word: tfidf(word, count, data_idf_dict) for word in count}\n",
    "        sorted_words = sorted(scores.items(), key=lambda x: math.sqrt(len(x[0]))*x[1], reverse=True)\n",
    "        critical_word = []\n",
    "        for word, score in sorted_words[:3]:\n",
    "            critical_word.append(word)\n",
    "            #print(\"\\tWord: {}, TF-IDF: {}\".format(word, round(score, 3))) \n",
    "        critical_words.append(critical_word)\n",
    "        if i % 100 == 0:\n",
    "            print ('cnt = {}'.format(i))\n",
    "    return critical_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-27T00:18:46.730316Z",
     "start_time": "2018-07-27T00:04:47.396721Z"
    }
   },
   "outputs": [],
   "source": [
    "critical_words_list = get_critical_words(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-27T01:01:28.575436Z",
     "start_time": "2018-07-27T01:01:28.567301Z"
    }
   },
   "outputs": [],
   "source": [
    "data['critical_word'] = critical_words_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-26T03:13:13.791592Z",
     "start_time": "2018-07-26T03:13:13.782519Z"
    }
   },
   "outputs": [],
   "source": [
    "#data.to_csv('../ScrapyDatas/weibo_test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-27T01:01:31.170116Z",
     "start_time": "2018-07-27T01:01:31.141388Z"
    }
   },
   "outputs": [],
   "source": [
    "word_senti = {}\n",
    "for sen, cri_word in zip(data.senti, data.critical_word):\n",
    "    #print(sen)\n",
    "    #print (cri_word)\n",
    "    for w in cri_word:\n",
    "        if sen == None or not isinstance(sen, float) or sen < 0:\n",
    "            continue\n",
    "        if (sen > 0.7):\n",
    "            if w in word_senti:\n",
    "                word_senti[w] += 1\n",
    "            else:\n",
    "                word_senti[w] = 1\n",
    "        if (sen < 0.3):\n",
    "            if w in word_senti:\n",
    "                word_senti[w] -= 1\n",
    "            else:\n",
    "                word_senti[w] = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 好坏词语"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-27T01:01:32.956381Z",
     "start_time": "2018-07-27T01:01:32.947407Z"
    }
   },
   "outputs": [],
   "source": [
    "word_senti_posi = sorted(word_senti.items(), key=lambda x: x[1], reverse=True)[:30]\n",
    "word_senti_nega = sorted(word_senti.items(), key=lambda x: x[1], reverse=False)[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-27T01:01:33.994784Z",
     "start_time": "2018-07-27T01:01:33.986490Z"
    }
   },
   "outputs": [],
   "source": [
    "for x in word_senti_posi:\n",
    "    print (x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-27T01:01:35.291779Z",
     "start_time": "2018-07-27T01:01:35.272630Z"
    }
   },
   "outputs": [],
   "source": [
    "for x in word_senti_nega:\n",
    "    print (x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-26T14:58:32.076303Z",
     "start_time": "2018-07-26T14:58:32.068066Z"
    }
   },
   "outputs": [],
   "source": [
    "### 输出好坏词语\n",
    "## TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-26T15:01:00.564007Z",
     "start_time": "2018-07-26T15:01:00.556909Z"
    }
   },
   "source": [
    "### 词语网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-27T01:16:03.672026Z",
     "start_time": "2018-07-27T01:16:03.659534Z"
    }
   },
   "outputs": [],
   "source": [
    "class Graph(object):\n",
    "    def __init__(self):\n",
    "        self.node_cnt = 0\n",
    "        self.id = {}\n",
    "        self.value = {}\n",
    "        self.deg = {}\n",
    "        self.name = {}\n",
    "        self.edges = {}\n",
    "        self.lim = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-27T01:16:04.427282Z",
     "start_time": "2018-07-27T01:16:04.414573Z"
    }
   },
   "outputs": [],
   "source": [
    "wG = Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-27T01:16:05.325325Z",
     "start_time": "2018-07-27T01:16:05.285610Z"
    }
   },
   "outputs": [],
   "source": [
    "for dic in data.dict:\n",
    "    for x in dic.keys():\n",
    "        if x not in wG.id:\n",
    "            wG.id[x] = wG.node_cnt\n",
    "            wG.node_cnt += 1\n",
    "            idx = wG.id[x]\n",
    "            wG.name[idx] = x\n",
    "            wG.value[idx] = 1\n",
    "            wG.deg[idx] = 0\n",
    "            wG.edges[idx] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-27T01:16:06.619310Z",
     "start_time": "2018-07-27T01:16:06.575174Z"
    }
   },
   "outputs": [],
   "source": [
    "for dic in data.dict:\n",
    "    for x in dic.keys():\n",
    "        idx = wG.id[x]\n",
    "        if idx not in wG.deg:\n",
    "            wG.deg[idx] = len(dic) - 1\n",
    "        else:\n",
    "            wG.deg[idx] += len(dic) - 1\n",
    "del_idx = set()\n",
    "for idx, val in wG.deg.items():\n",
    "    if val < wG.lim:\n",
    "        del_idx.add(idx)\n",
    "for idx in del_idx:\n",
    "    wG.name.pop(idx)\n",
    "    wG.deg.pop(idx)\n",
    "    wG.value.pop(idx)\n",
    "    wG.edges.pop(idx)\n",
    "wG.id = dict([ (k, v) for k, v in wG.id.items() if v not in del_idx ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-27T01:16:07.736147Z",
     "start_time": "2018-07-27T01:16:07.645294Z"
    }
   },
   "outputs": [],
   "source": [
    "for dic in data.dict:\n",
    "    for x in dic.keys():\n",
    "        if x in wG.id:\n",
    "            idx = wG.id[x]\n",
    "            for y in dic.keys():\n",
    "                if y != x and y in wG.id:\n",
    "                    idy = wG.id[y]\n",
    "                    if idx not in wG.edges[idy]:\n",
    "                        wG.edges[idx][idy] = 1\n",
    "                        wG.edges[idy][idx] = 1\n",
    "                    else:\n",
    "                        wG.edges[idx][idy] += 1\n",
    "                        wG.edges[idy][idx] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-27T01:16:08.862093Z",
     "start_time": "2018-07-27T01:16:08.849892Z"
    }
   },
   "outputs": [],
   "source": [
    "wG.edges = dict(sorted([ (k, v) for k, v in wG.edges.items() if len(v) > 1 ], key = lambda x: -len(x[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-27T01:16:11.158483Z",
     "start_time": "2018-07-27T01:16:11.136111Z"
    }
   },
   "outputs": [],
   "source": [
    "for x in [ {wG.name[idx]: { wG.name[idy]: v for idy, v in chx.items() if idy in wG.name} } for idx, chx in wG.edges.items()] :\n",
    "    print (x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top weibos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-27T00:26:33.728380Z",
     "start_time": "2018-07-27T00:26:33.703258Z"
    }
   },
   "outputs": [],
   "source": [
    "hottest_data = data.sort_values(by='level', axis=0, ascending=False)[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-27T00:26:34.832247Z",
     "start_time": "2018-07-27T00:26:34.810099Z"
    }
   },
   "outputs": [],
   "source": [
    "print (hottest_data.get(['level', 'text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-27T11:40:21.032614Z",
     "start_time": "2018-07-27T11:40:21.029797Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-27T11:47:07.862314Z",
     "start_time": "2018-07-27T11:47:07.848330Z"
    }
   },
   "outputs": [],
   "source": [
    "hash_list = [ int((hash(x)+len(str(y))*47)%(1e9+7)) for x, y in zip(data.text, data.user)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-27T11:47:08.511016Z",
     "start_time": "2018-07-27T11:47:08.491221Z"
    }
   },
   "outputs": [],
   "source": [
    "data['hash'] = hash_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-27T12:08:17.909533Z",
     "start_time": "2018-07-27T12:08:17.902939Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame([[1,2,3,4],[1,2,3,4],[1,'',2],[1,4,'']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-27T12:09:27.162219Z",
     "start_time": "2018-07-27T12:09:27.153435Z"
    }
   },
   "outputs": [],
   "source": [
    "df.columns = ['a','b','c','d']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-27T12:11:00.927797Z",
     "start_time": "2018-07-27T12:11:00.916693Z"
    }
   },
   "outputs": [],
   "source": [
    "def t1(df):\n",
    "    for cnt, (x, y) in enumerate(zip(df.e,df.a)):\n",
    "        if not isinstance(x, int):\n",
    "            df.loc[cnt,'e'] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-27T12:11:12.394581Z",
     "start_time": "2018-07-27T12:11:12.380693Z"
    }
   },
   "outputs": [],
   "source": [
    "t1(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-27T12:10:46.749092Z",
     "start_time": "2018-07-27T12:10:46.743431Z"
    }
   },
   "outputs": [],
   "source": [
    "df['e'] = pd.Series([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-27T13:27:47.528649Z",
     "start_time": "2018-07-27T13:27:47.480948Z"
    }
   },
   "outputs": [],
   "source": [
    "dict([ (hs, sen) for hs, sen in zip(data2.hash, data2.senti)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-28T02:55:49.870030Z",
     "start_time": "2018-07-28T02:55:49.859723Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.width', 10000)  # 设置字符显示宽度\n",
    "pd.set_option('display.max_rows', None)  # 设置显示最大行\n",
    "pd.set_option('display.max_colwidth',1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-28T03:05:35.407865Z",
     "start_time": "2018-07-28T03:05:35.283537Z"
    }
   },
   "outputs": [],
   "source": [
    "for text in data2.text:\n",
    "    text = re.sub('<.*?>', '', text)\n",
    "    text = text.replace(\"\\\\n\", '')\n",
    "    print (text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-28T03:45:46.193240Z",
     "start_time": "2018-07-28T03:45:46.185947Z"
    }
   },
   "outputs": [],
   "source": [
    "senti_dict = dict([ (hs, sen) for hs, sen in zip(data.hash, data.senti)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-28T03:48:44.042090Z",
     "start_time": "2018-07-28T03:48:44.030493Z"
    }
   },
   "outputs": [],
   "source": [
    "data3=data2\n",
    "data3['senti'] = pd.Series([])\n",
    "if 'senti' not in data3:\n",
    "    data3['senti'] = pd.Series([])\n",
    "\n",
    "new_senti = []\n",
    "for hs, sen in zip(data.hash, data.senti):\n",
    "    if isinstance(sen, int) and sen > 0 and sen < 1:\n",
    "        new_senti.append(sen)\n",
    "    elif hs in senti_dict:\n",
    "        new_senti.append(senti_dict[hs])\n",
    "    else:\n",
    "        new_senti.append('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-28T10:16:17.459044Z",
     "start_time": "2018-07-28T10:16:17.456022Z"
    }
   },
   "outputs": [],
   "source": [
    "week=[ time.strftime('%Y-%m-%d', time.localtime(time.time() - x * 24 * 60 * 60)) for x in range(7) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-29T01:48:26.104230Z",
     "start_time": "2018-07-29T01:48:26.100263Z"
    }
   },
   "outputs": [],
   "source": [
    "data_idf_iterator = pd.read_csv('../ScrapyDatas/weibo_idf_dict.csv', chunksize=10000, header=None)\n",
    "\n",
    "data_idf_dict = []\n",
    "for data_chunk in data_idf_iterator:\n",
    "    data_idf_dict_chunk = [ eval(dic) for dic in np.array(data_chunk[1]).tolist() ]\n",
    "    data_idf_dict.extend(data_idf_dict_chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-29T01:49:34.991221Z",
     "start_time": "2018-07-29T01:49:34.987761Z"
    }
   },
   "outputs": [],
   "source": [
    "print (data_idf_dict[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-04T16:24:42.117673Z",
     "start_time": "2018-08-04T16:24:41.481412Z"
    }
   },
   "outputs": [],
   "source": [
    "import pymongo\n",
    "import pandas as pd\n",
    "import re, time, requests\n",
    "mongo_uri = 'mongodb://impulse:njuacmicpc@120.79.139.239/weibo'\n",
    "client = pymongo.MongoClient(host=mongo_uri, port=27017)\n",
    "db = client['weibo']\n",
    "collection = db['weibos']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-04T16:29:22.395821Z",
     "start_time": "2018-08-04T16:29:22.385772Z"
    }
   },
   "outputs": [],
   "source": [
    "results = collection.find({}, {'user':1,'attitudes_count':1,'text':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-01T12:48:12.449365Z",
     "start_time": "2018-08-01T12:48:12.137614Z"
    }
   },
   "outputs": [],
   "source": [
    "collection.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-01T12:10:00.243370Z",
     "start_time": "2018-08-01T12:10:00.182170Z"
    }
   },
   "outputs": [],
   "source": [
    "collection.find_one({'id':'4266105453476132'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T16:09:38.717525Z",
     "start_time": "2018-07-31T16:09:38.662433Z"
    }
   },
   "outputs": [],
   "source": [
    "collection.update({'id':'4266105453476132'}, {'$set': {'senti':0.075441} })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T16:27:46.733248Z",
     "start_time": "2018-07-31T16:27:46.180217Z"
    }
   },
   "outputs": [],
   "source": [
    "data_prev = pd.read_csv('../ScrapyDatas/weibo_test_data.csv')\n",
    "len(data_prev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T16:54:05.204057Z",
     "start_time": "2018-07-31T16:27:47.840155Z"
    }
   },
   "outputs": [],
   "source": [
    "for x in zip(list(data_prev.id), list(data_prev.senti)):\n",
    "    collection.update({'id':str(x[0])}, {'$set': {'senti':float(x[1])} })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-01T01:19:55.254546Z",
     "start_time": "2018-08-01T01:19:55.210858Z"
    }
   },
   "outputs": [],
   "source": [
    "collection_good = db['good_words']\n",
    "collection_good.insert_one({'word':str('性质'), 'senti':float(-14)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-01T01:59:25.442690Z",
     "start_time": "2018-08-01T01:59:25.436886Z"
    }
   },
   "outputs": [],
   "source": [
    "x = ('疫苗', [('李克强', 36), ('道德', 30), ('国务院', 22), ('医药', 22), ('康泰', 20), ('腾讯', 6), ('阶段性', 6), ('丽水', 2), ('竹乡', 2), ('涉嫌犯罪', 8), ('公安机关', 8), ('存量', 4)])`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-01T12:36:01.946790Z",
     "start_time": "2018-08-01T12:36:01.932869Z"
    }
   },
   "outputs": [],
   "source": [
    "print ('In {}, begin, date is {}'.format('fe', time.strftime('%Y-%m-%d-%H:%M', time.localtime(time.time()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weibo.weibos的格式：\n",
    "{\n",
    "    \"_id\" : ObjectId(\"5b66edecc6769559cbd37f4c\"),\n",
    "    # 索引 ; 自动生成\n",
    "    \"id\" : \"4269654501116032\",\n",
    "    # 微博编号 ; 非负整数\n",
    "    \"attitudes_count\" : 1,\n",
    "    # 点赞数 ; 非负整数\n",
    "    \"comments_count\" : 0,\n",
    "    # 评论数 ; 非负整数\n",
    "    \"reposts_count\" : 0,\n",
    "    # 转发数 ; 非负整数\n",
    "    \"created_at\" : \"2018-08-05 00:00\",\n",
    "    # 创建时间 ; '%Y-%m-%d %H:%M'\n",
    "    \"source\" : \"月亮点金股市论坛超话\",           \n",
    "    # 来源，貌似没什么用 ; 普通文本\n",
    "    \"text\" : \"周评出炉 下周需注意几点：\",        \n",
    "    # 原微博 ; HTML格式（可能爬取残缺）\n",
    "    \"user\" : \"3146057615\", \n",
    "    # 微博用户名 ; 非负整数\n",
    "    \"crawled_at\" : \"2018-08-12 20:30\",\n",
    "    # 爬取时间 ; '%Y-%m-%d %H:%M'\n",
    "    \"created_date\" : \"2018-08-05\",\n",
    "    # 创建日期 ; '%Y-%m-%d'\n",
    "    \"full_text\" : \"......\"                   \n",
    "    # 原微博全文（如果‘text’不全则有‘full_text',我可以合并起来）; HTML格式（可能爬取残缺）\n",
    "    \"senti\" : 0.687963,\n",
    "    # 情感倾向 ; （0,1）间小数\n",
    "    \"level\" : 2\n",
    "    # 热门指标，即（点+1）×（评+1）×（转+1）; 非负整数\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weibo.word_tf的格式：## tf指词频\n",
    "{\n",
    "    \"_id\" : ObjectId(\"5b70a2d52309e626a47b3921\"),\n",
    "    # 索引 ; 自动生成\n",
    "    \"word\" : \"股份\",\n",
    "    # 词语 ; 普通文本\n",
    "    \"tf\" : 0.013,\n",
    "    # 词频： 普通浮点数\n",
    "    \"created_date\" : \"2018-08-13\"\n",
    "    # 创建日期 ; '%Y-%m-%d'\n",
    "}\n",
    "\n",
    "weibo.word_tfidf的格式：## tfidf指词频乘以逆频率\n",
    "{\n",
    "    \"_id\" : ObjectId(\"5b70a2d52309e626a47b3921\"),\n",
    "    # 索引 ; 自动生成\n",
    "    \"word\" : \"股份\",\n",
    "    # 词语 ; 普通文本\n",
    "    \"tfidf\" : 0.013,\n",
    "    # 词频乘以逆频率： 普通浮点数\n",
    "    \"created_date\" : \"2018-08-13\"\n",
    "    # 创建日期 ; '%Y-%m-%d'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weibo.good_words的格式：## good_words指senti较高的词语\n",
    "{\n",
    "    \"_id\" : ObjectId(\"5b70a2f42309e626a47b3d09\"),\n",
    "    \"word\" : \"原油\",\n",
    "    \"senti\" : 275.0,\n",
    "    \"created_date\" : \"2018-08-13\"\n",
    "}\n",
    "\n",
    "weibo.bad_words的格式：## bad_words指senti较低的词语\n",
    "{\n",
    "    \"_id\" : ObjectId(\"5b70a2f92309e626a47b3efd\"),\n",
    "    \"word\" : \"答题卡\",\n",
    "    \"senti\" : -81.0,\n",
    "    \"created_date\" : \"2018-08-13\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weibo.word_graph：## word_graph指词语之间的关系图\n",
    "{\n",
    "    \"_id\" : ObjectId(\"5b70a2fd2309e626a47b4110\"),\n",
    "    # 索引 ; 自动生成\n",
    "    \"vertex\" : \"橡胶\",\n",
    "    # （词语）节点 ; 普通文本\n",
    "    \"adjacent-list\" : [ \n",
    "        [ \n",
    "            \"苹果\", \n",
    "            526\n",
    "        ], \n",
    "        [ \n",
    "            \"原油\", \n",
    "            528\n",
    "        ], \n",
    "        [ \n",
    "            \"黄金\", \n",
    "            488\n",
    "        ], \n",
    "    ]\n",
    "    # （表示节点关系的）邻接表 ; list套list， 其中内层的list表示边的另一个节点，以及边权（越大表示词语之间的关系越大）\n",
    "    #  相当于 std::vector<std::pair<std::string,int>>\n",
    "    \"created_date\" : \"2018-08-13\"\n",
    "    # 创建日期 ; '%Y-%m-%d'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-19T07:31:57.095309Z",
     "start_time": "2018-10-19T07:31:57.090809Z"
    }
   },
   "outputs": [],
   "source": [
    "import pymongo\n",
    "mongo_uri = 'mongodb://impulse:njuacmicpc@120.79.139.239/weibo'\n",
    "client = pymongo.MongoClient(host=mongo_uri, port=27017)\n",
    "db = client['weibo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-19T07:32:59.518912Z",
     "start_time": "2018-10-19T07:31:57.868222Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "collection = db['users']\n",
    "data = pd.DataFrame(list(collection.find({})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-19T07:33:43.567238Z",
     "start_time": "2018-10-19T07:33:43.521491Z"
    }
   },
   "outputs": [],
   "source": [
    "data = data[['_id', 'description', 'fans_count', 'gender',\n",
    "             'name', 'verified_reason', 'verified_type', 'weibos_count']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-19T07:33:44.433326Z",
     "start_time": "2018-10-19T07:33:44.375709Z"
    }
   },
   "outputs": [],
   "source": [
    "data['text'] = data['description']\n",
    "data['reason'] = data['verified_reason']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-19T07:33:45.555744Z",
     "start_time": "2018-10-19T07:33:45.540254Z"
    }
   },
   "outputs": [],
   "source": [
    "data = data.drop(axis=0,columns=['description', 'verified_reason'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-19T07:33:46.457401Z",
     "start_time": "2018-10-19T07:33:46.419814Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>fans_count</th>\n",
       "      <th>gender</th>\n",
       "      <th>name</th>\n",
       "      <th>verified_type</th>\n",
       "      <th>weibos_count</th>\n",
       "      <th>text</th>\n",
       "      <th>reason</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5b4e065dbc23929e06e31dab</td>\n",
       "      <td>784</td>\n",
       "      <td>m</td>\n",
       "      <td>腾龙创富</td>\n",
       "      <td>2</td>\n",
       "      <td>68</td>\n",
       "      <td>致力于资产管理、期货股票投资指导、专业操盘手实战培训。</td>\n",
       "      <td>安徽腾龙创富金融信息服务有限公司</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5b4e0665bc23929e06e31db2</td>\n",
       "      <td>170</td>\n",
       "      <td>m</td>\n",
       "      <td>品股话投资</td>\n",
       "      <td>2</td>\n",
       "      <td>168</td>\n",
       "      <td>赣南有脐橙，国内皆有名！卖了脐橙买股票，持好股票卖脐橙，我是认真的，购橙V信：cwy1333...</td>\n",
       "      <td>龙南艾德礼品有限公司官方微博</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5b4e0674bc23929e06e31dbf</td>\n",
       "      <td>6076</td>\n",
       "      <td>m</td>\n",
       "      <td>月亮点金</td>\n",
       "      <td>0</td>\n",
       "      <td>556</td>\n",
       "      <td>知名财经博主 头条文章作者 微博签约自媒体</td>\n",
       "      <td>财经博主</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5b4e06aabc23929e06e31de3</td>\n",
       "      <td>3453</td>\n",
       "      <td>m</td>\n",
       "      <td>李信玄</td>\n",
       "      <td>0</td>\n",
       "      <td>7498</td>\n",
       "      <td>我的微信号：sz06888，欢迎大家前来交流学习，免费解答个股问题。</td>\n",
       "      <td>财经博主 头条文章作者</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5b4e06b6bc23929e06e31deb</td>\n",
       "      <td>76142</td>\n",
       "      <td>m</td>\n",
       "      <td>股道老张</td>\n",
       "      <td>0</td>\n",
       "      <td>13909</td>\n",
       "      <td>拥有丰富的解盘及操盘实战经验，对于热点题材龙头个股的把握较为精准并擅长把握各类主题投资机会。...</td>\n",
       "      <td>财经博主 头条文章作者 微博签约自媒体</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        _id  fans_count gender   name  verified_type  \\\n",
       "0  5b4e065dbc23929e06e31dab         784      m   腾龙创富              2   \n",
       "1  5b4e0665bc23929e06e31db2         170      m  品股话投资              2   \n",
       "2  5b4e0674bc23929e06e31dbf        6076      m   月亮点金              0   \n",
       "3  5b4e06aabc23929e06e31de3        3453      m    李信玄              0   \n",
       "4  5b4e06b6bc23929e06e31deb       76142      m   股道老张              0   \n",
       "\n",
       "   weibos_count                                               text  \\\n",
       "0            68                        致力于资产管理、期货股票投资指导、专业操盘手实战培训。   \n",
       "1           168  赣南有脐橙，国内皆有名！卖了脐橙买股票，持好股票卖脐橙，我是认真的，购橙V信：cwy1333...   \n",
       "2           556                              知名财经博主 头条文章作者 微博签约自媒体   \n",
       "3          7498                 我的微信号：sz06888，欢迎大家前来交流学习，免费解答个股问题。   \n",
       "4         13909  拥有丰富的解盘及操盘实战经验，对于热点题材龙头个股的把握较为精准并擅长把握各类主题投资机会。...   \n",
       "\n",
       "                reason  \n",
       "0     安徽腾龙创富金融信息服务有限公司  \n",
       "1       龙南艾德礼品有限公司官方微博  \n",
       "2                 财经博主  \n",
       "3          财经博主 头条文章作者  \n",
       "4  财经博主 头条文章作者 微博签约自媒体  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-19T07:39:55.616413Z",
     "start_time": "2018-10-19T07:39:54.655734Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.cluster import KMeans\n",
    "import jieba\n",
    "import re\n",
    "import math\n",
    "import jieba.posseg as postag\n",
    "\n",
    "def read_stop_words():\n",
    "    stop_words = []\n",
    "    stop_letters = []\n",
    "    with open('clustering_stop_words.txt') as sp:\n",
    "        for x in sp:\n",
    "            stop_words.append(x[:-1])\n",
    "\n",
    "    stop_words = set(stop_words)\n",
    "    return stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-19T07:39:55.758972Z",
     "start_time": "2018-10-19T07:39:55.751569Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "stop_words = read_stop_words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-19T07:40:02.548731Z",
     "start_time": "2018-10-19T07:39:56.356300Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Dumping model to file cache /tmp/jieba.cache\n",
      "Loading model cost 0.800 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR expected string or bytes-like object\n"
     ]
    }
   ],
   "source": [
    "documents = list(data.text)\n",
    "causes = list(data.reason)\n",
    "\n",
    "sentences_text, sentences_reason = [], []\n",
    "for sen in documents:\n",
    "    seg = None\n",
    "    try:\n",
    "        sen = re.sub('[^\\u4e00-\\u9fa5|，|!|。]+|\\?{1}|:{1}', '', sen)\n",
    "        seg = postag.cut(sen)\n",
    "        seg = [x.word for x in seg if (len(x.word) > 1 and 'n' in x.flag and x not in stop_words)]\n",
    "        seg = ' '.join(seg)\n",
    "    except Exception as err:\n",
    "        print('ERROR {}'.format(err))\n",
    "        seg = '错误'\n",
    "    sentences_text.append(seg)\n",
    "\n",
    "for sen in causes:\n",
    "    seg = None\n",
    "    try:\n",
    "        sen = re.sub('[^\\u4e00-\\u9fa5|，|!|。]+|\\?{1}|:{1}', '', sen)\n",
    "        seg = postag.cut(sen)\n",
    "        seg = [x.word for x in seg if len(x.word) > 1]\n",
    "        seg = ' '.join(seg)\n",
    "    except Exception as err:\n",
    "        print('ERROR {}'.format(err))\n",
    "        seg = '错误'\n",
    "    sentences_reason.append(seg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-19T07:40:02.552038Z",
     "start_time": "2018-10-19T07:40:02.550159Z"
    }
   },
   "outputs": [],
   "source": [
    "# ls = sorted(counter.items(), key = lambda x: x[1], reverse=True)\n",
    "# for x in ls: print (x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-19T07:40:23.694439Z",
     "start_time": "2018-10-19T07:40:23.622580Z"
    }
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(max_features = 500)\n",
    "transformer = TfidfTransformer()\n",
    "\n",
    "tfidf_text = transformer.fit_transform(vectorizer.fit_transform(sentences_text))\n",
    "tfidf_reason = transformer.fit_transform(vectorizer.fit_transform(sentences_reason))\n",
    "tfidf_text /= float(2)\n",
    "\n",
    "text_features = pd.DataFrame(tfidf_text.toarray())\n",
    "reason_features = pd.DataFrame(tfidf_reason.toarray())\n",
    "\n",
    "type_features = pd.get_dummies(data.verified_type)\n",
    "\n",
    "weibo_fetures = data.weibos_count.apply(lambda x: math.log2(x + 1))\n",
    "fan_features = data.fans_count.apply(lambda x: math.log2(x + 1))\n",
    "weibo_fetures /= 0.5 * weibo_fetures.mean()\n",
    "fan_features /= 0.5 * fan_features.mean()\n",
    "\n",
    "features = pd.concat([text_features, reason_features, type_features,\n",
    "                      weibo_fetures, fan_features], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-19T07:40:27.585764Z",
     "start_time": "2018-10-19T07:40:24.393409Z"
    }
   },
   "outputs": [],
   "source": [
    "clr = KMeans(n_clusters = 32)\n",
    "clr.fit(features)\n",
    "labels = clr.labels_\n",
    "data['labels'] = pd.Series(clr.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-19T07:40:27.689284Z",
     "start_time": "2018-10-19T07:40:27.587272Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : 125\n",
      "0 十年股海，十年坚持，十年百倍收益，喜欢总结，懂得感悟，分享经验，快乐投资，与股海沉浮一路同行！ 上海证大资产管理有限公司市场经理 财经博主 头条文章作者 微博签约自媒体\n",
      "0 股票现货风险首席分析专家，知名财经作家郭然微博自媒体联盟成员     理财规划师\n",
      "0 无锡不锈钢开户，期货开户，无锡不锈钢套利 QQ:1182006958 前 渤海现货贵金属首席理财顾问\n",
      "0 i美股资产管理 i美股资产管理有限公司创始人CEO\n",
      "0 本人致力于A股研究，短线操作，提前埋伏未来热点板块和概念，欢迎各位股民朋友前来交流学习！ 微博有延迟！加我的Q:422893994。方便交流。 项目管理师\n",
      "\n",
      "1 : 49\n",
      "0 从事金融行业六年，专研短线周期操作策略，擅长多维双边波段选股。 知名财经博主 股评团成员 头条文章作者\n",
      "0 基本功过硬，极致精准分析，简单快乐炒股，持续稳定盈利。 微博股评师 财经博主 头条文章作者\n",
      "0 题材挖掘预期龙头股 微博股评团成员 头条文章作者\n",
      "0 精通筹码理论，擅长躺底与逃顶，精准把握市场的节奏，独创分时看盘与盘口语言，把控A股的波动。 财经博主 微博股评团成员 头条文章作者\n",
      "0 外盘期货开户请加本人唯一微信 WK80008。无门槛资金限制。 微博股评团成员 财经博主 头条文章作者\n",
      "\n",
      "2 : 36\n",
      "0 Vampire创始人，华信万达期货特邀名家专栏，摩尔金融撰稿人。 财经博主\n",
      "0 这是一个神奇的投资群，不收取任何费用，周收益25%以上，没有可以退群！！！QQ群号：348464258 加群验证：336 财经博主\n",
      "0 任何一只股票拉起来后，最终目的只有一个，就是套人，就是击鼓传花。资本市场没有菩萨，只有嗜血逐利！ 财经博主\n",
      "0 国家注册黄金分析师 期货 外汇 股票现货交易 合作微信:boyi-0803 财经博主\n",
      "0 我的微博每日开盘前半个小时推荐牛股.信不信牛不牛,可查看我微博动态(绝对不会让你失望)。免费交流Q群:140528701没有20%收益你退群！进群验证:微博 财经博主\n",
      "\n",
      "3 : 57\n",
      "2 智通财经http://www.zhitongcaijing.com/ 深圳智通财经信息科技服务有限公司\n",
      "2 做铜生意，看铜资讯，铜期货行情分析，就上中铜在线。中铜在线zhongtongzaixian.com，做有深度的铜资讯门户，精心打造铜行业权威门户。关注铜业新闻、期铜走势、行情分析、财经政策、即时数据、研究报告的交流和分享。 嘉兴中铜信息科技有限公司\n",
      "2 盈盈理财成立于2013年4月，是国内领先的基于先进互联网技术和严格风险控制管理体系的金融信息服务及撮合交易平台，致力为广大投资人提供低门槛、易于理解、操作简便、安全高效、收益稳定可观的理财产品和投资渠道。 杭州龙盈互联网金融信息技术有限公司\n",
      "2 仙人掌股票APP，为股民提供快捷的股票资讯，跟投资达人的组合，加入投资达人的圈子，分享最牛的达人投资思路，让炒股变得简单！ 上海翼优信息技术有限公司\n",
      "2 1秒注册即可实盘炒港股，无需线下见证开户，免去繁琐流程省时省事。 北京汇众财富投资管理有限公司\n",
      "\n",
      "4 : 60\n",
      "2 华盛通是新浪集团和微博旗下的港股、美股投资服务平台。致力于科技与金融结合，为用户提供不断进化的投资交易工具。可通过手机在3分钟内完成香港证券户头的开立，同步获得港股、美股的交易通道。华盛为用户提供业内最低水平的佣金收费，港股交易佣金仅为万分之三，美股每笔则低至1.99美金。 华盛证券官方微博\n",
      "2 大连地区唯一的金融综合门户、财经媒体。 大连金融网 dljrw.com官方微博\n",
      "2 温榆河杯南北英雄股票操盘联赛 北京温榆河科技有限公司微博\n",
      "2 MCN机构 微博股票合作伙伴 环铭文化\n",
      "2 换手率手机短线炒股神器App，Level-2实时资金量化，短线私募操盘手自媒体。国内一线顶尖短线私募联合开发！ 上海利莫网络科技有限公司\n",
      "\n",
      "5 : 85\n",
      "0 中国著名的外汇贵金属投资人，知名博主。指导qq：853056960 武汉通鑫保利投资有限公司销售经理\n",
      "0 为广大投资者提供投资建议， 每日分析大盘 善于短线操作 把握不好可以咨询我   上海金帝投资有限公司投资顾问\n",
      "0 专注超短线：当天买，一般第二天就卖。 食丽派短线投资工作室创始人\n",
      "0 新浪财经专栏作家、资深投资人 深圳君择投资控股有限公司董事长\n",
      "0 一个游走于文学，股票，摄影，音乐，设计等领域的纠结的灵魂!一个极度悲观的乐观主义者！ 深圳市信合资产管理有限公司董事长\n",
      "\n",
      "6 : 99\n",
      "0 拥有丰富的解盘及操盘实战经验，对于热点题材龙头个股的把握较为精准并擅长把握各类主题投资机会。欢迎更多的投资者与GDLZ89实战一同交流互动！ 财经博主 头条文章作者 微博签约自媒体\n",
      "0 帮助别人成就自己，20年股海观风雨，主力控盘实独步股林。 知名财经博主 头条文章作者 微博签约自媒体\n",
      "0 巡A股之庄家，定起爆之位；教股市之兵法，结百家之散户。 财经博主 头条文章作者 微博签约自媒体\n",
      "0 短期理财你的首选，周期短 收益稳 配比赚差价，想参与添加我的VX：294218296 验证：Y 黄金投资分析师 财经博主 头条文章作者 微博签约自媒体\n",
      "0 二十年骨灰级投资客，十三年专业操盘经验，知名私募基金首席操盘。历经A股牛熊，总结出独自操作战法，致力于热点龙头挖掘，崇尚佛学 财经博主 头条文章作者 微博签约自媒体\n",
      "\n",
      "7 : 29\n",
      "0 财经媒体人，关注奢侈品，关注TMT，欢迎各位大虾新闻爆料~~~有料者发邮件：mintsky0611@126.com 财经媒体人\n",
      "0 股票期货投资理财、开户业务、V信  A8GSXL 财经博主 财经视频自媒体\n",
      "0 简单炒股，快乐生活，资金流派，极致打法 财经视频自媒体\n",
      "0 微博每天早盘9:30之前有大盘风向、牛股推荐、个股分析和操作提示等，多多关注QQ：1143790232微信：SG1989l 时尚美妆视频自媒体\n",
      "0 让庄家与你同行 财经视频自媒体\n",
      "\n",
      "8 : 32\n",
      "2 致力于资产管理、期货股票投资指导、专业操盘手实战培训。 安徽腾龙创富金融信息服务有限公司\n",
      "2 赣南有脐橙，国内皆有名！卖了脐橙买股票，持好股票卖脐橙，我是认真的，购橙V信：cwy13330139665 龙南艾德礼品有限公司官方微博\n",
      "2 个股分析：http://tg.gchj.com.cn/wap/fstsj04/ 北京盛世创富证券投资顾问有限公司\n",
      "2 以商品期货为基础、金融期货为重点，依托中投证券的研究力量，实时播报最新研究成果。注：2010年大商所-和讯网十大农产品期货研发团队。 天琪期货研究所官方微博\n",
      "2 返佣宝(www.fanyongbao.com)，金融返佣首选平台！返佣网,返利网,外汇返佣,黄金返佣，股票返佣，期货返佣,理财返佣,最高返佣100%。返佣宝以降低金融交易成本为使命，为会员提供最高的返佣标准，始终奉行安全、诚信、快捷的经营理念，打造金融返佣行业领先的一站式金融返佣折扣平台！ 大连仙迪信息科技有限公司\n",
      "\n",
      "9 : 48\n",
      "0 2013年在国内首创量化+仓位管理，提供更直观，量化的仓位管理解决方案。 财经博主 头条文章作者\n",
      "0 股票~期货~期权 定位：庙堂与江湖之外的静心之地 头条文章作者\n",
      "0 股票/外汇职业操盘手。 财经博主 头条文章作者\n",
      "0 基督徒，金融分析师 主要从事A股、美股、期货市场技术分析、逻辑推演。 于基本面、消息面无涉猎。 财经博主 头条文章作者\n",
      "0 个股解读，牛股推荐请添加笔者微信：kdj0753或QQ：2790641874 财经博主 头条文章作者\n",
      "\n",
      "10 : 57\n",
      "0 涨停股票推荐、潜力股、牛股、股票分析，仅供参考。 微博股评师 财经博主 微博签约自媒体\n",
      "0 主研究量化选股，中短线风格。 以沸腾的心态看待股市， 用量化的数据观察涨跌。 知名财经博主 微博股评师 微博签约自媒体\n",
      "0 2017年新浪微博模拟炒股大赛总收益第3名。曾任职国家行政事业单位，美国私募资本管理商会，独创了【解套宝】和【爱涨停】、【周金股】等荐股类栏目 财经博主 微博投资达人 头条文章作者 微博签约自媒体\n",
      "0 经历了16年的股海生涯，练就的独立的超短线交易方法,微博是个人炒股日志，不做咨询、荐股，跟风者自负盈亏。 微博签约自媒体\n",
      "0 交易日文字实战直播解盘；微博小号@股海实战一哥 同步解盘直播；微博不接任何推广及平台合作事宜，勿扰~！ 微博股评师 知名财经博主 微博签约自媒体\n",
      "\n",
      "11 : 39\n",
      "0 财经意见领袖 职业投资人 知名财经博主 头条文章作者\n",
      "0 东方财富上证吧 - 天堂湖，A股最精准趋势分析！ 知名财经博主 头条文章作者 微博签约自媒体\n",
      "0 一个比普通股民还普通的普通股民，炒股信奉：“时间是爷，空间是爹，时间是触发事件的神秘力量。” 知名财经博主 头条文章作者 微博签约自媒体\n",
      "0 谁说女子不如男？（目标：组建散户财团） 知名财经博主 头条文章作者\n",
      "0 公认的趋势派民间高手，被广大股民誉为趋势王，2010年起受邀成为谈股论金的主要嘉宾，2016年4月起受邀担任点掌财经的主要嘉宾 微博股评师 头条文章作者\n",
      "\n",
      "12 : 21\n",
      "3 新浪财经国际组官博，第一时间传递环球市场风云、关注世界财经。主打产品新浪财经APP，全球华人首选财经APP，大数据诊股开放体验，名家高手在线答疑，A股、港股、美股、期货、外汇所有行情全覆盖。 新浪财经美股官方微博\n",
      "3 提供财经资讯、商业故事、各界观点，关注制度建设。微信搜索&lt;21世纪经济报道&gt;或加&lt;jjbd21&gt;,更多精彩内容等着你。 21世纪经济报道官方微博\n",
      "3 微博股票官方运营账号 微博股票官方微博\n",
      "3 全面追蹤香港股市、匯市、樓市最新行情 香港財經資訊微博\n",
      "3 中国经济网是经济日报主办的中央重点新闻网站和国家经济门户网站，以经济报道、资讯传播和经济服务为主要发展方向，致力于打造“最具权威性的财经网… 中国经济网法人微博\n",
      "\n",
      "13 : 56\n",
      "3 观柳州，看柳州！生活大事小情、探底楼市房事、大街小巷美食……在柳州，扒客柳州！ 锦拓图文化传媒官方微博\n",
      "3 网易股票频道，实用可靠的股票投资平台和社区，做影响股价的资讯。 网易股票官方微博\n",
      "3 新浪港股官方微博,提供最快最全面的港股资讯；欢迎报料、投稿，请发微博私信。 新浪港股官方微博\n",
      "3 华尔街见闻出品，专注于美股市场，为您提供最重要的资讯数据，最全面的市场动态和最深刻的解读分析 由华尔街见闻出品，提供美股行情、经济数据和重大新闻\n",
      "3 新浪理财师平台汇聚数千名执业理财师，覆盖沪深股市3000+股票！实时行情解读、个股疑问秒回、交易计划共享。炒股找老师，就上新浪理财师！ 新浪理财师互联网金融平台官方微博\n",
      "\n",
      "14 : 74\n",
      "0 旅游钓鱼有我、摄影收藏有我、炒股买彩有我、球迷有我、卡拉有我、捐款有我。小时淘气老师批评我说：啥事都有你？老师我没放火没抢粮食没盗墓。 财经博主\n",
      "0 黑色系期货职业投资者，专注黑色产业研究。 财经博主\n",
      "0 第一财经直播嘉宾 财经博主\n",
      "0 玩期货的小散 财经博主\n",
      "0 2000年起先后进入股票、外汇和期货市场,历经苦难,发现价格运行的规律,希望后来者要么离开期货，要么向高手学习，掌握好了技术，再来赚钱不迟！ 财经博主\n",
      "\n",
      "15 : 89\n",
      "0 新浪微博财经类自媒体人，多年的股海沧桑,民间职业股票投资人.操作风格&lt;超短线结合波段&gt;微博是个人炒股日志 北京和众汇富证券 投资顾问 头条文章作者 微博签约自媒体\n",
      "0 香港新城財經台節目主持 慧悅傳媒創始人。专注于港股财经新闻。 慧悦传媒创始人\n",
      "0 资深股票分析师、培训师 郑州瑞轩教育有限公司董事长 财经博主\n",
      "0 从“制造”到“智造”再到＂资造＂， 打造奥康 黄金十年。 奥康股票简称：奥康国际 股票代码：603001 奥康鞋业股份有限公司副总裁、执行董事  奥康鞋业销售公司总经理\n",
      "0 金源高级策略师。擅长基本面加技术面分析，提供实用、盈利的交易策略。主攻金属、贵金属、工业化工类品种。现任第一财经、东方财经等著名节目特约嘉宾 金源期货高级策略师葛健颖 \n",
      "\n",
      "16 : 51\n",
      "0 娱乐财经达人 微博股评团成员\n",
      "0 一个十年磨一剑的老股民，目前专注商品期货跨期套利 微博股评团成员\n",
      "0 证券万三佣金、股票期货配资、个股期指合作、银行直存、黄金外汇开户，可微博私信。交流群：51243866 微博股评师\n",
      "0 个人博客，以博会友，可供技术交流，本博观点及文中所列举个股，仅供参考，买卖者请风险自控！ 前   国泰君安证券股份有限公司经理  微博股评团成员\n",
      "0 20年的股市风风雨雨，只想把经验与大家分享，一起交流，才会有所收获。本微博只记录自己的操作，不荐股，不收费，只交流，不建议跟风 微博股评师\n",
      "\n",
      "17 : 43\n",
      "0 卧龙擅长市场预测，风险控制，金融市场分析，致力于帮助每一位股民 跟对股赢一次；跟对人赢一生！小白变资深！小散变大户！ 财经博主\n",
      "0 股票投资人，在股海里摸爬滚打十几年，总结出了一套自己的获利模式。微信交流：zwfc5268 财经博主\n",
      "0 不追求涨停的奇迹,只追求稳健的收益 微博财经博主\n",
      "0 微信stock_note 股票笔记的作者笔记哥 财经博主\n",
      "0 股票，期货投资策略有需要请联系专员。QQ，441097082。个人微信，ganenlife。 财经博主\n",
      "\n",
      "18 : 15\n",
      "5 浙江在线（http://www.zjol.com.cn/）是国务院新闻办确定的地方重点新闻网站，浙江省惟一的省级重点新闻网站和综合性门户网站。网站以“权威媒体、大众网站”为基本定位，目前日均访问量达到1500万人次，内容影响力和经营实力已跃居全国地方网媒前列。2011年9月29日，浙江在线新闻网站纳入“浙报传媒”整体上市，成为国务院新闻办首批十家转企改制新闻网站中第一家成功登陆A股的网络媒体。新闻热线：0571-85311035 浙江在线官方微博\n",
      "5 和讯股票是国内知名财经网站和讯网旗下股票频道，提供全方位24小时全球股票行情，目前有A股、港股、美股、新股、券商、新三板、千股宝典等几大子频道，并提供资金流向、大宗交易等专业数据浏览。了解更多，请点击：http://stock.hexun.com/ 和讯网股票频道stock.hexun.com官方微博\n",
      "5 【云财经】国内第一股票情报聚合平台。专注于财经、证券、金融领域的资讯集成、舆情监控与大数据挖掘研究，提供国内唯一的股市垂直搜索服务。www.yuncaijing.com 云财经网 www.yuncaijing.com 官方微博\n",
      "5 东方财富网旗下股吧（http://guba.eastmoney.com）是给大家提供社交，行业分析以及个股探讨的全方位网络平台。希望您在股吧聊得开心，并能得到让您满意的资讯！东方财富网股吧团队竭诚为您服务！立即注册为股吧用户：http://passport.eastmoney.com/PhoneReg.EmUser?http://guba.eastmoney.com/ 东方财富网股吧 guba.eastmoney.com官方微博\n",
      "5 中国最大财经门户网站。最新版【和讯财经APP】上， 每天上千条财经动态7x24小时滚动播报，股票新闻定制化推送，敬请下载。 和讯网官方微博\n",
      "\n",
      "19 : 82\n",
      "0 知名财经评论员，享誉业界期货分析师，是各财经网活跃博主，名博，长期在各大财经网媒、纸媒等媒体发表期货方面的文章。微信：guo_haozh 财经博主 广州昊天投资有限公司 投资分析研究部总监 头条文章作者\n",
      "0 作家、独立时评人、财经评论员、文盲+法盲+精神病之律师、中共党员。战忽局法律顾问。电话：0514-80116490；微信号：lmz8848。不怕骚扰。 律师 知名法律博主 头条文章作者\n",
      "0 关注股市！关注经济！关注小散！专注短线！ 财经博主 中信证券股份有限公司经理 头条文章作者 微博签约自媒体\n",
      "0 相声演员中国煤矿文工团说唱团团长国家一级演员，中国曲艺家协会理事，第三届中国曲艺牡丹奖获得者，享受国务院特殊津贴 人称《股民团长》 中国煤矿文工团说唱团团长、著名相声演员\n",
      "0 追求稳定收益 知名财经博主 黄金投资分析师 头条文章作者\n",
      "\n",
      "20 : 79\n",
      "0 华安期货 股指期货 国债 程序化交易 套利 套保 结构化产品 期货私募 对冲 铁矿石 理财 期货培训 基本面 技术分析 华安期货有限责任公司 副总经理\n",
      "0 股之逻辑，尤擅长基本面分析。    深圳市易启传媒有限公司市场总监\n",
      "0 期货！ 万达期货工业品事业部黄金分析师孔赵楠\n",
      "0 中期协股指期货特聘讲师，省期协分析师委员会副主任。证券时报评选的全国最佳期货分析师，上证报评选的最佳农产品分析师，郑商所评选的高级期货分析师 长江期货首席农产品分析师\n",
      "0 国内知名农产品期货专家。 宏源期货农产品研究室负责人王勇\n",
      "\n",
      "21 : 31\n",
      "0 专注港股打新策略研究（新股申购策略、卖出策略、炒新策略，2017年港股打新实盘收益率265%） 深圳格隆汇信息科技有限公司 格隆汇合伙人\n",
      "0 安信期货研究所所长马春阳 安信期货研究所所长\n",
      "0 中国社科院财经战略研究院 长期研究时间经济、服务经济和休闲旅游经济 北京第二外国语学院 闲暇经济研究中心主任\n",
      "0 股票段子手，市场收割团团长 头条文章作者\n",
      "0 非主流炒股人士！ 头条文章作者\n",
      "\n",
      "22 : 75\n",
      "0 我的微信号：sz06888，欢迎大家前来交流学习，免费解答个股问题。 财经博主 头条文章作者\n",
      "0 关注港股窝轮牛熊证，与投资者交流互动，分享窝轮牛熊证选择逻辑。 财经博主 头条文章作者\n",
      "0 常能遣其欲，而心自静，澄其心而神自清 。 期货交流QQ：327904270 财经博主 头条文章作者\n",
      "0 投资：第一控制好风险，第二才是收益。 财经博主 头条文章作者\n",
      "0 80后自由炒股人，善长量价，准确测量预测股票具体目标价格。 财经博主 头条文章作者\n",
      "\n",
      "23 : 36\n",
      "0 最全MT4指标模版：打造黄金白银外汇赚钱的MT4指标模版交易系统！微信：335326784 广发证券股份有限公司上海分公司经理 财经博主\n",
      "0 本人的股票qq2695328061:验证：1008! 没有20%收益你拉黑!心态+技术+策略==好的收益!建议你备注好微博昵称，我好知道你是那位朋友！ 德恒证券有限责任公司经理\n",
      "0 股市 财经 冷笑话 搞笑 80后 旅游 图片 泽一控股（中国）股份有限公司职员\n",
      "0 老鬼：善于捕捉热点，牛股，侧重短线投资 ，擅长短线资金理论：大量资金铺在前,横盘整理必要看。 财经博主 华泰证券股份有限公司职员\n",
      "0 【趋势择时，价值选股，资金管理，绝对收益。】 广发证券机构部副总经理\n",
      "\n",
      "24 : 22\n",
      "0 爱炒股 爱生活 真性情 不装逼 职业投资人 \n",
      "0 天天看金子就是没感觉，因为活在浙江省遂昌金矿中。（微博中涉及股票个股，均为本人笔记，切勿据此买卖） 浙江省遂昌金矿有限公司经济师，工程师 职业投资人 微博签约自媒体\n",
      "0 27年国内22年国际资本市场，涉猎股票、基金、债券、期货、大宗、外汇、掉期交易等金融衍生品。浪迹全球资本江湖的一只秃鹰，骨灰级投资人。 职业投资人 资深股评师 头条文章作者 微博签约自媒体\n",
      "0 《中短线临盘决策技法》《中短线稳定赢利操练》作者 职业投资人陈元 ，火山投资创始人，《中短线临盘决策技法》作者 知名财经博主 微博签约自媒体\n",
      "0 极探资本创始人；国内高科技投资流派先行者；专注于A股，美股市场； 成长股职业投资人 微博股评师 微博签约自媒体\n",
      "\n",
      "25 : 20\n",
      "0 独立财经撰稿人，股票操盘专家，职业投资人。 知名财经博主\n",
      "0 职业操盘手 短线高手明星赛冠军 知名财经博主\n",
      "0 个人订阅号:胡桑论股 知名财经博主\n",
      "0 A股中：　第一种人是没有形成自己的交易系统，没有明确的买点卖点；第二种人是还没有明白交易的本质理念，方向性错误。 知名财经博主\n",
      "0 想买到好股票？看导报就对了 知名财经博主\n",
      "\n",
      "26 : 34\n",
      "0 螺纹钢铁矿石黑色产业链顶层设计书记处书记员，期货证券行业战略规划师。国家商品期货宏观产业对冲基金战略策划师，红色中国共产主义事业时政评论员。 知名财经博主\n",
      "0 实战派，擅长挖掘中线趋势牛股！2013年起受邀入驻各大财经网站做股市直播，近年来获得十大最具有潜力导师，短线牛股大赛冠军！ 知名财经博主\n",
      "0 港股通非官方微博 知名财经博主\n",
      "0 1、个人投资者，股票玩了20多年了； 2、广告者必拉黑，请勿打忧；3、只选择辛勤发博的朋友互粉，不看粉丝数量。 知名财经博主\n",
      "0 一一一一好股票一一一一一一必须好.价格买入，寻找A股的(⌇ຶö⌇ຶ)======ਊ 腿部劳动、腾讯、苹果。(⌇ຶö⌇ຶ)======、.ਊ 腿部劳动？？、 股评团成员 知名财经博主\n",
      "\n",
      "27 : 105\n",
      "0 爱财经爱生活。 此时眉目尚嫣然超话小主持人\n",
      "0 微博认证：独一家犀利财经观察家，20年A港美股职业经理，微博签约自媒体。微信xc1641005906 上海中金所衍生品研究院 博士研究员\n",
      "0 市场博弈的结果是均衡，又可细分静态均衡和动态均衡，静态易于操作，动态则更能带来超额收益。   北京聊塑新展贸易有限公司  研发总监\n",
      "0 期货内功交易心法：顺势，轻仓，亏盈比一定大于1:3，微信QQ同号258326366 武汉鸿金宝投资有限公司 总经理 何竟波\n",
      "0 炒股我只信卦哥的老太太买菜理论！ 卦哥家超话粉丝大咖\n",
      "\n",
      "28 : 59\n",
      "2 牛钱网，做专业金融衍生品投资服务平台，经营团队拥有10多年金融系统、财经传媒和丰富的线下业务经验！ 牛乾金融信息服务（上海）有限公司\n",
      "2 五矿期货投资群QQ:187957130、148187174 五矿经易期货有限公司\n",
      "2 2013，招商期货“问鼎九州”全国期货实盘交易大赛（暨第七届全国期货实盘交易大赛），纵路英豪来袭，谁来问鼎！报名时间：2013年3月15日-2013年9月30日报名电话：95565-4-2-1 招商期货官方微博\n",
      "2 我的农产品网系上海钢联旗下行业网站，网站力图打造国内权威的农产品价格、资讯和数据平台。我的农产品网全面汇聚白糖；豆粕、菜籽粕；豆油、棕榈油、菜籽油；大豆、菜籽；小麦、玉米、稻米；棉花、棉纱等十三种农产品现货价格，及时跟踪农产品期货行情，发布最新的农产品资讯和数据，为用户提供全方位的信息资源。 上海钢联电子商务股份有限公司\n",
      "2 安粮期货马鞍山营业部坐落于马鞍山市繁华地段的中央大厦五楼，环境优越、交通便利，营业场所面积400多平米，目前已经建成全新的机房并拥有先进的交易软件。营业部现有多条光纤线路，保证了网络的连续和通畅，并有充裕的设备资源为交易行情服务终端供客户选择。马鞍山营业部将凭借一流的硬件和软件服务设施，以严谨务实的工作态度，努力打造一支富有资深经验的专业团队，持续为客户提供优质高效的服务。 安粮期货马鞍山营业部官方微博\n",
      "\n",
      "29 : 24\n",
      "0 音乐股神，专注证券投资理财，证券分析师，财经作家 音乐视频自媒体\n",
      "0 以股会友，广交天下好友！股海日志，记录每日心得！ 知名财经博主 微博财经超话主持人 财经视频自媒体\n",
      "0 2008年入市，积累了多年实盘经验，现每天分享黄金外汇交易策略并连载实盘账户盈亏，欢迎跟踪关注。 知名财经博主 操盘笔记超话主持人 财经视频自媒体\n",
      "0 复利--才是赢利之王！微博是个人炒股日志，跟风者自负盈亏。 财经博主 财经视频自媒体\n",
      "0 期盼股票早日解套，早日搬离生产巷！参演过:幸福时光等等，我最兴奋的事就是在剧组里✈留恋：1989年身无分文，在大连星海公园打工一个多月学会游泳！ 视频自媒体\n",
      "\n",
      "30 : 44\n",
      "2 出国旅游最低价！ 解决网-特价海外游官方微博\n",
      "2 特价啦！特价啦！清仓处理，香港电话卡，卡内有48元话费，现在仅售RMB25元，有需要的请联系我！ 佳泰假期官方微博\n",
      "2 诺德基金2013年第四季度首发的市场中性量化策略专户产品，成立以来业绩表现和风险收益特征充分体现产品优势。该产品的多只后续系列产品目前正在热销中，详情垂询4008880009转8 诺德基金官方微博\n",
      "2 [选股宝]是一款针对A股主题投资的极简资讯推送工具。 官方网站：https://xuangubao.cn/ 选股宝官方微博\n",
      "2 瞬间抓住龙头股，你最好的看盘助手 天天看盘官方微博\n",
      "\n",
      "31 : 42\n",
      "0 知名财经博主 头条文章作者 微博签约自媒体 财经博主\n",
      "0 此人不善交易，A股、港股、美股都有在看， 科技、消费、周期雨露均沾，建议不要轻易关注。 财经博主\n",
      "0 擅长股票的技术理论分析，对缠论有独到的理解，尤其大盘分析独到、数次成功精准逃顶，职业操盘手。 财经博主\n",
      "0 自由期货投资人，偏好趋势交易、对冲套利，价差投机。 财经博主\n",
      "0 专业从事期货市场分析与研究，由于观点独特精准而受到交易者喜爱.学习群651990052验证吗20000 财经博主\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for dat in data.groupby('labels'):\n",
    "    print(dat[0], ': {}'.format(len(dat[1])))\n",
    "    dat = dat[1]\n",
    "    for _, __, ___ in zip(dat.verified_type[:5], dat.text[:5], dat.reason[:5]):\n",
    "        print(_, __, ___)\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
