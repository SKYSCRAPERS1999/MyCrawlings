{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-18T03:48:56.859541Z",
     "start_time": "2018-09-18T03:48:56.788387Z"
    }
   },
   "outputs": [],
   "source": [
    "import pymongo\n",
    "mongo_uri = 'mongodb://impulse:njuacmicpc@120.79.139.239/weibo'\n",
    "client = pymongo.MongoClient(host=mongo_uri, port=27017)\n",
    "db = client['weibo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-18T03:55:25.797421Z",
     "start_time": "2018-09-18T03:55:25.792019Z"
    }
   },
   "outputs": [],
   "source": [
    "# for name in ['good_words', 'bad_words']:\n",
    "#     collection = db[name]\n",
    "#     result = collection.find({'created_date':'2018-09-18'}, {'word':1,'senti':1,'good':1,'mid':1,'bad':1})\n",
    "#     for x in result:\n",
    "#         x.pop('_id')\n",
    "#         x['created_date'] = '2018-09-17'\n",
    "#         if collection.find(x).count() == 0:\n",
    "#             print (x)\n",
    "#             collection.insert_one(x)\n",
    "        \n",
    "# collection = db['word_tf']\n",
    "# result = collection.find({'created_date':'2018-09-18'}, {'word':1,'tf':1})\n",
    "# for x in result:\n",
    "#     x.pop('_id')\n",
    "#     x['created_date'] = '2018-09-17'\n",
    "#     if collection.find(x).count() == 0:\n",
    "#         print (x)\n",
    "#         collection.insert_one(x)\n",
    "\n",
    "# collection = db['word_tfidf']\n",
    "# result = collection.find({'created_date':'2018-09-18'}, {'word':1,'tfidf':1})\n",
    "# for x in result:\n",
    "#     x.pop('_id')\n",
    "#     x['created_date'] = '2018-09-17'\n",
    "#     if collection.find(x).count() == 0:\n",
    "#         print (x)\n",
    "#         collection.insert_one(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-25T14:23:22.472612Z",
     "start_time": "2018-08-25T14:23:22.295748Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.08197674, 0.01918605, 0.00767442, 0.00290698, 0.00127907,\n",
       "        0.00011628, 0.0005814 , 0.00069767, 0.00034884, 0.00011628,\n",
       "        0.00046512, 0.00023256, 0.        , 0.        , 0.00011628,\n",
       "        0.00023256, 0.        , 0.00011628, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.00011628, 0.        , 0.00011628]),\n",
       " array([  8. ,  16.6,  25.2,  33.8,  42.4,  51. ,  59.6,  68.2,  76.8,\n",
       "         85.4,  94. , 102.6, 111.2, 119.8, 128.4, 137. , 145.6, 154.2,\n",
       "        162.8, 171.4, 180. , 188.6, 197.2, 205.8, 214.4, 223. , 231.6,\n",
       "        240.2, 248.8, 257.4, 266. ]),\n",
       " <a list of 30 Patch objects>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt  # 绘图库\n",
    "plt.hist(ls, bins=30, color='steelblue', density=True )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# User Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import re, sys, bson\n",
    "collection = db['users']\n",
    "regex = re.compile('(?:谈股|财经|说股|期货|外汇|讲股|论股|看股|港股|美股|理财师|A股|经济政策|短线|炒股|荐股|盈亏|炒股|股利|股海|股民|股票|个股|做空|诱多|诱空|踏空|长空|短空|长多|短多|死多|翻多|翻空|多杀多|扎空|空仓|建仓|满仓|斩仓|减仓|加仓|重仓|清仓|套牢|补仓|仓位|庄家|震仓|追涨|杀跌|止盈|抄底|逃顶|盘整|回档|坐庄|吸筹|对敲|洗盘|散户|中户|坐轿|抬轿|筹码|抢帽子|多头陷阱|空头陷阱|护盘|跳空|开盘价|收盘价|最高价|最低价|成交量|放量|缩量|热门股|冷门股|白马股|黑马股|龙头股|阴跌|换手率|现手|平开|低开|高开|内盘|外盘|均价|浮筹|市盈率|含权|回购|基本面分析|量比|每股|收益|市净率|探底|填权|停牌|退市)')    \n",
    "nregex = re.compile('(?:公司|企业|CEO|基金会|大学|学院|政府)')\n",
    "\n",
    "weibo_list = collection.find({}, {'id': 1, 'description': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print (weibo_list.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "id_del = []\n",
    "for x in weibo_list:\n",
    "    desp = x['description']\n",
    "    if re.search(nregex, desp) != None or re.search(regex, desp) == None:\n",
    "        id_del.append(x['id'])\n",
    "\n",
    "for id in id_del:\n",
    "    collection.delete_one({'id': id})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "results = collection.find({}, {'id': 1})\n",
    "id_list = []\n",
    "for result in results:\n",
    "    id_list.append(str(result['id']))\n",
    "print (len(id_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "collection = db['weibos']\n",
    "results = collection.find({}, {'created_at': 1})\n",
    "time_list = []\n",
    "import re\n",
    "for result in results:\n",
    "    if re.search('2018-07-20', result['created_at']) != None:\n",
    "        time_list.append(str(result['created_at']))\n",
    "time_list = sorted(time_list, reverse=True)\n",
    "print (len(time_list))\n",
    "print (time_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "date = time.strftime('%Y-%m-%d', time.localtime())\n",
    "ldate = time.strftime('%Y-%m-%d', time.localtime(time.time() - 24 * 60 * 60))\n",
    "lldate = time.strftime('%Y-%m-%d', time.localtime(time.time() - 2 * 24 * 60 * 60))\n",
    "print (date)\n",
    "print (ldate)\n",
    "print (lldate)\n",
    "h = \"{}|{}|{}\".format(date, ldate, lldate)\n",
    "results1 = collection.find({'created_date': {'$regex': date}})\n",
    "results2 = collection.find({'created_date': {'$regex': ldate}})\n",
    "print (results1.count())\n",
    "print (results2.count())\n",
    "\n",
    "# weibo_id_list = []\n",
    "# for delete in deletes: \n",
    "#     weibo_id_list.append(delete['id'])\n",
    "# print (len(weibo_id_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print (weibo_id_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-26T01:21:20.066626Z",
     "start_time": "2018-07-26T01:21:20.063410Z"
    }
   },
   "source": [
    "## Load weibo_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-29T13:25:34.645881Z",
     "start_time": "2018-07-29T13:25:34.641098Z"
    }
   },
   "outputs": [],
   "source": [
    "import pymongo\n",
    "import pandas as pd\n",
    "def get_data():\n",
    "    client = pymongo.MongoClient(host='mongodb://impulse:njuacmicpc@120.79.139.239/weibo', port=27017)\n",
    "    db = client['weibo']\n",
    "    collection = db['weibos']\n",
    "    results = collection.find({}, {'id':1, 'user':1,'attitudes_count':1,'comments_count':1,'reposts_count':1,'text':1,'full_text':1})\n",
    "    \n",
    "    data = pd.DataFrame(list(results)[:500]) # modified\n",
    "    if 'attitudes_count' in data.columns: ## if it is normal\n",
    "        data = data.get(['user','attitudes_count','comments_count','reposts_count','text', 'full_text'])\n",
    "        data.columns = ['user', 'at_cnt', 'cmt_cnt', 'rep_cnt', 'text', 'f_text']\n",
    "        for i in range(len(data)):\n",
    "            if len(str(data.loc[i, 'f_text'])) > 135:\n",
    "                data.loc[i, 'text'] = data.loc[i, 'f_text']\n",
    "        data = data.drop('f_text', axis=1)\n",
    "    else:\n",
    "        print ('some errors occur')\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-15T14:26:50.269105Z",
     "start_time": "2018-08-15T14:26:50.249802Z"
    }
   },
   "outputs": [],
   "source": [
    "import pymongo, time\n",
    "import pandas as pd\n",
    "mongo_uri = 'mongodb://impulse:njuacmicpc@120.79.139.239/weibo'\n",
    "\n",
    "def get_data():\n",
    "    \n",
    "    print ('In {}, begin, date is {}'.format(get_data.__name__, time.strftime('%Y-%m-%d-%H:%M', time.localtime(time.time()))))\n",
    "\n",
    "    client = pymongo.MongoClient(host=mongo_uri, port=27017)\n",
    "    db = client['weibo']\n",
    "    collection = db['weibos']\n",
    "    results = collection.find({}, {'id':1,'user':1,'attitudes_count':1,'comments_count':1,'reposts_count':1,'text':1,'full_text':1})\n",
    "    print ('In {}: len of db: {}'.format(get_data.__name__, results.count()))\n",
    "    data = pd.DataFrame(list(results)) # for test\n",
    "    if 'attitudes_count' in data.columns: ## if it is normal\n",
    "        data = data.get(['id', 'user','attitudes_count','comments_count','reposts_count','text', 'full_text'])\n",
    "        data.columns = ['id', 'user', 'at_cnt', 'cmt_cnt', 'rep_cnt', 'text', 'f_text']\n",
    "        for i in range(len(data)):\n",
    "            if len(str(data.loc[i, 'f_text'])) > 135:\n",
    "                data.loc[i, 'text'] = data.loc[i, 'f_text']\n",
    "        data = data.drop('f_text', axis=1)        \n",
    "        print ('In {}: data loaded, len {}'.format(get_data.__name__, len(data)))\n",
    "    else:\n",
    "        print ('In {}: some errors occur'.format(get_data.__name__))        \n",
    "    \n",
    "    client.close()\n",
    "    print ('In {}, end, date is {}'.format(get_data.__name__, time.strftime('%Y-%m-%d-%H:%M', time.localtime(time.time()))))\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-15T14:37:26.341401Z",
     "start_time": "2018-08-15T14:26:51.127785Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In get_data, begin, date is 2018-08-15-22:26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/impulse/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:13: DeprecationWarning: count is deprecated. Use Collection.count_documents instead.\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In get_data: len of db: 50032\n",
      "In get_data: data loaded, len 50032\n",
      "In get_data, end, date is 2018-08-15-22:37\n"
     ]
    }
   ],
   "source": [
    "data = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-29T08:39:37.443168Z",
     "start_time": "2018-07-29T08:34:13.278222Z"
    }
   },
   "outputs": [],
   "source": [
    "client = pymongo.MongoClient(host='120.79.139.239', port=27017)\n",
    "db = client['weibo']\n",
    "collection = db['weibos']\n",
    "results = collection.find({}, {'user':1,'attitudes_count':1,'comments_count':1,'reposts_count':1,'text':1,'full_text':1})\n",
    "# data0 = pd.DataFrame(list(results))\n",
    "data0 = pd.DataFrame(columns={'user', 'at_cnt', 'cmt_cnt', 'rep_cnt', 'text', 'f_text'})\n",
    "dic = {'user':'user','at_cnt':'attitudes_count','cmt_cnt':'comments_count','rep_cnt':'reposts_count','text':'text','f_text':'full_text'}\n",
    "for cnt, raw in enumerate(results):    \n",
    "#     res = pd.DataFrame(columns={'user', 'at_cnt', 'cmt_cnt', 'rep_cnt', 'text', 'f_text'}, index=[cnt])\n",
    "    res = {}\n",
    "    for k, v in dic.items():\n",
    "        if v in raw:\n",
    "            res[k] = raw[v]\n",
    "        else:\n",
    "            res[k] = \"\"\n",
    "    \n",
    "    if len(res.get('f_text')) > 130:\n",
    "        res['text'] = res['f_text']\n",
    "        res['f_text'] = \"\"\n",
    "        \n",
    "    data0.loc[cnt] = res\n",
    "\n",
    "print (len(data0))\n",
    "print (data0.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-29T13:25:53.331766Z",
     "start_time": "2018-07-29T13:25:53.328226Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def read_stop_words(): \n",
    "    stop_words = []\n",
    "    stop_letters = []\n",
    "    with open('stop_words.txt') as sp:\n",
    "        for x in sp:\n",
    "            stop_words.append(x[:-1])\n",
    "    with open('stop_letters.txt') as sp:\n",
    "        for x in sp:\n",
    "            stop_letters.append(x[:-1])\n",
    "    stop_words = set(stop_words)\n",
    "    re_stop_letter = re.compile('|'.join(stop_letters))\n",
    "    return (stop_words, re_stop_letter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-29T13:25:55.149341Z",
     "start_time": "2018-07-29T13:25:54.005429Z"
    }
   },
   "outputs": [],
   "source": [
    "import re, jieba\n",
    "jieba.load_userdict('jieba_dict_companys')\n",
    "\n",
    "def get_clean_text(data, output=True):\n",
    "    texts = []\n",
    "    for cnt, raw in enumerate(data.text):\n",
    "        del_name = re.findall('@([^ |<|:|\\(|\\)|\\\\|\\/|<|>|\\[|\\]]+)', raw)\n",
    "        for name in del_name:\n",
    "            raw = re.sub(name, '', raw)\n",
    "        raw = re.sub('<br />', '，', raw)\n",
    "        raw = re.sub('[^\\u4e00-\\u9fa5|，|!|。]+|\\?{1}|:{1}', '', raw)\n",
    "        texts.append(raw)\n",
    "        \n",
    "        if cnt % 1000 == 0 and output == True:\n",
    "            print ('cnt = {}'.format(cnt))\n",
    "    if len(texts) == len(data):\n",
    "        return pd.Series(texts)\n",
    "    else:\n",
    "        print('not the same length')\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-29T13:26:04.275646Z",
     "start_time": "2018-07-29T13:26:03.743454Z"
    }
   },
   "outputs": [],
   "source": [
    "import re, jieba\n",
    "import jieba.posseg as postag\n",
    "                           \n",
    "def get_words(data, re_stop_letter, stop_words, output=True):\n",
    "    words = []\n",
    "    for cnt, raw in enumerate(data.c_text):\n",
    "        result = postag.cut(raw)\n",
    "        raw = [x.word for x in result if (len(x.word) > 1 and 'n' in x.flag and re.search(re_stop_letter, x.word) == None and x.word not in stop_words)]\n",
    "        words.append(raw)\n",
    "        \n",
    "        if cnt % 1000 == 0 and output == True:\n",
    "            print ('cnt = {}'.format(cnt))\n",
    "            \n",
    "    return pd.Series(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-29T13:26:05.525375Z",
     "start_time": "2018-07-29T13:26:05.522092Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_word_count(lst):\n",
    "    count = {}\n",
    "    for x in lst:\n",
    "        if x in count:\n",
    "            count[x] += 1\n",
    "        else:\n",
    "            count[x] = 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-29T13:37:30.072007Z",
     "start_time": "2018-07-29T13:37:30.065236Z"
    }
   },
   "outputs": [],
   "source": [
    "import requests, re, time, json\n",
    "\n",
    "# # sentiments\n",
    "def get_sentiment(data, output=True):\n",
    "    headers = {\n",
    "        'Content-Type': 'application/json'\n",
    "    }\n",
    "    params = {\n",
    "        'access_token': '24.cb5b8cccad6a49c21d4cccd1a047f9ae.2592000.1534940191.282335-11569351'\n",
    "    }\n",
    "    positive_prob = []\n",
    "    for cnt, (text, senti) in enumerate(zip(data.c_text, data.senti)):\n",
    "        \n",
    "        if isinstance(senti, int) or isinstance(senti, float):\n",
    "            positive_prob.append(senti)\n",
    "            print ('omit: {}'.format(cnt))\n",
    "            continue\n",
    "            \n",
    "        else:\n",
    "            start_time = time.clock()\n",
    "            post_json = {\n",
    "                \"text\": text\n",
    "            }\n",
    "    \n",
    "            response = requests.post('https://aip.baidubce.com/rpc/2.0/nlp/v1/sentiment_classify',\n",
    "                                    params=params, headers=headers, json=post_json)\n",
    "            if response.status_code != 200:\n",
    "                time.sleep(2.0)\n",
    "                response = requests.post('https://aip.baidubce.com/rpc/2.0/nlp/v1/sentiment_classify',\n",
    "                                    params=params, headers=headers, json=post_json)\n",
    "    \n",
    "            if response.text != None:\n",
    "                res_json = json.loads(response.text)\n",
    "                if res_json.get('items') != None and res_json.get('items')[0].get('positive_prob') != None: \n",
    "                    prob = res_json.get('items')[0].get('positive_prob')\n",
    "                    #print (prob)\n",
    "                    positive_prob.append(prob)\n",
    "                else:\n",
    "                    print('-1')\n",
    "                    positive_prob.append('-1')\n",
    "            else:\n",
    "                print('-1')\n",
    "                positive_prob.append('-1')\n",
    "            elapsed = (time.clock() - start_time)\n",
    "            time.sleep(0.21 - elapsed)\n",
    "\n",
    "        if cnt % 1000 == 0 and output:\n",
    "            print ('In {}: cnt = {}'.format(get_sentiment.__name__, cnt))\n",
    "    if len(data) != len(positive_prob):\n",
    "        print ('In {}: length not equal'.format(get_sentiment.__name__))\n",
    "        \n",
    "    return pd.Series(positive_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-29T13:31:34.985433Z",
     "start_time": "2018-07-29T13:26:20.946445Z"
    }
   },
   "outputs": [],
   "source": [
    "data = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-29T13:32:14.796076Z",
     "start_time": "2018-07-29T13:32:14.776285Z"
    }
   },
   "outputs": [],
   "source": [
    "stop_words, re_stop_letter = read_stop_words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-29T13:32:16.236874Z",
     "start_time": "2018-07-29T13:32:16.201403Z"
    }
   },
   "outputs": [],
   "source": [
    "data['c_text'] = get_clean_text(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-29T13:32:23.859381Z",
     "start_time": "2018-07-29T13:32:20.129227Z"
    }
   },
   "outputs": [],
   "source": [
    "data['words'] = get_words(data=data, re_stop_letter=re_stop_letter, stop_words=stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-29T13:34:35.602972Z",
     "start_time": "2018-07-29T13:34:35.597117Z"
    }
   },
   "outputs": [],
   "source": [
    "data['hash'] = [ int((hash(x)+len(str(y))*47)%(1e9+7)) for x, y in zip(data.text, data.user)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-29T13:34:35.602972Z",
     "start_time": "2018-07-29T13:34:35.597117Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-29T13:36:37.099730Z",
     "start_time": "2018-07-29T13:36:36.460013Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('../ScrapyDatas/weibo_test_data.csv')\n",
    "data['senti'] = pd.Series([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-29T13:38:10.806859Z",
     "start_time": "2018-07-29T13:38:07.951977Z"
    }
   },
   "outputs": [],
   "source": [
    "# notice ! in use !\n",
    "data['senti'] = get_sentiment(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-29T13:36:51.504620Z",
     "start_time": "2018-07-29T13:36:50.770046Z"
    }
   },
   "outputs": [],
   "source": [
    "data_prev = pd.read_csv('../ScrapyDatas/weibo_test_data.csv')\n",
    "senti_dict = dict([ (hs, sen) for hs, sen in zip(data_prev.hash, data_prev.senti)])\n",
    "\n",
    "# print (senti_dict)\n",
    "if 'senti' not in data:\n",
    "    data['senti'] = pd.Series([])\n",
    "\n",
    "new_senti = []\n",
    "for hs, sen in zip(data.hash, data.senti):\n",
    "    if isinstance(sen, int) and sen > 0 and sen < 1:\n",
    "        new_senti.append(sen)\n",
    "    elif hs in senti_dict:\n",
    "        new_senti.append(senti_dict[hs])\n",
    "    else:\n",
    "        new_senti.append('')\n",
    "    \n",
    "if len(new_senti) != len(data):\n",
    "    print('senti length error')\n",
    "    \n",
    "print (new_senti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-27T00:03:18.853175Z",
     "start_time": "2018-07-27T00:03:18.811812Z"
    }
   },
   "outputs": [],
   "source": [
    "word_counts = [ get_word_count(lst) for lst in data.words]\n",
    "data['dict'] = pd.Series(word_counts)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-27T00:03:18.867398Z",
     "start_time": "2018-07-27T00:03:18.855889Z"
    }
   },
   "outputs": [],
   "source": [
    "data['level'] = (1 + data.at_cnt) * (1 + data.rep_cnt) * (1 + data.cmt_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-27T00:03:19.025832Z",
     "start_time": "2018-07-27T00:03:18.873194Z"
    }
   },
   "outputs": [],
   "source": [
    "data2 = pd.read_csv('../ScrapyDatas/weibo_test_data.csv')\n",
    "data['senti'] = data2.senti"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-26T01:21:35.655384Z",
     "start_time": "2018-07-26T01:21:35.646720Z"
    }
   },
   "source": [
    "## load idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-27T00:03:30.437045Z",
     "start_time": "2018-07-27T00:03:30.425729Z"
    }
   },
   "outputs": [],
   "source": [
    "import math, numpy as np\n",
    "def tf(word, count):\n",
    "    return count[word] / sum(count.values())\n",
    "\n",
    "def n_containing(word, count_list):\n",
    "    return sum(1 for count in count_list if word in count)\n",
    "    \n",
    "def idf(word, count_list):\n",
    "    return math.log(len(count_list) / (1 + n_containing(word, count_list)))\n",
    "\n",
    "def tfidf(word, count, count_list):\n",
    "    return tf(word, count) * idf(word, count_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-27T00:03:33.855740Z",
     "start_time": "2018-07-27T00:03:32.650298Z"
    }
   },
   "outputs": [],
   "source": [
    "data_idf_dict = pd.read_csv('../ScrapyDatas/weibo_idf_dict.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-27T00:03:44.989324Z",
     "start_time": "2018-07-27T00:03:33.897449Z"
    }
   },
   "outputs": [],
   "source": [
    "data_idf_dict = [ eval(dic) for dic in np.array(data_idf_dict[1]).tolist() ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-27T00:03:45.040218Z",
     "start_time": "2018-07-27T00:03:44.994521Z"
    }
   },
   "outputs": [],
   "source": [
    "data_dict_all = {}\n",
    "for dic in data.dict:\n",
    "    for k, v in dic.items():\n",
    "        if k in data_dict_all:\n",
    "            data_dict_all[k] += v\n",
    "        else:\n",
    "            data_dict_all[k] = v\n",
    "            \n",
    "        if len(k) == 4:\n",
    "            head, tail = k[2:], k[:-2]\n",
    "            if head in data_dict_all:\n",
    "                data_dict_all[head] += v\n",
    "            else:\n",
    "                data_dict_all[head] = v\n",
    "                \n",
    "            if tail in data_dict_all:\n",
    "                data_dict_all[tail] += v\n",
    "            else:\n",
    "                data_dict_all[tail] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-27T00:03:51.812349Z",
     "start_time": "2018-07-27T00:03:45.041942Z"
    }
   },
   "outputs": [],
   "source": [
    "# remove not nouns\n",
    "\n",
    "from snownlp import SnowNLP\n",
    "def tpok(word):\n",
    "    string = str(word)\n",
    "    s = SnowNLP(string)\n",
    "    ls = list(s.tags)\n",
    "    if len(ls) >= 3:\n",
    "        return False\n",
    "    if len(ls) == 1 and 'n' not in ls[0][1]:\n",
    "        return False\n",
    "    if len(word) == 2:\n",
    "        tail = str(word[-1])\n",
    "        st = SnowNLP(tail)\n",
    "        ls = list(st.tags)\n",
    "        if len(ls) == 1 and ls[0][1] == 'v':\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "data_dict_all = dict([ (k, v) for k, v in data_dict_all.items() if tpok(k)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-27T00:03:51.825381Z",
     "start_time": "2018-07-27T00:03:51.813827Z"
    }
   },
   "outputs": [],
   "source": [
    "data_dict_all = dict(sorted(data_dict_all.items(), key=lambda x: math.sqrt(len(x[0]))*x[1], reverse=True))\n",
    "data_dict_all = dict([(x,y) for x,y in data_dict_all.items() if y > 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-27T00:03:51.864885Z",
     "start_time": "2018-07-27T00:03:51.827543Z"
    }
   },
   "outputs": [],
   "source": [
    "data_words_list_clean = []\n",
    "for dic in data.dict:\n",
    "    data_words_clean = {}\n",
    "    for k, v in dic.items():\n",
    "        if k in data_dict_all:\n",
    "            data_words_clean[k] = v\n",
    "    data_words_list_clean.append(data_words_clean)\n",
    "\n",
    "data.dict = data_words_list_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### have dict for each, get dict for all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-27T01:00:49.111516Z",
     "start_time": "2018-07-27T01:00:46.770160Z"
    }
   },
   "outputs": [],
   "source": [
    "data_idf_dict_all = {}\n",
    "for dic in data_idf_dict:\n",
    "    for k, v in dic.items():\n",
    "        if k in data_idf_dict_all:\n",
    "            data_idf_dict_all[k] += v\n",
    "        else:\n",
    "            data_idf_dict_all[k] = v\n",
    "            \n",
    "        if len(k) == 4:\n",
    "            head, tail = k[2:], k[:-2]\n",
    "            if head in data_idf_dict_all:\n",
    "                data_idf_dict_all[head] += v\n",
    "            else:\n",
    "                data_idf_dict_all[head] = v\n",
    "                \n",
    "            if tail in data_idf_dict_all:\n",
    "                data_idf_dict_all[tail] += v\n",
    "            else:\n",
    "                data_idf_dict_all[tail] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-27T01:00:50.499359Z",
     "start_time": "2018-07-27T01:00:50.167482Z"
    }
   },
   "outputs": [],
   "source": [
    "data_idf_dict_all = dict(sorted(data_idf_dict_all.items(), key=lambda x: math.sqrt(len(x[0]))*x[1], reverse=True))\n",
    "data_idf_dict_all = dict([(x,y) for x,y in data_idf_dict_all.items() if y > 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-26T01:37:19.267989Z",
     "start_time": "2018-07-26T01:37:19.265623Z"
    }
   },
   "source": [
    "### work idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 关键词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-27T01:00:53.170110Z",
     "start_time": "2018-07-27T01:00:53.089505Z"
    }
   },
   "outputs": [],
   "source": [
    "# only tf for all\n",
    "print(\"Top words in all documents\")\n",
    "all_scores = { word: tf(word, data_dict_all) for word in data_dict_all}\n",
    "all_sorted_words = sorted(all_scores.items(), key=lambda x: math.sqrt(len(x[0]))*x[1], reverse=True)\n",
    "for word, score in all_sorted_words[:100]:\n",
    "    print(\"\\tWord: {}, TF: {}\".format(word, round(score, 5))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-27T01:01:08.603657Z",
     "start_time": "2018-07-27T01:00:55.666883Z"
    }
   },
   "outputs": [],
   "source": [
    "# tf-idf for all\n",
    "print(\"Top words in all documents\")\n",
    "\n",
    "all_scores = { word : tfidf(word, data_dict_all, data_idf_dict_all)\n",
    "                     for word in data_dict_all }\n",
    "all_sorted_words = sorted(all_scores.items(), key=lambda x: math.sqrt(len(x[0]))*x[1], reverse=True)\n",
    "for word, score in all_sorted_words[:100]:\n",
    "    print(\"\\tWord: {}, TF-IDF: {}\".format(word, round(score, 5))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-27T00:04:43.634573Z",
     "start_time": "2018-07-27T00:04:43.626529Z"
    }
   },
   "outputs": [],
   "source": [
    "### 输出关键词\n",
    "## TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-27T01:01:15.897909Z",
     "start_time": "2018-07-27T01:01:15.885565Z"
    }
   },
   "outputs": [],
   "source": [
    "# tf-idf for each\n",
    "\n",
    "def get_critical_words(data):\n",
    "    countlist = data.dict\n",
    "    critical_words = []\n",
    "    for i, count in enumerate(data.dict):\n",
    "        #print(\"Top words in document {}\".format(i))\n",
    "        scores = {word: tfidf(word, count, data_idf_dict) for word in count}\n",
    "        sorted_words = sorted(scores.items(), key=lambda x: math.sqrt(len(x[0]))*x[1], reverse=True)\n",
    "        critical_word = []\n",
    "        for word, score in sorted_words[:3]:\n",
    "            critical_word.append(word)\n",
    "            #print(\"\\tWord: {}, TF-IDF: {}\".format(word, round(score, 3))) \n",
    "        critical_words.append(critical_word)\n",
    "        if i % 100 == 0:\n",
    "            print ('cnt = {}'.format(i))\n",
    "    return critical_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-27T00:18:46.730316Z",
     "start_time": "2018-07-27T00:04:47.396721Z"
    }
   },
   "outputs": [],
   "source": [
    "critical_words_list = get_critical_words(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-27T01:01:28.575436Z",
     "start_time": "2018-07-27T01:01:28.567301Z"
    }
   },
   "outputs": [],
   "source": [
    "data['critical_word'] = critical_words_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-26T03:13:13.791592Z",
     "start_time": "2018-07-26T03:13:13.782519Z"
    }
   },
   "outputs": [],
   "source": [
    "#data.to_csv('../ScrapyDatas/weibo_test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-27T01:01:31.170116Z",
     "start_time": "2018-07-27T01:01:31.141388Z"
    }
   },
   "outputs": [],
   "source": [
    "word_senti = {}\n",
    "for sen, cri_word in zip(data.senti, data.critical_word):\n",
    "    #print(sen)\n",
    "    #print (cri_word)\n",
    "    for w in cri_word:\n",
    "        if sen == None or not isinstance(sen, float) or sen < 0:\n",
    "            continue\n",
    "        if (sen > 0.7):\n",
    "            if w in word_senti:\n",
    "                word_senti[w] += 1\n",
    "            else:\n",
    "                word_senti[w] = 1\n",
    "        if (sen < 0.3):\n",
    "            if w in word_senti:\n",
    "                word_senti[w] -= 1\n",
    "            else:\n",
    "                word_senti[w] = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 好坏词语"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-27T01:01:32.956381Z",
     "start_time": "2018-07-27T01:01:32.947407Z"
    }
   },
   "outputs": [],
   "source": [
    "word_senti_posi = sorted(word_senti.items(), key=lambda x: x[1], reverse=True)[:30]\n",
    "word_senti_nega = sorted(word_senti.items(), key=lambda x: x[1], reverse=False)[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-27T01:01:33.994784Z",
     "start_time": "2018-07-27T01:01:33.986490Z"
    }
   },
   "outputs": [],
   "source": [
    "for x in word_senti_posi:\n",
    "    print (x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-27T01:01:35.291779Z",
     "start_time": "2018-07-27T01:01:35.272630Z"
    }
   },
   "outputs": [],
   "source": [
    "for x in word_senti_nega:\n",
    "    print (x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-26T14:58:32.076303Z",
     "start_time": "2018-07-26T14:58:32.068066Z"
    }
   },
   "outputs": [],
   "source": [
    "### 输出好坏词语\n",
    "## TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-26T15:01:00.564007Z",
     "start_time": "2018-07-26T15:01:00.556909Z"
    }
   },
   "source": [
    "### 词语网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-27T01:16:03.672026Z",
     "start_time": "2018-07-27T01:16:03.659534Z"
    }
   },
   "outputs": [],
   "source": [
    "class Graph(object):\n",
    "    def __init__(self):\n",
    "        self.node_cnt = 0\n",
    "        self.id = {}\n",
    "        self.value = {}\n",
    "        self.deg = {}\n",
    "        self.name = {}\n",
    "        self.edges = {}\n",
    "        self.lim = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-27T01:16:04.427282Z",
     "start_time": "2018-07-27T01:16:04.414573Z"
    }
   },
   "outputs": [],
   "source": [
    "wG = Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-27T01:16:05.325325Z",
     "start_time": "2018-07-27T01:16:05.285610Z"
    }
   },
   "outputs": [],
   "source": [
    "for dic in data.dict:\n",
    "    for x in dic.keys():\n",
    "        if x not in wG.id:\n",
    "            wG.id[x] = wG.node_cnt\n",
    "            wG.node_cnt += 1\n",
    "            idx = wG.id[x]\n",
    "            wG.name[idx] = x\n",
    "            wG.value[idx] = 1\n",
    "            wG.deg[idx] = 0\n",
    "            wG.edges[idx] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-27T01:16:06.619310Z",
     "start_time": "2018-07-27T01:16:06.575174Z"
    }
   },
   "outputs": [],
   "source": [
    "for dic in data.dict:\n",
    "    for x in dic.keys():\n",
    "        idx = wG.id[x]\n",
    "        if idx not in wG.deg:\n",
    "            wG.deg[idx] = len(dic) - 1\n",
    "        else:\n",
    "            wG.deg[idx] += len(dic) - 1\n",
    "del_idx = set()\n",
    "for idx, val in wG.deg.items():\n",
    "    if val < wG.lim:\n",
    "        del_idx.add(idx)\n",
    "for idx in del_idx:\n",
    "    wG.name.pop(idx)\n",
    "    wG.deg.pop(idx)\n",
    "    wG.value.pop(idx)\n",
    "    wG.edges.pop(idx)\n",
    "wG.id = dict([ (k, v) for k, v in wG.id.items() if v not in del_idx ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-27T01:16:07.736147Z",
     "start_time": "2018-07-27T01:16:07.645294Z"
    }
   },
   "outputs": [],
   "source": [
    "for dic in data.dict:\n",
    "    for x in dic.keys():\n",
    "        if x in wG.id:\n",
    "            idx = wG.id[x]\n",
    "            for y in dic.keys():\n",
    "                if y != x and y in wG.id:\n",
    "                    idy = wG.id[y]\n",
    "                    if idx not in wG.edges[idy]:\n",
    "                        wG.edges[idx][idy] = 1\n",
    "                        wG.edges[idy][idx] = 1\n",
    "                    else:\n",
    "                        wG.edges[idx][idy] += 1\n",
    "                        wG.edges[idy][idx] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-27T01:16:08.862093Z",
     "start_time": "2018-07-27T01:16:08.849892Z"
    }
   },
   "outputs": [],
   "source": [
    "wG.edges = dict(sorted([ (k, v) for k, v in wG.edges.items() if len(v) > 1 ], key = lambda x: -len(x[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-27T01:16:11.158483Z",
     "start_time": "2018-07-27T01:16:11.136111Z"
    }
   },
   "outputs": [],
   "source": [
    "for x in [ {wG.name[idx]: { wG.name[idy]: v for idy, v in chx.items() if idy in wG.name} } for idx, chx in wG.edges.items()] :\n",
    "    print (x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top weibos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-27T00:26:33.728380Z",
     "start_time": "2018-07-27T00:26:33.703258Z"
    }
   },
   "outputs": [],
   "source": [
    "hottest_data = data.sort_values(by='level', axis=0, ascending=False)[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-27T00:26:34.832247Z",
     "start_time": "2018-07-27T00:26:34.810099Z"
    }
   },
   "outputs": [],
   "source": [
    "print (hottest_data.get(['level', 'text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-27T11:40:21.032614Z",
     "start_time": "2018-07-27T11:40:21.029797Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-27T11:47:07.862314Z",
     "start_time": "2018-07-27T11:47:07.848330Z"
    }
   },
   "outputs": [],
   "source": [
    "hash_list = [ int((hash(x)+len(str(y))*47)%(1e9+7)) for x, y in zip(data.text, data.user)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-27T11:47:08.511016Z",
     "start_time": "2018-07-27T11:47:08.491221Z"
    }
   },
   "outputs": [],
   "source": [
    "data['hash'] = hash_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-27T12:08:17.909533Z",
     "start_time": "2018-07-27T12:08:17.902939Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame([[1,2,3,4],[1,2,3,4],[1,'',2],[1,4,'']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-27T12:09:27.162219Z",
     "start_time": "2018-07-27T12:09:27.153435Z"
    }
   },
   "outputs": [],
   "source": [
    "df.columns = ['a','b','c','d']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-27T12:11:00.927797Z",
     "start_time": "2018-07-27T12:11:00.916693Z"
    }
   },
   "outputs": [],
   "source": [
    "def t1(df):\n",
    "    for cnt, (x, y) in enumerate(zip(df.e,df.a)):\n",
    "        if not isinstance(x, int):\n",
    "            df.loc[cnt,'e'] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-27T12:11:12.394581Z",
     "start_time": "2018-07-27T12:11:12.380693Z"
    }
   },
   "outputs": [],
   "source": [
    "t1(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-27T12:10:46.749092Z",
     "start_time": "2018-07-27T12:10:46.743431Z"
    }
   },
   "outputs": [],
   "source": [
    "df['e'] = pd.Series([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-27T13:27:47.528649Z",
     "start_time": "2018-07-27T13:27:47.480948Z"
    }
   },
   "outputs": [],
   "source": [
    "dict([ (hs, sen) for hs, sen in zip(data2.hash, data2.senti)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-28T02:55:49.870030Z",
     "start_time": "2018-07-28T02:55:49.859723Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.width', 10000)  # 设置字符显示宽度\n",
    "pd.set_option('display.max_rows', None)  # 设置显示最大行\n",
    "pd.set_option('display.max_colwidth',1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-28T03:05:35.407865Z",
     "start_time": "2018-07-28T03:05:35.283537Z"
    }
   },
   "outputs": [],
   "source": [
    "for text in data2.text:\n",
    "    text = re.sub('<.*?>', '', text)\n",
    "    text = text.replace(\"\\\\n\", '')\n",
    "    print (text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-28T03:45:46.193240Z",
     "start_time": "2018-07-28T03:45:46.185947Z"
    }
   },
   "outputs": [],
   "source": [
    "senti_dict = dict([ (hs, sen) for hs, sen in zip(data.hash, data.senti)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-28T03:48:44.042090Z",
     "start_time": "2018-07-28T03:48:44.030493Z"
    }
   },
   "outputs": [],
   "source": [
    "data3=data2\n",
    "data3['senti'] = pd.Series([])\n",
    "if 'senti' not in data3:\n",
    "    data3['senti'] = pd.Series([])\n",
    "\n",
    "new_senti = []\n",
    "for hs, sen in zip(data.hash, data.senti):\n",
    "    if isinstance(sen, int) and sen > 0 and sen < 1:\n",
    "        new_senti.append(sen)\n",
    "    elif hs in senti_dict:\n",
    "        new_senti.append(senti_dict[hs])\n",
    "    else:\n",
    "        new_senti.append('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-28T10:16:17.459044Z",
     "start_time": "2018-07-28T10:16:17.456022Z"
    }
   },
   "outputs": [],
   "source": [
    "week=[ time.strftime('%Y-%m-%d', time.localtime(time.time() - x * 24 * 60 * 60)) for x in range(7) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-29T01:48:26.104230Z",
     "start_time": "2018-07-29T01:48:26.100263Z"
    }
   },
   "outputs": [],
   "source": [
    "data_idf_iterator = pd.read_csv('../ScrapyDatas/weibo_idf_dict.csv', chunksize=10000, header=None)\n",
    "\n",
    "data_idf_dict = []\n",
    "for data_chunk in data_idf_iterator:\n",
    "    data_idf_dict_chunk = [ eval(dic) for dic in np.array(data_chunk[1]).tolist() ]\n",
    "    data_idf_dict.extend(data_idf_dict_chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-29T01:49:34.991221Z",
     "start_time": "2018-07-29T01:49:34.987761Z"
    }
   },
   "outputs": [],
   "source": [
    "print (data_idf_dict[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-04T16:24:42.117673Z",
     "start_time": "2018-08-04T16:24:41.481412Z"
    }
   },
   "outputs": [],
   "source": [
    "import pymongo\n",
    "import pandas as pd\n",
    "import re, time, requests\n",
    "mongo_uri = 'mongodb://impulse:njuacmicpc@120.79.139.239/weibo'\n",
    "client = pymongo.MongoClient(host=mongo_uri, port=27017)\n",
    "db = client['weibo']\n",
    "collection = db['weibos']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-04T16:29:22.395821Z",
     "start_time": "2018-08-04T16:29:22.385772Z"
    }
   },
   "outputs": [],
   "source": [
    "results = collection.find({}, {'user':1,'attitudes_count':1,'text':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-01T12:48:12.449365Z",
     "start_time": "2018-08-01T12:48:12.137614Z"
    }
   },
   "outputs": [],
   "source": [
    "collection.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-01T12:10:00.243370Z",
     "start_time": "2018-08-01T12:10:00.182170Z"
    }
   },
   "outputs": [],
   "source": [
    "collection.find_one({'id':'4266105453476132'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T16:09:38.717525Z",
     "start_time": "2018-07-31T16:09:38.662433Z"
    }
   },
   "outputs": [],
   "source": [
    "collection.update({'id':'4266105453476132'}, {'$set': {'senti':0.075441} })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T16:27:46.733248Z",
     "start_time": "2018-07-31T16:27:46.180217Z"
    }
   },
   "outputs": [],
   "source": [
    "data_prev = pd.read_csv('../ScrapyDatas/weibo_test_data.csv')\n",
    "len(data_prev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T16:54:05.204057Z",
     "start_time": "2018-07-31T16:27:47.840155Z"
    }
   },
   "outputs": [],
   "source": [
    "for x in zip(list(data_prev.id), list(data_prev.senti)):\n",
    "    collection.update({'id':str(x[0])}, {'$set': {'senti':float(x[1])} })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-01T01:19:55.254546Z",
     "start_time": "2018-08-01T01:19:55.210858Z"
    }
   },
   "outputs": [],
   "source": [
    "collection_good = db['good_words']\n",
    "collection_good.insert_one({'word':str('性质'), 'senti':float(-14)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-01T01:59:25.442690Z",
     "start_time": "2018-08-01T01:59:25.436886Z"
    }
   },
   "outputs": [],
   "source": [
    "x = ('疫苗', [('李克强', 36), ('道德', 30), ('国务院', 22), ('医药', 22), ('康泰', 20), ('腾讯', 6), ('阶段性', 6), ('丽水', 2), ('竹乡', 2), ('涉嫌犯罪', 8), ('公安机关', 8), ('存量', 4)])`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-01T12:36:01.946790Z",
     "start_time": "2018-08-01T12:36:01.932869Z"
    }
   },
   "outputs": [],
   "source": [
    "print ('In {}, begin, date is {}'.format('fe', time.strftime('%Y-%m-%d-%H:%M', time.localtime(time.time()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weibo.weibos的格式：\n",
    "{\n",
    "    \"_id\" : ObjectId(\"5b66edecc6769559cbd37f4c\"),\n",
    "    # 索引 ; 自动生成\n",
    "    \"id\" : \"4269654501116032\",\n",
    "    # 微博编号 ; 非负整数\n",
    "    \"attitudes_count\" : 1,\n",
    "    # 点赞数 ; 非负整数\n",
    "    \"comments_count\" : 0,\n",
    "    # 评论数 ; 非负整数\n",
    "    \"reposts_count\" : 0,\n",
    "    # 转发数 ; 非负整数\n",
    "    \"created_at\" : \"2018-08-05 00:00\",\n",
    "    # 创建时间 ; '%Y-%m-%d %H:%M'\n",
    "    \"source\" : \"月亮点金股市论坛超话\",           \n",
    "    # 来源，貌似没什么用 ; 普通文本\n",
    "    \"text\" : \"周评出炉 下周需注意几点：\",        \n",
    "    # 原微博 ; HTML格式（可能爬取残缺）\n",
    "    \"user\" : \"3146057615\", \n",
    "    # 微博用户名 ; 非负整数\n",
    "    \"crawled_at\" : \"2018-08-12 20:30\",\n",
    "    # 爬取时间 ; '%Y-%m-%d %H:%M'\n",
    "    \"created_date\" : \"2018-08-05\",\n",
    "    # 创建日期 ; '%Y-%m-%d'\n",
    "    \"full_text\" : \"......\"                   \n",
    "    # 原微博全文（如果‘text’不全则有‘full_text',我可以合并起来）; HTML格式（可能爬取残缺）\n",
    "    \"senti\" : 0.687963,\n",
    "    # 情感倾向 ; （0,1）间小数\n",
    "    \"level\" : 2\n",
    "    # 热门指标，即（点+1）×（评+1）×（转+1）; 非负整数\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weibo.word_tf的格式：## tf指词频\n",
    "{\n",
    "    \"_id\" : ObjectId(\"5b70a2d52309e626a47b3921\"),\n",
    "    # 索引 ; 自动生成\n",
    "    \"word\" : \"股份\",\n",
    "    # 词语 ; 普通文本\n",
    "    \"tf\" : 0.013,\n",
    "    # 词频： 普通浮点数\n",
    "    \"created_date\" : \"2018-08-13\"\n",
    "    # 创建日期 ; '%Y-%m-%d'\n",
    "}\n",
    "\n",
    "weibo.word_tfidf的格式：## tfidf指词频乘以逆频率\n",
    "{\n",
    "    \"_id\" : ObjectId(\"5b70a2d52309e626a47b3921\"),\n",
    "    # 索引 ; 自动生成\n",
    "    \"word\" : \"股份\",\n",
    "    # 词语 ; 普通文本\n",
    "    \"tfidf\" : 0.013,\n",
    "    # 词频乘以逆频率： 普通浮点数\n",
    "    \"created_date\" : \"2018-08-13\"\n",
    "    # 创建日期 ; '%Y-%m-%d'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weibo.good_words的格式：## good_words指senti较高的词语\n",
    "{\n",
    "    \"_id\" : ObjectId(\"5b70a2f42309e626a47b3d09\"),\n",
    "    \"word\" : \"原油\",\n",
    "    \"senti\" : 275.0,\n",
    "    \"created_date\" : \"2018-08-13\"\n",
    "}\n",
    "\n",
    "weibo.bad_words的格式：## bad_words指senti较低的词语\n",
    "{\n",
    "    \"_id\" : ObjectId(\"5b70a2f92309e626a47b3efd\"),\n",
    "    \"word\" : \"答题卡\",\n",
    "    \"senti\" : -81.0,\n",
    "    \"created_date\" : \"2018-08-13\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weibo.word_graph：## word_graph指词语之间的关系图\n",
    "{\n",
    "    \"_id\" : ObjectId(\"5b70a2fd2309e626a47b4110\"),\n",
    "    # 索引 ; 自动生成\n",
    "    \"vertex\" : \"橡胶\",\n",
    "    # （词语）节点 ; 普通文本\n",
    "    \"adjacent-list\" : [ \n",
    "        [ \n",
    "            \"苹果\", \n",
    "            526\n",
    "        ], \n",
    "        [ \n",
    "            \"原油\", \n",
    "            528\n",
    "        ], \n",
    "        [ \n",
    "            \"黄金\", \n",
    "            488\n",
    "        ], \n",
    "    ]\n",
    "    # （表示节点关系的）邻接表 ; list套list， 其中内层的list表示边的另一个节点，以及边权（越大表示词语之间的关系越大）\n",
    "    #  相当于 std::vector<std::pair<std::string,int>>\n",
    "    \"created_date\" : \"2018-08-13\"\n",
    "    # 创建日期 ; '%Y-%m-%d'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-19T12:01:05.546643Z",
     "start_time": "2018-10-19T12:01:05.528846Z"
    }
   },
   "outputs": [],
   "source": [
    "import pymongo\n",
    "mongo_uri = 'mongodb://impulse:njuacmicpc@120.79.139.239/weibo'\n",
    "client = pymongo.MongoClient(host=mongo_uri, port=27017)\n",
    "db = client['weibo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-19T12:02:07.224173Z",
     "start_time": "2018-10-19T12:01:06.497889Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "collection = db['users']\n",
    "data = pd.DataFrame(list(collection.find({})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-19T12:18:44.283570Z",
     "start_time": "2018-10-19T12:18:44.242272Z"
    }
   },
   "outputs": [],
   "source": [
    "data = data[['id', 'description', 'fans_count', 'gender',\n",
    "             'name', 'verified_reason', 'verified_type', 'weibos_count']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-19T12:18:45.262427Z",
     "start_time": "2018-10-19T12:18:45.213553Z"
    }
   },
   "outputs": [],
   "source": [
    "data['text'] = data['description']\n",
    "data['reason'] = data['verified_reason']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-19T12:18:46.128571Z",
     "start_time": "2018-10-19T12:18:46.111589Z"
    }
   },
   "outputs": [],
   "source": [
    "data = data.drop(axis=0,columns=['description', 'verified_reason'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-19T12:18:46.903370Z",
     "start_time": "2018-10-19T12:18:46.852855Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>fans_count</th>\n",
       "      <th>gender</th>\n",
       "      <th>name</th>\n",
       "      <th>verified_type</th>\n",
       "      <th>weibos_count</th>\n",
       "      <th>text</th>\n",
       "      <th>reason</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5802435481</td>\n",
       "      <td>784</td>\n",
       "      <td>m</td>\n",
       "      <td>腾龙创富</td>\n",
       "      <td>2</td>\n",
       "      <td>68</td>\n",
       "      <td>致力于资产管理、期货股票投资指导、专业操盘手实战培训。</td>\n",
       "      <td>安徽腾龙创富金融信息服务有限公司</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6018430740</td>\n",
       "      <td>170</td>\n",
       "      <td>m</td>\n",
       "      <td>品股话投资</td>\n",
       "      <td>2</td>\n",
       "      <td>168</td>\n",
       "      <td>赣南有脐橙，国内皆有名！卖了脐橙买股票，持好股票卖脐橙，我是认真的，购橙V信：cwy1333...</td>\n",
       "      <td>龙南艾德礼品有限公司官方微博</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3146057615</td>\n",
       "      <td>6076</td>\n",
       "      <td>m</td>\n",
       "      <td>月亮点金</td>\n",
       "      <td>0</td>\n",
       "      <td>556</td>\n",
       "      <td>知名财经博主 头条文章作者 微博签约自媒体</td>\n",
       "      <td>财经博主</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5997213232</td>\n",
       "      <td>3453</td>\n",
       "      <td>m</td>\n",
       "      <td>李信玄</td>\n",
       "      <td>0</td>\n",
       "      <td>7498</td>\n",
       "      <td>我的微信号：sz06888，欢迎大家前来交流学习，免费解答个股问题。</td>\n",
       "      <td>财经博主 头条文章作者</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3869635429</td>\n",
       "      <td>76142</td>\n",
       "      <td>m</td>\n",
       "      <td>股道老张</td>\n",
       "      <td>0</td>\n",
       "      <td>13909</td>\n",
       "      <td>拥有丰富的解盘及操盘实战经验，对于热点题材龙头个股的把握较为精准并擅长把握各类主题投资机会。...</td>\n",
       "      <td>财经博主 头条文章作者 微博签约自媒体</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  fans_count gender   name  verified_type  weibos_count  \\\n",
       "0  5802435481         784      m   腾龙创富              2            68   \n",
       "1  6018430740         170      m  品股话投资              2           168   \n",
       "2  3146057615        6076      m   月亮点金              0           556   \n",
       "3  5997213232        3453      m    李信玄              0          7498   \n",
       "4  3869635429       76142      m   股道老张              0         13909   \n",
       "\n",
       "                                                text               reason  \n",
       "0                        致力于资产管理、期货股票投资指导、专业操盘手实战培训。     安徽腾龙创富金融信息服务有限公司  \n",
       "1  赣南有脐橙，国内皆有名！卖了脐橙买股票，持好股票卖脐橙，我是认真的，购橙V信：cwy1333...       龙南艾德礼品有限公司官方微博  \n",
       "2                              知名财经博主 头条文章作者 微博签约自媒体                 财经博主  \n",
       "3                 我的微信号：sz06888，欢迎大家前来交流学习，免费解答个股问题。          财经博主 头条文章作者  \n",
       "4  拥有丰富的解盘及操盘实战经验，对于热点题材龙头个股的把握较为精准并擅长把握各类主题投资机会。...  财经博主 头条文章作者 微博签约自媒体  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-19T12:18:49.596557Z",
     "start_time": "2018-10-19T12:18:49.591689Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.cluster import KMeans\n",
    "import jieba\n",
    "import re\n",
    "import math\n",
    "import jieba.posseg as postag\n",
    "\n",
    "def read_stop_words():\n",
    "    stop_words = []\n",
    "    stop_letters = []\n",
    "    with open('clustering_stop_words.txt') as sp:\n",
    "        for x in sp:\n",
    "            stop_words.append(x[:-1])\n",
    "\n",
    "    stop_words = set(stop_words)\n",
    "    return stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-19T12:18:50.550400Z",
     "start_time": "2018-10-19T12:18:50.524203Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "stop_words = read_stop_words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-19T12:18:57.158506Z",
     "start_time": "2018-10-19T12:18:51.864573Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR expected string or bytes-like object\n"
     ]
    }
   ],
   "source": [
    "documents = list(data.text)\n",
    "causes = list(data.reason)\n",
    "\n",
    "sentences_text, sentences_reason = [], []\n",
    "for sen in documents:\n",
    "    seg = None\n",
    "    try:\n",
    "        sen = re.sub('[^\\u4e00-\\u9fa5|，|!|。]+|\\?{1}|:{1}', '', sen)\n",
    "        seg = postag.cut(sen)\n",
    "        seg = [x.word for x in seg if (len(x.word) > 1 and 'n' in x.flag and x not in stop_words)]\n",
    "        seg = ' '.join(seg)\n",
    "    except Exception as err:\n",
    "        print('ERROR {}'.format(err))\n",
    "        seg = '错误'\n",
    "    sentences_text.append(seg)\n",
    "\n",
    "for sen in causes:\n",
    "    seg = None\n",
    "    try:\n",
    "        sen = re.sub('[^\\u4e00-\\u9fa5|，|!|。]+|\\?{1}|:{1}', '', sen)\n",
    "        seg = postag.cut(sen)\n",
    "        seg = [x.word for x in seg if len(x.word) > 1]\n",
    "        seg = ' '.join(seg)\n",
    "    except Exception as err:\n",
    "        print('ERROR {}'.format(err))\n",
    "        seg = '错误'\n",
    "    sentences_reason.append(seg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-19T07:40:02.552038Z",
     "start_time": "2018-10-19T07:40:02.550159Z"
    }
   },
   "outputs": [],
   "source": [
    "# ls = sorted(counter.items(), key = lambda x: x[1], reverse=True)\n",
    "# for x in ls: print (x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-19T12:18:58.845121Z",
     "start_time": "2018-10-19T12:18:58.782275Z"
    }
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(max_features = 500)\n",
    "transformer = TfidfTransformer()\n",
    "\n",
    "tfidf_text = transformer.fit_transform(vectorizer.fit_transform(sentences_text))\n",
    "tfidf_reason = transformer.fit_transform(vectorizer.fit_transform(sentences_reason))\n",
    "tfidf_text /= float(2)\n",
    "\n",
    "text_features = pd.DataFrame(tfidf_text.toarray())\n",
    "reason_features = pd.DataFrame(tfidf_reason.toarray())\n",
    "\n",
    "type_features = pd.get_dummies(data.verified_type)\n",
    "\n",
    "weibo_fetures = data.weibos_count.apply(lambda x: math.log2(x + 1))\n",
    "fan_features = data.fans_count.apply(lambda x: math.log2(x + 1))\n",
    "weibo_fetures /= 0.5 * weibo_fetures.mean()\n",
    "fan_features /= 0.5 * fan_features.mean()\n",
    "\n",
    "features = pd.concat([text_features, reason_features, type_features,\n",
    "                      weibo_fetures, fan_features], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-19T12:19:02.950260Z",
     "start_time": "2018-10-19T12:18:59.819652Z"
    }
   },
   "outputs": [],
   "source": [
    "clr = KMeans(n_clusters = 32)\n",
    "clr.fit(features)\n",
    "labels = clr.labels_\n",
    "data['labels'] = pd.Series(clr.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-19T12:50:28.246311Z",
     "start_time": "2018-10-19T12:50:28.238155Z"
    }
   },
   "outputs": [],
   "source": [
    "id_bucket = defaultdict(lambda: [])\n",
    "id_map = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-19T12:50:28.992223Z",
     "start_time": "2018-10-19T12:50:28.923186Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : 75\n",
      "0 作家、独立时评人、财经评论员、文盲+法盲+精神病之律师、中共党员。战忽局法律顾问。电话：0514-80116490；微信号：lmz8848。不怕骚扰。 律师 知名法律博主 头条文章作者\n",
      "0 关注股市！关注经济！关注小散！专注短线！ 财经博主 中信证券股份有限公司经理 头条文章作者 微博签约自媒体\n",
      "0 相声演员中国煤矿文工团说唱团团长国家一级演员，中国曲艺家协会理事，第三届中国曲艺牡丹奖获得者，享受国务院特殊津贴 人称《股民团长》 中国煤矿文工团说唱团团长、著名相声演员\n",
      "0 本微博已停用。📢新微博：浙商投资卢献星V   请联系微信：zheshang789。 微信公众号：浙商投资卢献星  著名预言家，股票＂计量经济学模型＂专家组长 浙江沃德投资有限公司董事长 头条文章作者\n",
      "0 本博所提及股票仅限讨论，不构成推荐，读者免费参考，盈亏自负 微博股评师\n",
      "\n",
      "1 : 89\n",
      "0 知名财经博主 头条文章作者 微博签约自媒体 财经博主\n",
      "0 自由期货投资人，偏好趋势交易、对冲套利，价差投机。 财经博主\n",
      "0 专业从事期货市场分析与研究，由于观点独特精准而受到交易者喜爱.学习群651990052验证吗20000 财经博主\n",
      "0 Vampire创始人，华信万达期货特邀名家专栏，摩尔金融撰稿人。 财经博主\n",
      "0 这是一个神奇的投资群，不收取任何费用，周收益25%以上，没有可以退群！！！QQ群号：348464258 加群验证：336 财经博主\n",
      "\n",
      "2 : 55\n",
      "2 2013，招商期货“问鼎九州”全国期货实盘交易大赛（暨第七届全国期货实盘交易大赛），纵路英豪来袭，谁来问鼎！报名时间：2013年3月15日-2013年9月30日报名电话：95565-4-2-1 招商期货官方微博\n",
      "2 大连地区唯一的金融综合门户、财经媒体。 大连金融网 dljrw.com官方微博\n",
      "2 出国旅游最低价！ 解决网-特价海外游官方微博\n",
      "2 特价啦！特价啦！清仓处理，香港电话卡，卡内有48元话费，现在仅售RMB25元，有需要的请联系我！ 佳泰假期官方微博\n",
      "2 诺德基金2013年第四季度首发的市场中性量化策略专户产品，成立以来业绩表现和风险收益特征充分体现产品优势。该产品的多只后续系列产品目前正在热销中，详情垂询4008880009转8 诺德基金官方微博\n",
      "\n",
      "3 : 76\n",
      "0 关注港股窝轮牛熊证，与投资者交流互动，分享窝轮牛熊证选择逻辑。 财经博主 头条文章作者\n",
      "0 常能遣其欲，而心自静，澄其心而神自清 。 期货交流QQ：327904270 财经博主 头条文章作者\n",
      "0 投资：第一控制好风险，第二才是收益。 财经博主 头条文章作者\n",
      "0 80后自由炒股人，善长量价，准确测量预测股票具体目标价格。 财经博主 头条文章作者\n",
      "0 股票分析师 头条文章作者\n",
      "\n",
      "4 : 55\n",
      "2 盈盈理财成立于2013年4月，是国内领先的基于先进互联网技术和严格风险控制管理体系的金融信息服务及撮合交易平台，致力为广大投资人提供低门槛、易于理解、操作简便、安全高效、收益稳定可观的理财产品和投资渠道。 杭州龙盈互联网金融信息技术有限公司\n",
      "2 仙人掌股票APP，为股民提供快捷的股票资讯，跟投资达人的组合，加入投资达人的圈子，分享最牛的达人投资思路，让炒股变得简单！ 上海翼优信息技术有限公司\n",
      "2 1秒注册即可实盘炒港股，无需线下见证开户，免去繁琐流程省时省事。 北京汇众财富投资管理有限公司\n",
      "2 投中网是中国股权投资领域第一门户网站。隶属于投中信息（新三板股票代码835562）。网站致力于连接人，信息与资产。为所有关注私募股权投资行业的用户提供最为专业的资讯、数据、研究、会议等服务。关注网站信息请访问：微信：（China-Venture）网站：www.chinaventure.com.cn 投中信息官方微博\n",
      "2 天弘基金是余额宝的基金管理人，截至2017年6月30日，天弘基金用户总数扩大至3.75亿户，国内平均每4人就有一个天弘基金客户；2017年上半年，天弘基金旗下公募基金为投资者赚取收益约230亿元�� 天弘基金是余额宝基金管理人\n",
      "\n",
      "5 : 30\n",
      "0 财经意见领袖 职业投资人 知名财经博主 头条文章作者\n",
      "0 追求稳定收益 知名财经博主 黄金投资分析师 头条文章作者\n",
      "0 擅长逃顶，只做事前预判，不做事后诸葛亮，不搞马后炮！ 知名财经博主 头条文章作者\n",
      "0 本微博所提及的个股仅从纯技术消息出发，不代表必涨或必跌，仅供参考，风险自担。 知名财经博主 头条文章作者\n",
      "0 本人擅长短线，超短线投资 知名财经博主 头条文章作者\n",
      "\n",
      "6 : 47\n",
      "0 娱乐财经达人 微博股评团成员\n",
      "0 一个十年磨一剑的老股民，目前专注商品期货跨期套利 微博股评团成员\n",
      "0 证券万三佣金、股票期货配资、个股期指合作、银行直存、黄金外汇开户，可微博私信。交流群：51243866 微博股评师\n",
      "0 个人博客，以博会友，可供技术交流，本博观点及文中所列举个股，仅供参考，买卖者请风险自控！ 前   国泰君安证券股份有限公司经理  微博股评团成员\n",
      "0 20年的股市风风雨雨，只想把经验与大家分享，一起交流，才会有所收获。本微博只记录自己的操作，不荐股，不收费，只交流，不建议跟风 微博股评师\n",
      "\n",
      "7 : 40\n",
      "0 两大爱好：风水和股票 知名美股投资人\n",
      "0 日出日落，星辰变幻。教主买股票，带你做最成功的投资，陪你看最美丽的风景 职业投资人 微博签约自媒体\n",
      "0 千帆竞过，百舸争流，股海沉浮十余载，实战派投资风格，追求持续稳定的投资回报收益，仙人掌和雪球财经网站昵称 回头想想 仙人掌股票签约博主 头条文章作者\n",
      "0 在南山，有个爱玩股票的女的。 华盛资本证券特约评论员\n",
      "0 最接地气的华尔街资深美股投研团队，研究在新浪财经、搜狐财经、华尔街见闻等各大财经媒体发布。 特许金融分析师  股票研究员 财经博主 美股超话主持人\n",
      "\n",
      "8 : 105\n",
      "0 旅游钓鱼有我、摄影收藏有我、炒股买彩有我、球迷有我、卡拉有我、捐款有我。小时淘气老师批评我说：啥事都有你？老师我没放火没抢粮食没盗墓。 财经博主\n",
      "0 此人不善交易，A股、港股、美股都有在看， 科技、消费、周期雨露均沾，建议不要轻易关注。 财经博主\n",
      "0 擅长股票的技术理论分析，对缠论有独到的理解，尤其大盘分析独到、数次成功精准逃顶，职业操盘手。 财经博主\n",
      "0 黑色系期货职业投资者，专注黑色产业研究。 财经博主\n",
      "0 第一财经直播嘉宾 财经博主\n",
      "\n",
      "9 : 41\n",
      "2 华盛通是新浪集团和微博旗下的港股、美股投资服务平台。致力于科技与金融结合，为用户提供不断进化的投资交易工具。可通过手机在3分钟内完成香港证券户头的开立，同步获得港股、美股的交易通道。华盛为用户提供业内最低水平的佣金收费，港股交易佣金仅为万分之三，美股每笔则低至1.99美金。 华盛证券官方微博\n",
      "2 MCN机构 微博股票合作伙伴 环铭文化\n",
      "2 换手率手机短线炒股神器App，Level-2实时资金量化，短线私募操盘手自媒体。国内一线顶尖短线私募联合开发！ 上海利莫网络科技有限公司\n",
      "2 光波投资 股票事业部，致力于股票技术研究。 光波投资 股票事业部\n",
      "2 专注于高收益与安全性的互联网理财平台 上海能睿金融信息服务有限公司\n",
      "\n",
      "10 : 21\n",
      "3 新浪财经国际组官博，第一时间传递环球市场风云、关注世界财经。主打产品新浪财经APP，全球华人首选财经APP，大数据诊股开放体验，名家高手在线答疑，A股、港股、美股、期货、外汇所有行情全覆盖。 新浪财经美股官方微博\n",
      "3 提供财经资讯、商业故事、各界观点，关注制度建设。微信搜索&lt;21世纪经济报道&gt;或加&lt;jjbd21&gt;,更多精彩内容等着你。 21世纪经济报道官方微博\n",
      "3 微博股票官方运营账号 微博股票官方微博\n",
      "3 全面追蹤香港股市、匯市、樓市最新行情 香港財經資訊微博\n",
      "3 中国经济网是经济日报主办的中央重点新闻网站和国家经济门户网站，以经济报道、资讯传播和经济服务为主要发展方向，致力于打造“最具权威性的财经网… 中国经济网法人微博\n",
      "\n",
      "11 : 31\n",
      "0 从事金融行业六年，专研短线周期操作策略，擅长多维双边波段选股。 知名财经博主 股评团成员 头条文章作者\n",
      "0 基本功过硬，极致精准分析，简单快乐炒股，持续稳定盈利。 微博股评师 财经博主 头条文章作者\n",
      "0 题材挖掘预期龙头股 微博股评团成员 头条文章作者\n",
      "0 精通筹码理论，擅长躺底与逃顶，精准把握市场的节奏，独创分时看盘与盘口语言，把控A股的波动。 财经博主 微博股评团成员 头条文章作者\n",
      "0 空姐喜欢炒股！超短线！关注微博分享自己持股！ 微博股评团成员 财经博主 头条文章作者 微博签约自媒体\n",
      "\n",
      "12 : 5\n",
      "2 个股分析：http://tg.gchj.com.cn/wap/fstsj04/ 北京盛世创富证券投资顾问有限公司\n",
      "2 以商品期货为基础、金融期货为重点，依托中投证券的研究力量，实时播报最新研究成果。注：2010年大商所-和讯网十大农产品期货研发团队。 天琪期货研究所官方微博\n",
      "2 www.gshk.net国内第一家以做空为主要投资手段的研究机构。 国内第一家互联网金融即时通信服务供应商 深圳冠穗衍生品信息服务有限公司\n",
      "3 《海西财经报道》是厦门最具影响力的财经栏目，每周一至周五厦视二套22:10首播，呈现最新财经资讯。每周六≪金融聚焦≫权威报道海西金融业界热点。 厦门电视台财富直通车栏目官方微博\n",
      "2 圈知道……让收益再多一点！ 上海商询道信息科技有限公司\n",
      "\n",
      "13 : 116\n",
      "0 最全MT4指标模版：打造黄金白银外汇赚钱的MT4指标模版交易系统！微信：335326784 广发证券股份有限公司上海分公司经理 财经博主\n",
      "0 华安期货 股指期货 国债 程序化交易 套利 套保 结构化产品 期货私募 对冲 铁矿石 理财 期货培训 基本面 技术分析 华安期货有限责任公司 副总经理\n",
      "0 股之逻辑，尤擅长基本面分析。    深圳市易启传媒有限公司市场总监\n",
      "0 期货！ 万达期货工业品事业部黄金分析师孔赵楠\n",
      "0 从“制造”到“智造”再到＂资造＂， 打造奥康 黄金十年。 奥康股票简称：奥康国际 股票代码：603001 奥康鞋业股份有限公司副总裁、执行董事  奥康鞋业销售公司总经理\n",
      "\n",
      "14 : 56\n",
      "3 观柳州，看柳州！生活大事小情、探底楼市房事、大街小巷美食……在柳州，扒客柳州！ 锦拓图文化传媒官方微博\n",
      "3 网易股票频道，实用可靠的股票投资平台和社区，做影响股价的资讯。 网易股票官方微博\n",
      "3 新浪港股官方微博,提供最快最全面的港股资讯；欢迎报料、投稿，请发微博私信。 新浪港股官方微博\n",
      "3 华尔街见闻出品，专注于美股市场，为您提供最重要的资讯数据，最全面的市场动态和最深刻的解读分析 由华尔街见闻出品，提供美股行情、经济数据和重大新闻\n",
      "3 新浪理财师平台汇聚数千名执业理财师，覆盖沪深股市3000+股票！实时行情解读、个股疑问秒回、交易计划共享。炒股找老师，就上新浪理财师！ 新浪理财师互联网金融平台官方微博\n",
      "\n",
      "15 : 51\n",
      "0 螺纹钢铁矿石黑色产业链顶层设计书记处书记员，期货证券行业战略规划师。国家商品期货宏观产业对冲基金战略策划师，红色中国共产主义事业时政评论员。 知名财经博主\n",
      "0 实战派，擅长挖掘中线趋势牛股！2013年起受邀入驻各大财经网站做股市直播，近年来获得十大最具有潜力导师，短线牛股大赛冠军！ 知名财经博主\n",
      "0 独立财经撰稿人，股票操盘专家，职业投资人。 知名财经博主\n",
      "0 港股通非官方微博 知名财经博主\n",
      "0 职业操盘手 短线高手明星赛冠军 知名财经博主\n",
      "\n",
      "16 : 15\n",
      "5 浙江在线（http://www.zjol.com.cn/）是国务院新闻办确定的地方重点新闻网站，浙江省惟一的省级重点新闻网站和综合性门户网站。网站以“权威媒体、大众网站”为基本定位，目前日均访问量达到1500万人次，内容影响力和经营实力已跃居全国地方网媒前列。2011年9月29日，浙江在线新闻网站纳入“浙报传媒”整体上市，成为国务院新闻办首批十家转企改制新闻网站中第一家成功登陆A股的网络媒体。新闻热线：0571-85311035 浙江在线官方微博\n",
      "5 和讯股票是国内知名财经网站和讯网旗下股票频道，提供全方位24小时全球股票行情，目前有A股、港股、美股、新股、券商、新三板、千股宝典等几大子频道，并提供资金流向、大宗交易等专业数据浏览。了解更多，请点击：http://stock.hexun.com/ 和讯网股票频道stock.hexun.com官方微博\n",
      "5 【云财经】国内第一股票情报聚合平台。专注于财经、证券、金融领域的资讯集成、舆情监控与大数据挖掘研究，提供国内唯一的股市垂直搜索服务。www.yuncaijing.com 云财经网 www.yuncaijing.com 官方微博\n",
      "5 东方财富网旗下股吧（http://guba.eastmoney.com）是给大家提供社交，行业分析以及个股探讨的全方位网络平台。希望您在股吧聊得开心，并能得到让您满意的资讯！东方财富网股吧团队竭诚为您服务！立即注册为股吧用户：http://passport.eastmoney.com/PhoneReg.EmUser?http://guba.eastmoney.com/ 东方财富网股吧 guba.eastmoney.com官方微博\n",
      "5 中国最大财经门户网站。最新版【和讯财经APP】上， 每天上千条财经动态7x24小时滚动播报，股票新闻定制化推送，敬请下载。 和讯网官方微博\n",
      "\n",
      "17 : 47\n",
      "2 牛钱网，做专业金融衍生品投资服务平台，经营团队拥有10多年金融系统、财经传媒和丰富的线下业务经验！ 牛乾金融信息服务（上海）有限公司\n",
      "2 智通财经http://www.zhitongcaijing.com/ 深圳智通财经信息科技服务有限公司\n",
      "2 五矿期货投资群QQ:187957130、148187174 五矿经易期货有限公司\n",
      "2 做铜生意，看铜资讯，铜期货行情分析，就上中铜在线。中铜在线zhongtongzaixian.com，做有深度的铜资讯门户，精心打造铜行业权威门户。关注铜业新闻、期铜走势、行情分析、财经政策、即时数据、研究报告的交流和分享。 嘉兴中铜信息科技有限公司\n",
      "2 我的农产品网系上海钢联旗下行业网站，网站力图打造国内权威的农产品价格、资讯和数据平台。我的农产品网全面汇聚白糖；豆粕、菜籽粕；豆油、棕榈油、菜籽油；大豆、菜籽；小麦、玉米、稻米；棉花、棉纱等十三种农产品现货价格，及时跟踪农产品期货行情，发布最新的农产品资讯和数据，为用户提供全方位的信息资源。 上海钢联电子商务股份有限公司\n",
      "\n",
      "18 : 91\n",
      "0 新浪微博财经类自媒体人，多年的股海沧桑,民间职业股票投资人.操作风格&lt;超短线结合波段&gt;微博是个人炒股日志 北京和众汇富证券 投资顾问 头条文章作者 微博签约自媒体\n",
      "0 香港新城財經台節目主持 慧悅傳媒創始人。专注于港股财经新闻。 慧悦传媒创始人\n",
      "0 资深股票分析师、培训师 郑州瑞轩教育有限公司董事长 财经博主\n",
      "0 音乐股神，专注证券投资理财，证券分析师，财经作家 音乐视频自媒体\n",
      "0 金源高级策略师。擅长基本面加技术面分析，提供实用、盈利的交易策略。主攻金属、贵金属、工业化工类品种。现任第一财经、东方财经等著名节目特约嘉宾 金源期货高级策略师葛健颖 \n",
      "\n",
      "19 : 37\n",
      "0 涨停股票推荐、潜力股、牛股、股票分析，仅供参考。 微博股评师 财经博主 微博签约自媒体\n",
      "0 主研究量化选股，中短线风格。 以沸腾的心态看待股市， 用量化的数据观察涨跌。 知名财经博主 微博股评师 微博签约自媒体\n",
      "0 2017年新浪微博模拟炒股大赛总收益第3名。曾任职国家行政事业单位，美国私募资本管理商会，独创了【解套宝】和【爱涨停】、【周金股】等荐股类栏目 财经博主 微博投资达人 头条文章作者 微博签约自媒体\n",
      "0 交易日文字实战直播解盘；微博小号@股海实战一哥 同步解盘直播；微博不接任何推广及平台合作事宜，勿扰~！ 微博股评师 知名财经博主 微博签约自媒体\n",
      "0 微信公众号：股海任平生 知名财经博主 微博签约自媒体\n",
      "\n",
      "20 : 49\n",
      "0 知名财经评论员，享誉业界期货分析师，是各财经网活跃博主，名博，长期在各大财经网媒、纸媒等媒体发表期货方面的文章。微信：guo_haozh 财经博主 广州昊天投资有限公司 投资分析研究部总监 头条文章作者\n",
      "0 中国著名的外汇贵金属投资人，知名博主。指导qq：853056960 武汉通鑫保利投资有限公司销售经理\n",
      "0 为广大投资者提供投资建议， 每日分析大盘 善于短线操作 把握不好可以咨询我   上海金帝投资有限公司投资顾问\n",
      "0 专注超短线：当天买，一般第二天就卖。 食丽派短线投资工作室创始人\n",
      "0 新浪财经专栏作家、资深投资人 深圳君择投资控股有限公司董事长\n",
      "\n",
      "21 : 17\n",
      "2 安粮期货马鞍山营业部坐落于马鞍山市繁华地段的中央大厦五楼，环境优越、交通便利，营业场所面积400多平米，目前已经建成全新的机房并拥有先进的交易软件。营业部现有多条光纤线路，保证了网络的连续和通畅，并有充裕的设备资源为交易行情服务终端供客户选择。马鞍山营业部将凭借一流的硬件和软件服务设施，以严谨务实的工作态度，努力打造一支富有资深经验的专业团队，持续为客户提供优质高效的服务。 安粮期货马鞍山营业部官方微博\n",
      "2 营业部地址：上海市浦东新区杨思后长街78号营业部电话：021-33902773营业部主营业务范围：1、融资融券业务——可以提供做多和做空的双向选择2、商品和股指期货IB业务——资金可以杠杆放大3、开放式和封闭式基金业务——基金定投可以积少成多，是子女教育和未来养老的有效助力4、券商集合理财计划——是稳健投资者的最好选择5、短期固定收益类产品和信托产品——1天期产品最高收益率达3%，信托类年化收益率超8%6、约定回购业务——提供更快捷的融资渠道 长江证券股份有限公司上海后长街证券营业部官方微博\n",
      "2 我的微博每日开盘前半个小时推荐牛股,信不信牛不牛,可查看我微博动态(绝对不会让你失望).请加免费交流Q群:50409732 没有20%收益您退群!进群验证:微博 中信万通证券有限责任公司青岛松江路证券营业部\n",
      "2 期货套利套保：服务产业经济 对冲价格风险\r\n",
      "期货资产管理：量化投资分析 资产保值增值 中国国际期货有限公司郑州郑商所营业部\n",
      "2 中国国际期货光华路营业中心隶属于国际期货总部旗下，营业中心坐落于北京CBD核心区域，拥有营销、财务、客服、技术、研究人员百余人，欢迎广大投资… 中国国际期货-光华路营业部官方微博\n",
      "\n",
      "22 : 146\n",
      "0 十年股海，十年坚持，十年百倍收益，喜欢总结，懂得感悟，分享经验，快乐投资，与股海沉浮一路同行！ 上海证大资产管理有限公司市场经理 财经博主 头条文章作者 微博签约自媒体\n",
      "0 股票现货风险首席分析专家，知名财经作家郭然微博自媒体联盟成员     理财规划师\n",
      "0 无锡不锈钢开户，期货开户，无锡不锈钢套利 QQ:1182006958 前 渤海现货贵金属首席理财顾问\n",
      "0 本人致力于A股研究，短线操作，提前埋伏未来热点板块和概念，欢迎各位股民朋友前来交流学习！ 微博有延迟！加我的Q:422893994。方便交流。 项目管理师\n",
      "0 职业化妆，爱好理发，业余炒股，没事看书，热忠绘画，必须抽奖，闲着逛街，有空发微 高级化妆师 高级服装设计定制工 知名读物博主\n",
      "\n",
      "23 : 46\n",
      "0 财经媒体人，关注奢侈品，关注TMT，欢迎各位大虾新闻爆料~~~有料者发邮件：mintsky0611@126.com 财经媒体人\n",
      "0 复利--才是赢利之王！微博是个人炒股日志，跟风者自负盈亏。 财经博主 财经视频自媒体\n",
      "0 炒炒股，聊聊天，抓抓妖股，短线走起！ 财经视频自媒体\n",
      "0 股票期货投资理财、开户业务、V信  A8GSXL 财经博主 财经视频自媒体\n",
      "0 简单炒股，快乐生活，资金流派，极致打法 财经视频自媒体\n",
      "\n",
      "24 : 37\n",
      "0 i美股资产管理 i美股资产管理有限公司创始人CEO\n",
      "0 一个游走于文学，股票，摄影，音乐，设计等领域的纠结的灵魂!一个极度悲观的乐观主义者！ 深圳市信合资产管理有限公司董事长\n",
      "0 熊市短线做熊票，牛市长线做牛票，顺大势逆小势高抛低吸，寻求常年稳定收益 上海台益投资管理有限公司 职员\n",
      "0 听我广播节奏买股票。包你一年翻倍 上海申彤投资管理有限公司研究总监 财经博主 头条文章作者\n",
      "0 关于股市的问题请找我私聊.或者加我VX号:vbvbpenji88即使你不相信，奇迹也会发生；即使你不承认，实力依然存在；即使你不参与，收益仍然继续   上海冠亚投资管理有限公司 职员\n",
      "\n",
      "25 : 42\n",
      "0 东方财富上证吧 - 天堂湖，A股最精准趋势分析！ 知名财经博主 头条文章作者 微博签约自媒体\n",
      "0 一个比普通股民还普通的普通股民，炒股信奉：“时间是爷，空间是爹，时间是触发事件的神秘力量。” 知名财经博主 头条文章作者 微博签约自媒体\n",
      "0 每天A股收评在微信公众号：林奇 上海独孤投资CEO 头条文章作者 微博签约自媒体\n",
      "0 职业股民，资深财经博主，股评师，炒股比赛冠军 知名财经博主 头条文章作者 微博签约自媒体\n",
      "0 私募操盘手，13年A股大赛周亚军！ 知名财经博主 头条文章作者 微博签约自媒体\n",
      "\n",
      "26 : 70\n",
      "0 拥有丰富的解盘及操盘实战经验，对于热点题材龙头个股的把握较为精准并擅长把握各类主题投资机会。欢迎更多的投资者与GDLZ89实战一同交流互动！ 财经博主 头条文章作者 微博签约自媒体\n",
      "0 帮助别人成就自己，20年股海观风雨，主力控盘实独步股林。 知名财经博主 头条文章作者 微博签约自媒体\n",
      "0 巡A股之庄家，定起爆之位；教股市之兵法，结百家之散户。 财经博主 头条文章作者 微博签约自媒体\n",
      "0 短期理财你的首选，周期短 收益稳 配比赚差价，想参与添加我的VX：294218296 验证：Y 黄金投资分析师 财经博主 头条文章作者 微博签约自媒体\n",
      "0 二十年骨灰级投资客，十三年专业操盘经验，知名私募基金首席操盘。历经A股牛熊，总结出独自操作战法，致力于热点龙头挖掘，崇尚佛学 财经博主 头条文章作者 微博签约自媒体\n",
      "\n",
      "27 : 27\n",
      "0 外盘期货开户请加本人唯一微信 WK80008。无门槛资金限制。 微博股评团成员 财经博主 头条文章作者\n",
      "0 仙人掌股票签约博主、摩尔金融撰稿人 水晶球财经撰稿人、换手率特约博主、财联社V认证 股评团成员 财经博主\n",
      "0 庄圣庭，资深投资者，证券分析师，20余年投资生涯，拥有丰富的解盘及操盘实战经验，对于热点题材龙头个股的把握较为精准并擅长把握各类主题投资机会。 股评团成员 财经博主 头条文章作者\n",
      "0 技术与趋势结合的短线操作，擅长抓妖擒牛，精准把握股票市场走势。稳健安全获利。 财经博主 股评团成员 头条文章作者\n",
      "0 本博主提供个人股票观点及建议，风险自担。 华西证券职业操盘手执业编号S1080611120088 买入靠耐心，持有靠信心，卖出靠决心。 股评团成员 财经博主 头条文章作者\n",
      "\n",
      "28 : 99\n",
      "0 爱财经爱生活。 此时眉目尚嫣然超话小主持人\n",
      "0 微博认证：独一家犀利财经观察家，20年A港美股职业经理，微博签约自媒体。微信xc1641005906 上海中金所衍生品研究院 博士研究员\n",
      "0 市场博弈的结果是均衡，又可细分静态均衡和动态均衡，静态易于操作，动态则更能带来超额收益。   北京聊塑新展贸易有限公司  研发总监\n",
      "0 期货内功交易心法：顺势，轻仓，亏盈比一定大于1:3，微信QQ同号258326366 武汉鸿金宝投资有限公司 总经理 何竟波\n",
      "0 国内知名农产品期货专家。 宏源期货农产品研究室负责人王勇\n",
      "\n",
      "29 : 48\n",
      "0 我的微信号：sz06888，欢迎大家前来交流学习，免费解答个股问题。 财经博主 头条文章作者\n",
      "0 2013年在国内首创量化+仓位管理，提供更直观，量化的仓位管理解决方案。 财经博主 头条文章作者\n",
      "0 股票~期货~期权 定位：庙堂与江湖之外的静心之地 头条文章作者\n",
      "0 股票/外汇职业操盘手。 财经博主 头条文章作者\n",
      "0 基督徒，金融分析师 主要从事A股、美股、期货市场技术分析、逻辑推演。 于基本面、消息面无涉猎。 财经博主 头条文章作者\n",
      "\n",
      "30 : 21\n",
      "0 专注港股打新策略研究（新股申购策略、卖出策略、炒新策略，2017年港股打新实盘收益率265%） 深圳格隆汇信息科技有限公司 格隆汇合伙人\n",
      "0 安信期货研究所所长马春阳 安信期货研究所所长\n",
      "0 股票段子手，市场收割团团长 头条文章作者\n",
      "0 非主流炒股人士！ 头条文章作者\n",
      "0 那些个股神! 来，我们用实盘说话，马后炮咱不放 财经博主 头条文章作者\n",
      "\n",
      "31 : 33\n",
      "2 致力于资产管理、期货股票投资指导、专业操盘手实战培训。 安徽腾龙创富金融信息服务有限公司\n",
      "2 赣南有脐橙，国内皆有名！卖了脐橙买股票，持好股票卖脐橙，我是认真的，购橙V信：cwy13330139665 龙南艾德礼品有限公司官方微博\n",
      "2 返佣宝(www.fanyongbao.com)，金融返佣首选平台！返佣网,返利网,外汇返佣,黄金返佣，股票返佣，期货返佣,理财返佣,最高返佣100%。返佣宝以降低金融交易成本为使命，为会员提供最高的返佣标准，始终奉行安全、诚信、快捷的经营理念，打造金融返佣行业领先的一站式金融返佣折扣平台！ 大连仙迪信息科技有限公司\n",
      "2 DriveWealth LLC 嘉维证券是美国FINRA 及 SIPC 成员。交易佣金为每股0.0125美元，每笔交易佣金至少2.99美元。无最低注资要求。作为美国金融业监管局FINRA 发牌的持牌券商，DriveWealth LLC提供美国股票交易、交易所买卖基金（ETF）交易及美国存托凭证（ADRs）交易。 DriveWealth LLC\n",
      "2 【金融港】系金斧子携手国际顶级风投打造，服务于理财师的理财产品分销平台，平台包括网站、IOS、Android、微信公众账号等 深圳前海滚雪球财富管理有限公司\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for dat in data.groupby('labels'):\n",
    "    print(dat[0], ': {}'.format(len(dat[1])))\n",
    "    cls, dat = dat[0], dat[1]\n",
    "    for _, __, ___ in zip(dat.verified_type[:5], dat.text[:5], dat.reason[:5]):\n",
    "        print(_, __, ___)\n",
    "    print()\n",
    "    for x in dat.id:\n",
    "        id_bucket[cls].append(x)\n",
    "        id_map[x] = cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-19T12:41:35.427121Z",
     "start_time": "2018-10-19T12:40:15.448263Z"
    }
   },
   "outputs": [],
   "source": [
    "for k, v in id_bucket.items():\n",
    "    for x in v:\n",
    "        collection.update_one({'id': x}, {'$set': {'cluster_class': k} }, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-19T12:41:35.444684Z",
     "start_time": "2018-10-19T12:41:35.435459Z"
    }
   },
   "outputs": [],
   "source": [
    "# collection.update_one({'id': 5802435481}, {'$set': {'cluster_class': 1} }, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labeling weibos with clustering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-19T12:43:58.324310Z",
     "start_time": "2018-10-19T12:43:58.321387Z"
    }
   },
   "outputs": [],
   "source": [
    "collection_weibo = db['weibos']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-20T01:29:23.919863Z",
     "start_time": "2018-10-20T01:29:23.913074Z"
    }
   },
   "outputs": [],
   "source": [
    "result = collection_weibo.find({'cluster_class':{'$exists': False}}, {'id':1, 'user':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-20T01:30:06.604730Z",
     "start_time": "2018-10-20T01:29:48.891743Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnt = 0\n",
      "cnt = 100\n",
      "cnt = 200\n",
      "cnt = 300\n"
     ]
    }
   ],
   "source": [
    "# result = collection_weibo.find({}, {'id':1, 'user':1})\n",
    "result = collection_weibo.find({'cluster_class':{'$exists': False}}, {'id':1, 'user':1})\n",
    "for (cnt, x) in enumerate(result):\n",
    "    collection_weibo.update_one({'id': x['id']}, {'$set': {'cluster_class': id_map[int(x['user'])]} }, False)\n",
    "    if cnt % 100 == 0:\n",
    "        print('cnt = {}'.format(cnt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-20T01:25:26.072727Z",
     "start_time": "2018-10-20T01:25:26.065555Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_map[2038950003]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
